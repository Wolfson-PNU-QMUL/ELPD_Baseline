{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013786c0",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Getting-started\" data-toc-modified-id=\"Getting-started-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Getting started</a></span></li><li><span><a href=\"#Ethnicity\" data-toc-modified-id=\"Ethnicity-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Ethnicity</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Gender\" data-toc-modified-id=\"Gender-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Gender</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Age-at-assessment\" data-toc-modified-id=\"Age-at-assessment-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Age at assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#PD-patients\" data-toc-modified-id=\"PD-patients-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>PD patients</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Significance-testing\" data-toc-modified-id=\"Significance-testing-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Significance testing</a></span></li></ul></li><li><span><a href=\"#Age-at-diagnosis\" data-toc-modified-id=\"Age-at-diagnosis-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Age at diagnosis</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#SIgnificance\" data-toc-modified-id=\"SIgnificance-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>SIgnificance</a></span></li></ul></li><li><span><a href=\"#Age-at-symptom-onset\" data-toc-modified-id=\"Age-at-symptom-onset-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Age at symptom onset</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance\" data-toc-modified-id=\"Significance-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Significance</a></span></li></ul></li><li><span><a href=\"#Time-since-diagnosis\" data-toc-modified-id=\"Time-since-diagnosis-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Time since diagnosis</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance-testing\" data-toc-modified-id=\"Significance-testing-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Significance testing</a></span></li></ul></li><li><span><a href=\"#Duration-of-symptoms-on-assessment-/-Disease-duration\" data-toc-modified-id=\"Duration-of-symptoms-on-assessment-/-Disease-duration-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Duration of symptoms on assessment / Disease duration</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance-testing\" data-toc-modified-id=\"Significance-testing-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Significance testing</a></span></li></ul></li><li><span><a href=\"#Duration-of-symptoms-at-diagnosis\" data-toc-modified-id=\"Duration-of-symptoms-at-diagnosis-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Duration of symptoms at diagnosis</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance-testing\" data-toc-modified-id=\"Significance-testing-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Significance testing</a></span></li></ul></li><li><span><a href=\"#Comorbidities\" data-toc-modified-id=\"Comorbidities-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Comorbidities</a></span><ul class=\"toc-item\"><li><span><a href=\"#HTN\" data-toc-modified-id=\"HTN-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>HTN</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-10.1.1\"><span class=\"toc-item-num\">10.1.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-10.1.2\"><span class=\"toc-item-num\">10.1.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Significance\" data-toc-modified-id=\"Significance-10.1.3\"><span class=\"toc-item-num\">10.1.3&nbsp;&nbsp;</span>Significance</a></span></li></ul></li><li><span><a href=\"#T2DM\" data-toc-modified-id=\"T2DM-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>T2DM</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-10.2.1\"><span class=\"toc-item-num\">10.2.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-10.2.2\"><span class=\"toc-item-num\">10.2.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Signficance\" data-toc-modified-id=\"Signficance-10.2.3\"><span class=\"toc-item-num\">10.2.3&nbsp;&nbsp;</span>Signficance</a></span></li></ul></li><li><span><a href=\"#Smoking\" data-toc-modified-id=\"Smoking-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Smoking</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-10.3.1\"><span class=\"toc-item-num\">10.3.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-10.3.2\"><span class=\"toc-item-num\">10.3.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Significance\" data-toc-modified-id=\"Significance-10.3.3\"><span class=\"toc-item-num\">10.3.3&nbsp;&nbsp;</span>Significance</a></span></li></ul></li></ul></li><li><span><a href=\"#LEDD\" data-toc-modified-id=\"LEDD-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>LEDD</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#UPDRS\" data-toc-modified-id=\"UPDRS-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>UPDRS</a></span><ul class=\"toc-item\"><li><span><a href=\"#UPDRS-I\" data-toc-modified-id=\"UPDRS-I-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>UPDRS I</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-12.1.1\"><span class=\"toc-item-num\">12.1.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-12.1.2\"><span class=\"toc-item-num\">12.1.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-12.1.3\"><span class=\"toc-item-num\">12.1.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#UPDRS-II\" data-toc-modified-id=\"UPDRS-II-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>UPDRS II</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-12.2.1\"><span class=\"toc-item-num\">12.2.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-12.2.2\"><span class=\"toc-item-num\">12.2.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-12.2.3\"><span class=\"toc-item-num\">12.2.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#UPDRS-III\" data-toc-modified-id=\"UPDRS-III-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>UPDRS III</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-12.3.1\"><span class=\"toc-item-num\">12.3.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Signifcance---univariate\" data-toc-modified-id=\"Signifcance---univariate-12.3.2\"><span class=\"toc-item-num\">12.3.2&nbsp;&nbsp;</span>Signifcance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-12.3.3\"><span class=\"toc-item-num\">12.3.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li><li><span><a href=\"#OFF-vs-ON-state\" data-toc-modified-id=\"OFF-vs-ON-state-12.3.4\"><span class=\"toc-item-num\">12.3.4&nbsp;&nbsp;</span>OFF vs ON state</a></span></li></ul></li><li><span><a href=\"#UPDRS-IV\" data-toc-modified-id=\"UPDRS-IV-12.4\"><span class=\"toc-item-num\">12.4&nbsp;&nbsp;</span>UPDRS IV</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-12.4.1\"><span class=\"toc-item-num\">12.4.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-12.4.2\"><span class=\"toc-item-num\">12.4.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-12.4.3\"><span class=\"toc-item-num\">12.4.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#UPDRS-figure\" data-toc-modified-id=\"UPDRS-figure-12.5\"><span class=\"toc-item-num\">12.5&nbsp;&nbsp;</span>UPDRS figure</a></span></li></ul></li><li><span><a href=\"#NMSQ\" data-toc-modified-id=\"NMSQ-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>NMSQ</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-13.3\"><span class=\"toc-item-num\">13.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#MoCA\" data-toc-modified-id=\"MoCA-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>MoCA</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HCs\" data-toc-modified-id=\"HCs-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>HCs</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-14.4\"><span class=\"toc-item-num\">14.4&nbsp;&nbsp;</span>Significance - multivariate</a></span></li><li><span><a href=\"#MoCA-Figure\" data-toc-modified-id=\"MoCA-Figure-14.5\"><span class=\"toc-item-num\">14.5&nbsp;&nbsp;</span>MoCA Figure</a></span></li><li><span><a href=\"#Significance---categorical-data\" data-toc-modified-id=\"Significance---categorical-data-14.6\"><span class=\"toc-item-num\">14.6&nbsp;&nbsp;</span>Significance - categorical data</a></span><ul class=\"toc-item\"><li><span><a href=\"#NC,-MCI,-PDD\" data-toc-modified-id=\"NC,-MCI,-PDD-14.6.1\"><span class=\"toc-item-num\">14.6.1&nbsp;&nbsp;</span>NC, MCI, PDD</a></span></li><li><span><a href=\"#NC-vs-CI\" data-toc-modified-id=\"NC-vs-CI-14.6.2\"><span class=\"toc-item-num\">14.6.2&nbsp;&nbsp;</span>NC vs CI</a></span></li></ul></li></ul></li><li><span><a href=\"#Smell-test\" data-toc-modified-id=\"Smell-test-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Smell test</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-15.1\"><span class=\"toc-item-num\">15.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#HC\" data-toc-modified-id=\"HC-15.2\"><span class=\"toc-item-num\">15.2&nbsp;&nbsp;</span>HC</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-15.3\"><span class=\"toc-item-num\">15.3&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-15.4\"><span class=\"toc-item-num\">15.4&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#HADS\" data-toc-modified-id=\"HADS-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>HADS</a></span><ul class=\"toc-item\"><li><span><a href=\"#HADS-D\" data-toc-modified-id=\"HADS-D-16.1\"><span class=\"toc-item-num\">16.1&nbsp;&nbsp;</span>HADS-D</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-16.1.1\"><span class=\"toc-item-num\">16.1.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#SIgnificance---univariate\" data-toc-modified-id=\"SIgnificance---univariate-16.1.2\"><span class=\"toc-item-num\">16.1.2&nbsp;&nbsp;</span>SIgnificance - univariate</a></span></li><li><span><a href=\"#SIgnificance---multivariate\" data-toc-modified-id=\"SIgnificance---multivariate-16.1.3\"><span class=\"toc-item-num\">16.1.3&nbsp;&nbsp;</span>SIgnificance - multivariate</a></span></li></ul></li><li><span><a href=\"#HADS-A\" data-toc-modified-id=\"HADS-A-16.2\"><span class=\"toc-item-num\">16.2&nbsp;&nbsp;</span>HADS-A</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-16.2.1\"><span class=\"toc-item-num\">16.2.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-16.2.2\"><span class=\"toc-item-num\">16.2.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-16.2.3\"><span class=\"toc-item-num\">16.2.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li></ul></li><li><span><a href=\"#RBDSQ\" data-toc-modified-id=\"RBDSQ-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>RBDSQ</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-17.1\"><span class=\"toc-item-num\">17.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-17.2\"><span class=\"toc-item-num\">17.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-17.3\"><span class=\"toc-item-num\">17.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#PSS2\" data-toc-modified-id=\"PSS2-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>PSS2</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-18.1\"><span class=\"toc-item-num\">18.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-18.2\"><span class=\"toc-item-num\">18.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-18.3\"><span class=\"toc-item-num\">18.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#ESS\" data-toc-modified-id=\"ESS-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>ESS</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-19.1\"><span class=\"toc-item-num\">19.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-19.2\"><span class=\"toc-item-num\">19.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-19.3\"><span class=\"toc-item-num\">19.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#SCOPA--AUT\" data-toc-modified-id=\"SCOPA--AUT-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>SCOPA- AUT</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-20.1\"><span class=\"toc-item-num\">20.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-20.2\"><span class=\"toc-item-num\">20.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-20.3\"><span class=\"toc-item-num\">20.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#EQ5D5L\" data-toc-modified-id=\"EQ5D5L-21\"><span class=\"toc-item-num\">21&nbsp;&nbsp;</span>EQ5D5L</a></span><ul class=\"toc-item\"><li><span><a href=\"#VAS\" data-toc-modified-id=\"VAS-21.1\"><span class=\"toc-item-num\">21.1&nbsp;&nbsp;</span>VAS</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-21.1.1\"><span class=\"toc-item-num\">21.1.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-21.1.2\"><span class=\"toc-item-num\">21.1.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-21.1.3\"><span class=\"toc-item-num\">21.1.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#Index\" data-toc-modified-id=\"Index-21.2\"><span class=\"toc-item-num\">21.2&nbsp;&nbsp;</span>Index</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-21.2.1\"><span class=\"toc-item-num\">21.2.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-21.2.2\"><span class=\"toc-item-num\">21.2.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-21.2.3\"><span class=\"toc-item-num\">21.2.3&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li></ul></li><li><span><a href=\"#MERQ\" data-toc-modified-id=\"MERQ-22\"><span class=\"toc-item-num\">22&nbsp;&nbsp;</span>MERQ</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pesticides\" data-toc-modified-id=\"Pesticides-22.1\"><span class=\"toc-item-num\">22.1&nbsp;&nbsp;</span>Pesticides</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.1.1\"><span class=\"toc-item-num\">22.1.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.1.2\"><span class=\"toc-item-num\">22.1.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Head-innjury\" data-toc-modified-id=\"Head-innjury-22.2\"><span class=\"toc-item-num\">22.2&nbsp;&nbsp;</span>Head innjury</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.2.1\"><span class=\"toc-item-num\">22.2.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.2.2\"><span class=\"toc-item-num\">22.2.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Caffeine---previous\" data-toc-modified-id=\"Caffeine---previous-22.3\"><span class=\"toc-item-num\">22.3&nbsp;&nbsp;</span>Caffeine - previous</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.3.1\"><span class=\"toc-item-num\">22.3.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.3.2\"><span class=\"toc-item-num\">22.3.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Caffeine---current\" data-toc-modified-id=\"Caffeine---current-22.4\"><span class=\"toc-item-num\">22.4&nbsp;&nbsp;</span>Caffeine - current</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.4.1\"><span class=\"toc-item-num\">22.4.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.4.2\"><span class=\"toc-item-num\">22.4.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Caffeine-amount---previous\" data-toc-modified-id=\"Caffeine-amount---previous-22.5\"><span class=\"toc-item-num\">22.5&nbsp;&nbsp;</span>Caffeine amount - previous</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.5.1\"><span class=\"toc-item-num\">22.5.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.5.2\"><span class=\"toc-item-num\">22.5.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Caffeine-amount---current\" data-toc-modified-id=\"Caffeine-amount---current-22.6\"><span class=\"toc-item-num\">22.6&nbsp;&nbsp;</span>Caffeine amount - current</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.6.1\"><span class=\"toc-item-num\">22.6.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.6.2\"><span class=\"toc-item-num\">22.6.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Alcohol---previous\" data-toc-modified-id=\"Alcohol---previous-22.7\"><span class=\"toc-item-num\">22.7&nbsp;&nbsp;</span>Alcohol - previous</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.7.1\"><span class=\"toc-item-num\">22.7.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.7.2\"><span class=\"toc-item-num\">22.7.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Acohol---current\" data-toc-modified-id=\"Acohol---current-22.8\"><span class=\"toc-item-num\">22.8&nbsp;&nbsp;</span>Acohol - current</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.8.1\"><span class=\"toc-item-num\">22.8.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.8.2\"><span class=\"toc-item-num\">22.8.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Smoking---previous\" data-toc-modified-id=\"Smoking---previous-22.9\"><span class=\"toc-item-num\">22.9&nbsp;&nbsp;</span>Smoking - previous</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.9.1\"><span class=\"toc-item-num\">22.9.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.9.2\"><span class=\"toc-item-num\">22.9.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li><li><span><a href=\"#Smoking---current\" data-toc-modified-id=\"Smoking---current-22.10\"><span class=\"toc-item-num\">22.10&nbsp;&nbsp;</span>Smoking - current</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP\" data-toc-modified-id=\"PwP-22.10.1\"><span class=\"toc-item-num\">22.10.1&nbsp;&nbsp;</span>PwP</a></span></li><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-22.10.2\"><span class=\"toc-item-num\">22.10.2&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li></ul></li><li><span><a href=\"#BRAINtest-data\" data-toc-modified-id=\"BRAINtest-data-23\"><span class=\"toc-item-num\">23&nbsp;&nbsp;</span>BRAINtest data</a></span><ul class=\"toc-item\"><li><span><a href=\"#UPDRSIII-L-vs-R-scores\" data-toc-modified-id=\"UPDRSIII-L-vs-R-scores-23.1\"><span class=\"toc-item-num\">23.1&nbsp;&nbsp;</span>UPDRSIII L vs R scores</a></span></li><li><span><a href=\"#KS\" data-toc-modified-id=\"KS-23.2\"><span class=\"toc-item-num\">23.2&nbsp;&nbsp;</span>KS</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP---Group-by-UPDRS\" data-toc-modified-id=\"PwP---Group-by-UPDRS-23.2.1\"><span class=\"toc-item-num\">23.2.1&nbsp;&nbsp;</span>PwP - Group by UPDRS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-23.2.1.1\"><span class=\"toc-item-num\">23.2.1.1&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-23.2.1.2\"><span class=\"toc-item-num\">23.2.1.2&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#HCs\" data-toc-modified-id=\"HCs-23.2.2\"><span class=\"toc-item-num\">23.2.2&nbsp;&nbsp;</span>HCs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-23.2.2.1\"><span class=\"toc-item-num\">23.2.2.1&nbsp;&nbsp;</span>Significance - univariate</a></span></li></ul></li></ul></li><li><span><a href=\"#AT\" data-toc-modified-id=\"AT-23.3\"><span class=\"toc-item-num\">23.3&nbsp;&nbsp;</span>AT</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP---Group-by-UPDRS\" data-toc-modified-id=\"PwP---Group-by-UPDRS-23.3.1\"><span class=\"toc-item-num\">23.3.1&nbsp;&nbsp;</span>PwP - Group by UPDRS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-23.3.1.1\"><span class=\"toc-item-num\">23.3.1.1&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-23.3.1.2\"><span class=\"toc-item-num\">23.3.1.2&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#HCs\" data-toc-modified-id=\"HCs-23.3.2\"><span class=\"toc-item-num\">23.3.2&nbsp;&nbsp;</span>HCs</a></span></li></ul></li><li><span><a href=\"#IS\" data-toc-modified-id=\"IS-23.4\"><span class=\"toc-item-num\">23.4&nbsp;&nbsp;</span>IS</a></span><ul class=\"toc-item\"><li><span><a href=\"#PwP---Group-by-UPDRS\" data-toc-modified-id=\"PwP---Group-by-UPDRS-23.4.1\"><span class=\"toc-item-num\">23.4.1&nbsp;&nbsp;</span>PwP - Group by UPDRS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-23.4.1.1\"><span class=\"toc-item-num\">23.4.1.1&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-23.4.1.2\"><span class=\"toc-item-num\">23.4.1.2&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li><li><span><a href=\"#HCs\" data-toc-modified-id=\"HCs-23.4.2\"><span class=\"toc-item-num\">23.4.2&nbsp;&nbsp;</span>HCs</a></span></li></ul></li></ul></li><li><span><a href=\"#Deprivation-index\" data-toc-modified-id=\"Deprivation-index-24\"><span class=\"toc-item-num\">24&nbsp;&nbsp;</span>Deprivation index</a></span><ul class=\"toc-item\"><li><span><a href=\"#Significance---univariate\" data-toc-modified-id=\"Significance---univariate-24.1\"><span class=\"toc-item-num\">24.1&nbsp;&nbsp;</span>Significance - univariate</a></span></li><li><span><a href=\"#Significance---multivariate\" data-toc-modified-id=\"Significance---multivariate-24.2\"><span class=\"toc-item-num\">24.2&nbsp;&nbsp;</span>Significance - multivariate</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91afa715",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a06e6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import researchpy as rp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.contingency_tables import Table2x2, mcnemar, Table\n",
    "from scipy.stats import chi2_contingency\n",
    "from matplotlib.markers import TICKDOWN\n",
    "from statannot import add_stat_annotation\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b46d5e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After excluding patients without a visit 1: 218\n"
     ]
    }
   ],
   "source": [
    "# Read file\n",
    "ELPDP = pd.read_csv('Raw_data_PwP.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Identify NAs\n",
    "ELPDP.replace(999, np.NaN, inplace=True)\n",
    "ELPDP.replace(888, np.NaN, inplace=True)\n",
    "ELPDP.replace(' ', np.NaN, inplace=True)\n",
    "ELPDP = ELPDP[ELPDP['DOA'].notna()]\n",
    "\n",
    "print('After excluding patients without a visit 1:', ELPDP.ELPD_ID.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e37e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of HCs:  90\n"
     ]
    }
   ],
   "source": [
    "# Read file\n",
    "ELPDH = pd.read_csv('Raw_data_HC.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Identify NAs\n",
    "ELPDH.replace(999, np.NaN, inplace=True)\n",
    "ELPDH.replace(888, np.NaN, inplace=True)\n",
    "ELPDH.replace(' ', np.NaN, inplace=True)\n",
    "\n",
    "print('')\n",
    "print('Number of HCs: ', ELPDH.ELPD_ID.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10851800",
   "metadata": {},
   "source": [
    "# Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0effc5",
   "metadata": {},
   "source": [
    "## PwP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9252cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PwP in ELPD:  218\n",
      "\n",
      "n:  96\n",
      "%:  44\n",
      "\n",
      "n:  85\n",
      "%:  39\n",
      "\n",
      "n:  24\n",
      "%:  11\n"
     ]
    }
   ],
   "source": [
    "a = 'ELPD_ID'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# All\n",
    "print('Total number of PwP in ELPD: ', df[a].count())\n",
    "print('')\n",
    "\n",
    "# White\n",
    "W = df[df[b]==1].count()\n",
    "print('n: ', W[a])\n",
    "W_percentage = W[a] / df[a].count() * 100\n",
    "print('%: ', \"%.0f\" % W_percentage)\n",
    "print('')\n",
    "\n",
    "# South Asian\n",
    "SA = df[df[b]==3].count()\n",
    "print('n: ', SA[a])\n",
    "SA_percentage = SA[a] / df[a].count() * 100\n",
    "print('%: ', \"%.0f\" % SA_percentage)\n",
    "print('')\n",
    "\n",
    "# Black\n",
    "B = df[df[b]==2].count()\n",
    "print('n: ', B[a])\n",
    "B_percentage = B[a] / df[a].count() * 100\n",
    "print('%: ', \"%.0f\" % B_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44faa566",
   "metadata": {},
   "source": [
    "## HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cbde2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of HCs in ELPD:  90\n",
      "\n",
      "n:  30\n",
      "%:  33\n",
      "\n",
      "n:  56\n",
      "%:  62\n",
      "\n",
      "n:  2\n",
      "%:  2\n"
     ]
    }
   ],
   "source": [
    "a = 'ELPD_ID'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "\n",
    "# ALl\n",
    "print('Total number of HCs in ELPD: ', df[a].count())\n",
    "print('')\n",
    "\n",
    "# White \n",
    "W_HC = df[df[b]==1].count()\n",
    "print('n: ', W_HC[a])\n",
    "W_percentage = W_HC[a] / df[a].count() * 100\n",
    "print('%: ', \"%.0f\" % W_percentage)\n",
    "print('')\n",
    "\n",
    "# South Asian \n",
    "SA_HC = df[df[b]==3].count()\n",
    "print('n: ', SA_HC[a])\n",
    "SA_percentage = SA_HC[a] / df[a].count() * 100\n",
    "print('%: ', \"%.0f\" % SA_percentage)\n",
    "print('')\n",
    "\n",
    "# Black\n",
    "B_HC = df[df[b]==2].count()\n",
    "print('n: ', B_HC[a])\n",
    "B_percentage = B_HC[a] / df[a].count() * 100\n",
    "print('%: ', \"%.0f\" % B_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a716f2",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d342196",
   "metadata": {},
   "source": [
    "PwP vs HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6333650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PwP  HC\n",
      "Ethnicity           \n",
      "White         96  30\n",
      "South Asian   85  56\n",
      "Black         24   2\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {'Ethnicity':['White', 'South Asian', 'Black'],\n",
    "        'PwP': [W[a], SA[a], B[a]], \n",
    "        'HC': [W_HC[a], SA_HC[a], B_HC[a]]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['Ethnicity','PwP', 'HC'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index('Ethnicity', inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d97944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 14.79\n",
      "\n",
      "Difference is significant, p:  0.0006 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fisher's exact as n < 5 in at least one cell:\n",
    "\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2ee23",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df37425",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "685db5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  218\n",
      "Male\n",
      "All\n",
      "n:  137\n",
      "%:  62.8\n",
      "\n",
      "White:  96\n",
      "n:  63\n",
      "%:  65.6\n",
      "\n",
      "South Asian:  85\n",
      "n:  56\n",
      "%:  65.9\n",
      "\n",
      "Black:  24\n",
      "n:  12\n",
      "%:  50.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'ELPD_ID'\n",
    "b = 'Ethnicity'\n",
    "c = 'Gender'\n",
    "df = ELPDP\n",
    "\n",
    "# Percentage of males:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "Male = df[df[c]==1].count()\n",
    "print('Male')\n",
    "print('All')\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "Male = W[W[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "Male = SA[SA[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "Male = B[B[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220a459",
   "metadata": {},
   "source": [
    "## HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e7f9228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCs\n",
      "All:  90\n",
      "n:  63\n",
      "%:  70.0\n",
      "\n",
      "White:  30\n",
      "n:  19\n",
      "%:  63.3\n",
      "\n",
      "South Asian:  56\n",
      "n:  42\n",
      "%:  75.0\n",
      "\n",
      "Black:  2\n",
      "n:  1\n",
      "%:  50.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'ELPD_ID'\n",
    "b = 'Ethnicity'\n",
    "c = 'Gender'\n",
    "df = ELPDH\n",
    "\n",
    "# Percentage of males:\n",
    "print('HCs')\n",
    "print('All: ', df[a].count())\n",
    "Male = df[df[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "Male = W[W[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "Male = SA[SA[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "Male = B[B[c]==1].count()\n",
    "print('n: ', Male[a])\n",
    "Male_percentage = Male[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Male_percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd83805",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f32d7",
   "metadata": {},
   "source": [
    "PwP vs HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1cc1654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PwP  HC\n",
      "Gender         \n",
      "Male    137  63\n",
      "Female   81  27\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "\n",
    "# Patients \n",
    "df = ELPDP\n",
    "\n",
    "Male = df[df[c]==1]\n",
    "Male = Male[a].count()\n",
    "Female = df[df[c]==0]\n",
    "Female = Female[a].count()\n",
    "\n",
    "\n",
    "# Healthy controls\n",
    "df = ELPDH\n",
    "\n",
    "Male_HC = df[df[c]==1]\n",
    "Male_HC = Male_HC[a].count()\n",
    "Female_HC = df[df[c]==0]\n",
    "Female_HC = Female_HC[a].count()\n",
    "\n",
    "\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {'Gender':['Male', 'Female'],\n",
    "        'PwP': [Male, Female], \n",
    "        'HC': [Male_HC, Female_HC]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['Gender','PwP', 'HC'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index('Gender', inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52d6c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP vs HC\n",
      "\n",
      "T statistic:  1.136\n",
      "Degrees of freedom:  1\n",
      "p value: 0.287\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "print('PwP vs HC')\n",
    "print('')\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "#Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.3f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98391f",
   "metadata": {},
   "source": [
    "PwP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49f8b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        White  South Asian  Black\n",
      "Gender                           \n",
      "Male       63           56     12\n",
      "Female     33           29     12\n"
     ]
    }
   ],
   "source": [
    "a = 'ELPD_ID'\n",
    "b = 'Ethnicity'\n",
    "c = 'Gender'\n",
    "df = ELPDP\n",
    "\n",
    "# Percentage of males:\n",
    "W = df[df[b]==1]\n",
    "W_Male = W[W[c]==1]\n",
    "W_Male = W_Male[c].count()\n",
    "W_Female = W[W[c]==0]\n",
    "W_Female = W_Female[c].count()\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "SA_Male = SA[SA[c]==1]\n",
    "SA_Male = SA_Male[c].count()\n",
    "SA_Female = SA[SA[c]==0]\n",
    "SA_Female = SA_Female[c].count()\n",
    "\n",
    "B = df[df[b]==2]\n",
    "B_Male = B[B[c]==1]\n",
    "B_Male = B_Male[c].count()\n",
    "B_Female = B[B[c]==0]\n",
    "B_Female = B_Female[c].count()\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {'Gender':['Male', 'Female'],\n",
    "        'White': [W_Male, W_Female], \n",
    "        'South Asian': [SA_Male, SA_Female],\n",
    "            'Black': [B_Male, B_Female]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[c,'White', 'South Asian', 'Black'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index('Gender', inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "386b4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP vs HC\n",
      "\n",
      "T statistic:  2.279\n",
      "Degrees of freedom:  2\n",
      "p value: 0.320\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "print('PwP vs HC')\n",
    "print('')\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "#Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.3f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d107f",
   "metadata": {},
   "source": [
    "HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc5a85eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        White  South Asian  Black\n",
      "Gender                           \n",
      "Male       19           42      1\n",
      "Female     11           14      1\n"
     ]
    }
   ],
   "source": [
    "a = 'ELPD_ID'\n",
    "b = 'Ethnicity'\n",
    "c = 'Gender'\n",
    "df = ELPDH\n",
    "\n",
    "# Percentage of males:\n",
    "W = df[df[b]==1]\n",
    "W_Male = W[W[c]==1]\n",
    "W_Male = W_Male[c].count()\n",
    "W_Female = W[W[c]==0]\n",
    "W_Female = W_Female[c].count()\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "SA_Male = SA[SA[c]==1]\n",
    "SA_Male = SA_Male[c].count()\n",
    "SA_Female = SA[SA[c]==0]\n",
    "SA_Female = SA_Female[c].count()\n",
    "\n",
    "B = df[df[b]==2]\n",
    "B_Male = B[B[c]==1]\n",
    "B_Male = B_Male[c].count()\n",
    "B_Female = B[B[c]==0]\n",
    "B_Female = B_Female[c].count()\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {'Gender':['Male', 'Female'],\n",
    "        'White': [W_Male, W_Female], \n",
    "        'South Asian': [SA_Male, SA_Female],\n",
    "            'Black': [B_Male, B_Female]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[c,'White', 'South Asian', 'Black'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index('Gender', inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aebd0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1.69\n",
      "\n",
      "Difference is not significant, p:  0.4298 0.430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fisher's exact as n < 5 in at least one cell:\n",
    "\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193e5b0",
   "metadata": {},
   "source": [
    "# Age at assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c46f5",
   "metadata": {},
   "source": [
    "## PD patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7967a481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  68.5\n",
      "SD:  10.8\n",
      "\n",
      "White\n",
      "Mean:  70.2\n",
      "SD:  9.5\n",
      "\n",
      "South Asian\n",
      "Mean:  66.4\n",
      "SD:  11.4\n",
      "\n",
      "Black\n",
      "Mean:  71.1\n",
      "SD:  10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'Age'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "age = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\"  % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "age = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "age = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "age = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa85c0",
   "metadata": {},
   "source": [
    "## HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b322b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "HCs\n",
      "\n",
      "All\n",
      "Mean:  62.7\n",
      "SD:  10.9\n",
      "\n",
      "White\n",
      "Mean:  71.0\n",
      "SD:  8.2\n",
      "\n",
      "South Asian\n",
      "Mean:  58.4\n",
      "SD:  9.5\n",
      "\n",
      "Black\n",
      "Mean:  69.5\n",
      "SD:  6.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'Age'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('HCs')\n",
    "print('')\n",
    "print('All')\n",
    "age = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\"  % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "age = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "age = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "age = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f8e7e",
   "metadata": {},
   "source": [
    "## Significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73547e",
   "metadata": {},
   "source": [
    "PwP vs HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c111d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "Distribution\n",
      "All PwP\n",
      "Statistics = 0.980, p = 0.003\n",
      "Distribution is not normal\n",
      "\n",
      "All HCs\n",
      "Statistics = 0.971, p = 0.042\n",
      "Distribution is not normal\n",
      "\n",
      "Total PwP vs total HCs\n",
      "Statistics = 0.060, p = 0.807\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'Age'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('All PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Check that distribution is normal with Shapiro test\n",
    "df2 = ELPDH\n",
    "stat, p = st.shapiro(df2[a])\n",
    "print('All HCs')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "# Check that distribution is normal with Shapiro test\n",
    "stat, p = st.levene(df1[a], df2[a], center= 'mean')\n",
    "print('Total PwP vs total HCs')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16eb4b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All PwP vs all HCs\n",
      "Statistics = 12873.000, p = 0.00002\n",
      "Difference is significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('All PwP vs all HCs')\n",
    "stat, p = st.mannwhitneyu(x=df1[a], y=df2[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.5f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f97d1",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e5e5b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "PwP\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.985, p = 0.340\n",
      "Distribution is normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.980, p = 0.206\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.972, p = 0.724\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 2.861, p = 0.092\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.221, p = 0.639\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.394, p = 0.532\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'Age'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0824286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "White vs South Asian\n",
      "T:  6.1 DOF:  84.0\n",
      "Difference is not significant, p =  0.000\n",
      "\n",
      "White vs Black\n",
      "T:  0.2 DOF:  30.0\n",
      "Difference is significant, p =  0.808\n",
      "\n",
      "Black vs South Asian\n",
      "T:  1.6 DOF:  56.0\n",
      "Difference is significant, p =  0.110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution normal, variances equal, therefore use t-test:\n",
    "print('PwP')\n",
    "print('White vs South Asian')\n",
    "summary, results = rp.ttest(group1= W[a], group1_name= \"White\",\n",
    "                            group2= SA[a], group2_name= \"South Asian\")\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n",
    "\n",
    "print('White vs Black')\n",
    "summary, results = rp.ttest(group1= W[a], group1_name= \"White\",\n",
    "                            group2= B[a], group2_name= \"Black\")\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n",
    "\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group1_name= \"Black\",\n",
    "                            group2= SA[a], group2_name= \"South Asian\")\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ',\"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eaf650",
   "metadata": {},
   "source": [
    "# Age at diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e73ac7",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7563c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeDiagnosis\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  63.0\n",
      "SD:  11.6\n",
      "\n",
      "White\n",
      "Mean:  64.5\n",
      "SD:  11.0\n",
      "\n",
      "South Asian\n",
      "Mean:  61.0\n",
      "SD:  11.5\n",
      "\n",
      "Black\n",
      "Mean:  65.6\n",
      "SD:  11.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'AgeDiagnosis'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "age = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\"  % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "age = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "age = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "age = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa103d3",
   "metadata": {},
   "source": [
    "## SIgnificance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a5a9e",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc3093cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeDiagnosis\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.975, p = 0.001\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.965, p = 0.012\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.977, p = 0.140\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.944, p = 0.203\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.945, p = 0.332\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.392, p = 0.533\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.000, p = 0.997\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'AgeDiagnosis'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86df5567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 4818.000, p = 0.036\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1081.000, p = 0.643\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "No significant difference between groups, p =  0.088\n",
      "T:  1.7208\n",
      "DOF:  107.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group1_name= \"Black\",\n",
    "                            group2= SA[a], group2_name= \"South Asian\")\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('No significant difference between groups, p = ', \"%.3f\" % results.results[3])\n",
    "    print('T: ', results.results[2])\n",
    "    print('DOF: ', results.results[1])\n",
    "else:\n",
    "    print('Significant difference between groups, p = ', \"%.3f\" %  results.results[3])\n",
    "    print('T: ', results.results[2])\n",
    "    print('DOF: ', results.results[1])\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18eca2a",
   "metadata": {},
   "source": [
    "# Age at symptom onset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e4da7",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a80436e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeSymptomOnset\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  61.3\n",
      "SD:  12.0\n",
      "\n",
      "White\n",
      "Mean:  62.6\n",
      "SD:  11.3\n",
      "\n",
      "South Asian\n",
      "Mean:  59.2\n",
      "SD:  12.2\n",
      "\n",
      "Black\n",
      "Mean:  64.4\n",
      "SD:  11.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'AgeSymptomOnset'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "age = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\"  % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "age = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "age = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "age = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % age.mean())\n",
    "print(\"SD: \", \"%.1f\" % age.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2136a",
   "metadata": {},
   "source": [
    "## Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdfceac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeSymptomOnset\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.970, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.965, p = 0.011\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.973, p = 0.075\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.946, p = 0.221\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 1.678, p = 0.197\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.453, p = 0.502\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.027, p = 0.870\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'AgeSymptomOnset'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae7ec825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 4756.500, p = 0.055\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1050.000, p = 0.505\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "No significant difference between groups, p =  0.068\n",
      "T:  1.8474\n",
      "DOF:  107.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group1_name= \"Black\",\n",
    "                            group2= SA[a], group2_name= \"South Asian\")\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('No significant difference between groups, p = ', \"%.3f\" % results.results[3])\n",
    "    print('T: ', results.results[2])\n",
    "    print('DOF: ', results.results[1])\n",
    "else:\n",
    "    print('Significant difference between groups, p = ', \"%.3f\" %  results.results[3])\n",
    "    print('T: ', results.results[2])\n",
    "    print('DOF: ', results.results[1])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de3bee",
   "metadata": {},
   "source": [
    "# Time since diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6cc2bd",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f267e392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.879452\n",
       "1       5.901370\n",
       "2       2.460274\n",
       "3       1.312329\n",
       "4       6.652055\n",
       "         ...    \n",
       "213     2.800000\n",
       "214     0.652055\n",
       "215     7.936986\n",
       "216    12.158904\n",
       "217     3.460274\n",
       "Name: YearsSinceDiagnosis, Length: 218, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ELPDP\n",
    "df['YearsSinceDiagnosis'] = df['DaysSinceDiagnosis']/365\n",
    "df['YearsSinceDiagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3c97bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsSinceDiagnosis\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  5.9\n",
      "SD:  5.4\n",
      "Median:  4.8\n",
      "IQR:  6.9\n",
      "\n",
      "White\n",
      "Mean:  6.0\n",
      "SD:  6.0\n",
      "Median:  4.1\n",
      "IQR:  6.6\n",
      "\n",
      "South Asian\n",
      "Mean:  5.9\n",
      "SD:  4.9\n",
      "Median:  5.0\n",
      "IQR:  7.7\n",
      "\n",
      "Black\n",
      "Mean:  5.9\n",
      "SD:  4.2\n",
      "Median:  5.6\n",
      "IQR:  4.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'YearsSinceDiagnosis'\n",
    "b = 'Ethnicity'\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "duration = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % duration.mean())\n",
    "print(\"SD: \", \"%.1f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "duration = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % duration.mean())\n",
    "print(\"SD: \", \"%.1f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "duration = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % duration.mean())\n",
    "print(\"SD: \", \"%.1f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "duration = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % duration.mean())\n",
    "print(\"SD: \", \"%.1f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7088b",
   "metadata": {},
   "source": [
    "## Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91b28722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsSinceDiagnosis\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.866, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.812, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.917, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.933, p = 0.113\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.595, p = 0.441\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1.849, p = 0.176\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.528, p = 0.219\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'YearsSinceDiagnosis'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9e3b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 3961.500, p = 0.737\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1065.000, p = 0.570\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1049.500, p = 0.832\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39642a8",
   "metadata": {},
   "source": [
    "# Duration of symptoms on assessment / Disease duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf0a0c",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03d903e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3.882192\n",
       "1      11.572603\n",
       "2       3.463014\n",
       "3       2.479452\n",
       "4       8.402740\n",
       "         ...    \n",
       "213     7.912329\n",
       "214     2.684932\n",
       "215    10.539726\n",
       "216    12.542466\n",
       "217     7.704110\n",
       "Name: YearsSinceSymptomOnset, Length: 218, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ELPDP\n",
    "df['YearsSinceSymptomOnset'] = df['DaysSinceSymptomOnset']/365\n",
    "df['YearsSinceSymptomOnset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ed9b4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsSinceSymptomOnset\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  8\n",
      "SD:  6\n",
      "Median:  6.3\n",
      "IQR:  7.4\n",
      "\n",
      "White\n",
      "Mean:  8\n",
      "SD:  7\n",
      "Median:  6.0\n",
      "IQR:  7.6\n",
      "\n",
      "South Asian\n",
      "Mean:  8\n",
      "SD:  6\n",
      "Median:  6.8\n",
      "IQR:  7.3\n",
      "\n",
      "Black\n",
      "Mean:  7\n",
      "SD:  5\n",
      "Median:  6.5\n",
      "IQR:  3.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'YearsSinceSymptomOnset'\n",
    "b = 'Ethnicity'\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "duration = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "duration = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "duration = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "duration = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074d22e",
   "metadata": {},
   "source": [
    "## Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9052cfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsSinceSymptomOnset\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.851, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.831, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.862, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.877, p = 0.007\n",
      "Distribution is not normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.476, p = 0.491\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 2.760, p = 0.099\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.792, p = 0.183\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'YearsSinceSymptomOnset'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c0f3d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 4101.500, p = 0.952\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1141.000, p = 0.945\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1009.000, p = 0.939\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d729467",
   "metadata": {},
   "source": [
    "# Duration of symptoms at diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5f871",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "949b0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.002740\n",
       "1      5.671233\n",
       "2      1.002740\n",
       "3      1.167123\n",
       "4      1.750685\n",
       "         ...   \n",
       "213    5.112329\n",
       "214    2.032877\n",
       "215    2.602740\n",
       "216    0.383562\n",
       "217    4.243836\n",
       "Name: YearsSinceSymptomOnsetAtDiagnosis, Length: 218, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new variable\n",
    "a = 'DaysSinceSymptomOnsetAtDiagnosis'\n",
    "b = 'Ethnicity'\n",
    "c = 'DaysSinceDiagnosis'\n",
    "d = 'DaysSinceSymptomOnset'\n",
    "df = ELPDP\n",
    "\n",
    "df['DaysSinceSymptomOnsetAtDiagnosis'] = df[d] - df[c]\n",
    "df['DaysSinceSymptomOnsetAtDiagnosis']\n",
    "\n",
    "df['YearsSinceSymptomOnsetAtDiagnosis'] = df['DaysSinceSymptomOnsetAtDiagnosis']/365\n",
    "a = 'YearsSinceSymptomOnsetAtDiagnosis'\n",
    "df = df[df[a].notna()]\n",
    "df[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9ba8953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsSinceSymptomOnsetAtDiagnosis\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  2\n",
      "SD:  3\n",
      "Median:  1.0\n",
      "IQR:  1.6\n",
      "\n",
      "White\n",
      "Mean:  2\n",
      "SD:  2\n",
      "Median:  1.2\n",
      "IQR:  1.5\n",
      "\n",
      "South Asian\n",
      "Mean:  2\n",
      "SD:  4\n",
      "Median:  1.0\n",
      "IQR:  1.9\n",
      "\n",
      "Black\n",
      "Mean:  1\n",
      "SD:  1\n",
      "Median:  1.0\n",
      "IQR:  0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean  for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "duration = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "duration = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "duration = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "duration = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9176dd",
   "metadata": {},
   "source": [
    "## Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0f4bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsSinceSymptomOnsetAtDiagnosis\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.465, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.639, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.371, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.811, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.236, p = 0.627\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 2.944, p = 0.089\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.693, p = 0.196\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'YearsSinceSymptomOnsetAtDiagnosis'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c102cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 4561.500, p = 0.171\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1329.000, p = 0.247\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1026.000, p = 0.968\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26c641",
   "metadata": {},
   "source": [
    "# Comorbidities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6fd9ac",
   "metadata": {},
   "source": [
    "## HTN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537711eb",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87c155b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  216\n",
      "\n",
      "DaysSinceDiagnosis\n",
      "All\n",
      "n:  112\n",
      "%:  51.9\n",
      "\n",
      "White:  94\n",
      "n:  46\n",
      "%:  48.9\n",
      "\n",
      "South Asian:  85\n",
      "n:  44\n",
      "%:  51.8\n",
      "\n",
      "Black:  24\n",
      "n:  18\n",
      "%:  75.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'HTN'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "comorbidity = df[df[a]==1].count()\n",
    "print('')\n",
    "print(c)\n",
    "print('All')\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "comorbidity = W[W[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "comorbidity = SA[SA[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "comorbidity = B[B[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008b9a8",
   "metadata": {},
   "source": [
    "### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "484120a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  72\n",
      "\n",
      "DaysSinceDiagnosis\n",
      "All\n",
      "n:  30\n",
      "%:  41.7\n",
      "\n",
      "White:  29\n",
      "n:  13\n",
      "%:  44.8\n",
      "\n",
      "South Asian:  40\n",
      "n:  16\n",
      "%:  40.0\n",
      "\n",
      "Black:  1\n",
      "n:  1\n",
      "%:  100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'HTN'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "comorbidity = df[df[a]==1].count()\n",
    "print('')\n",
    "print(c)\n",
    "print('All')\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "comorbidity = W[W[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "comorbidity = SA[SA[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "comorbidity = B[B[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2641c9",
   "metadata": {},
   "source": [
    "### Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f71f5725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PwP  HC\n",
      "HTN             \n",
      "Present  112  30\n",
      "Absent   104  42\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "a = 'HTN'\n",
    "\n",
    "# Patients \n",
    "df = ELPDP\n",
    "present = df[df[a]==1]\n",
    "present_PwP = present[a].count()\n",
    "not_present =  df1[df1[a]==0]\n",
    "not_present_PwP = not_present[a].count()\n",
    "\n",
    "# Healthy controls\n",
    "df = ELPDH\n",
    "present = df[df[a]==1]\n",
    "present_HC = present[a].count()\n",
    "not_present =  df[df[a]==0]\n",
    "not_present_HC = not_present[a].count()\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {a:['Present', 'Absent'],\n",
    "        'PwP': [present_PwP, not_present_PwP], \n",
    "        'HC': [present_HC, not_present_HC]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[a,'PwP', 'HC'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index(a, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39165b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference\n",
      "\n",
      "T statistic:  1.852\n",
      "Degrees of freedom:  1\n",
      "p value: 0.174\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "print('Difference')\n",
    "print('')\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "#Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.3f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2f47d",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1386524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "HTN                               \n",
      "Present     46           44     18\n",
      "Absent      48           41      6\n"
     ]
    }
   ],
   "source": [
    "a = 'HTN'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "present = W[W[a]==1]\n",
    "W_present = present[a].count()\n",
    "not_present =  W[W[a]==0]\n",
    "W_not_present = not_present[a].count()\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "present = SA[SA[a]==1]\n",
    "SA_present = present[a].count()\n",
    "not_present =  SA[SA[a]==0]\n",
    "SA_not_present = not_present[a].count()\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "present = B[B[a]==1]\n",
    "B_present = present[a].count()\n",
    "not_present =  B[B[a]==0]\n",
    "B_not_present = not_present[a].count()\n",
    "\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {a:['Present', 'Absent'],\n",
    "        'White': [W_present, W_not_present], \n",
    "        'South Asian': [SA_present, SA_not_present],\n",
    "            'Black' : [B_present, B_not_present]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[a,'White', 'South Asian', 'Black'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index(a, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e36a1034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference\n",
      "\n",
      "T statistic:  5.338\n",
      "Degrees of freedom:  2\n",
      "p value: 0.069\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "print('Difference')\n",
    "print('')\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "#Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.3f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd47f2",
   "metadata": {},
   "source": [
    "## T2DM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9ce8c",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4127b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  216\n",
      "\n",
      "DaysSinceDiagnosis\n",
      "All\n",
      "n:  68\n",
      "%:  31.5\n",
      "\n",
      "White:  95\n",
      "n:  23\n",
      "%:  24.2\n",
      "\n",
      "South Asian:  85\n",
      "n:  39\n",
      "%:  45.9\n",
      "\n",
      "Black:  23\n",
      "n:  6\n",
      "%:  26.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'T2DM'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "comorbidity = df[df[a]==1].count()\n",
    "print('')\n",
    "print(c)\n",
    "print('All')\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "comorbidity = W[W[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "comorbidity = SA[SA[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "comorbidity = B[B[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc76bc",
   "metadata": {},
   "source": [
    "### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f28b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  72\n",
      "\n",
      "DaysSinceDiagnosis\n",
      "All\n",
      "n:  21\n",
      "%:  29.2\n",
      "\n",
      "White:  29\n",
      "n:  1\n",
      "%:  3.4\n",
      "\n",
      "South Asian:  40\n",
      "n:  20\n",
      "%:  50.0\n",
      "\n",
      "Black:  1\n",
      "n:  0\n",
      "%:  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'T2DM'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "comorbidity = df[df[a]==1].count()\n",
    "print('')\n",
    "print(c)\n",
    "print('All')\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "comorbidity = W[W[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "comorbidity = SA[SA[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "comorbidity = B[B[a]==1].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9b29c",
   "metadata": {},
   "source": [
    "### Signficance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db37bcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PwP  HC\n",
      "T2DM            \n",
      "Present   68  21\n",
      "Absent   148  51\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "a = 'T2DM'\n",
    "\n",
    "# Patients \n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "present = df[df[a]==1]\n",
    "present_PwP = present[a].count()\n",
    "not_present =  df1[df1[a]==0]\n",
    "not_present_PwP = not_present[a].count()\n",
    "\n",
    "# Healthy controls\n",
    "df = ELPDH\n",
    "df = df[df[a].notna()]\n",
    "present = df[df[a]==1]\n",
    "present_HC = present[a].count()\n",
    "not_present =  df[df[a]==0]\n",
    "not_present_HC = not_present[a].count()\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {a:['Present', 'Absent'],\n",
    "        'PwP': [present_PwP, not_present_PwP], \n",
    "        'HC': [present_HC, not_present_HC]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[a,'PwP', 'HC'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index(a, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c9ddeba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference\n",
      "\n",
      "T statistic:  0.049\n",
      "Degrees of freedom:  1\n",
      "p value: 0.825\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "print('Difference')\n",
    "print('')\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "#Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.3f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95f20a",
   "metadata": {},
   "source": [
    "## Smoking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc717f",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc453f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  212\n",
      "\n",
      "DaysSinceDiagnosis - combined previous and current\n",
      "All\n",
      "n:  61\n",
      "%:  28.8\n",
      "\n",
      "White:  93\n",
      "n:  35\n",
      "%:  37.6\n",
      "\n",
      "South Asian:  85\n",
      "n:  18\n",
      "%:  21.2\n",
      "\n",
      "Black:  22\n",
      "n:  4\n",
      "%:  18.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'Smoking'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "comorbidity = df[(df[a] == 1) | (df[a] == 2)].count()\n",
    "print('')\n",
    "print(c, '- combined previous and current')\n",
    "print('All')\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "comorbidity = W[(W[a] == 1) | (W[a] == 2)].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "comorbidity = SA[(SA[a] == 1) | (SA[a] == 2)].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "comorbidity = B[(B[a] == 1) | (B[a] == 2)].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4acb58",
   "metadata": {},
   "source": [
    "### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35749bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "All:  15\n",
      "\n",
      "DaysSinceDiagnosis - combined previous and current\n",
      "All\n",
      "n:  2\n",
      "%:  13.3\n",
      "\n",
      "White:  1\n",
      "n:  0\n",
      "%:  0.0\n",
      "\n",
      "South Asian:  14\n",
      "n:  2\n",
      "%:  14.3\n",
      "\n",
      "Black:  0\n",
      "n:  0\n",
      "%:  nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3897019936.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  Percentage = comorbidity[a] / B[a].count() * 100\n"
     ]
    }
   ],
   "source": [
    "a = 'Smoking'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "print('All: ', df[a].count())\n",
    "comorbidity = df[(df[a] == 1) | (df[a] == 2)].count()\n",
    "print('')\n",
    "print(c, '- combined previous and current')\n",
    "print('All')\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "comorbidity = W[(W[a] == 1) | (W[a] == 2)].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "comorbidity = SA[(SA[a] == 1) | (SA[a] == 2)].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "comorbidity = B[(B[a] == 1) | (B[a] == 2)].count()\n",
    "print('n: ', comorbidity[a])\n",
    "Percentage = comorbidity[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0232f37",
   "metadata": {},
   "source": [
    "### Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad4cc2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PwP  HC\n",
      "Smoking         \n",
      "Present   61   2\n",
      "Absent   151  13\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "a = 'Smoking'\n",
    "\n",
    "# Patients \n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "present = df[(df[a] == 1) | (df[a] == 2)]\n",
    "present_PwP = present[a].count()\n",
    "not_present =  df1[df1[a]==0]\n",
    "not_present_PwP = not_present[a].count()\n",
    "\n",
    "# Healthy controls\n",
    "df = ELPDH\n",
    "df = df[df[a].notna()]\n",
    "present = df[(df[a] == 1) | (df[a] == 2)]\n",
    "present_HC = present[a].count()\n",
    "not_present =  df[df[a]==0]\n",
    "not_present_HC = not_present[a].count()\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {a:['Present', 'Absent'],\n",
    "        'PwP': [present_PwP, not_present_PwP], \n",
    "        'HC': [present_HC, not_present_HC]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[a,'PwP', 'HC'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index(a, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "667a7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1.67\n",
      "\n",
      "Difference is not significant, p:  0.1968 0.197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fisher's exact as n < 5 in at least one cell:\n",
    "\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18df1e",
   "metadata": {},
   "source": [
    "# LEDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4db0bd",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c180817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEDD_ADJUSTED_2\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  626\n",
      "SD:  500\n",
      "Median:  510\n",
      "IQR:  525\n",
      "\n",
      "White\n",
      "Mean:  643\n",
      "SD:  615\n",
      "Median:  481\n",
      "IQR:  503\n",
      "\n",
      "South Asian\n",
      "Mean:  640\n",
      "SD:  393\n",
      "Median:  625\n",
      "IQR:  535\n",
      "\n",
      "Black\n",
      "Mean:  562\n",
      "SD:  347\n",
      "Median:  510\n",
      "IQR:  363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'LEDD_ADJUSTED_3'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean  for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "duration = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "duration = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "duration = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "duration = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e60bc5",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "86a6dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEDD_ADJUSTED_2\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.796, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.708, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.956, p = 0.006\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.865, p = 0.004\n",
      "Distribution is not normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 1.637, p = 0.202\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 2.030, p = 0.157\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.764, p = 0.187\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'LEDD_ADJUSTED_3'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a081939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 3705.000, p = 0.286\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1140.500, p = 0.942\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 902.000, p = 0.390\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28267a0",
   "metadata": {},
   "source": [
    "# UPDRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c09e2",
   "metadata": {},
   "source": [
    "## UPDRS I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce3187",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e85edde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part1Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  16.2\n",
      "SD:  8.8\n",
      "\n",
      "White\n",
      "Mean:  14.6\n",
      "SD:  7.7\n",
      "\n",
      "South Asian\n",
      "Mean:  18.7\n",
      "SD:  9.6\n",
      "\n",
      "Black\n",
      "Mean:  15.4\n",
      "SD:  7.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'UPDRS_Part1Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 52), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7f99f",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c960d120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part1Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.953, p = 0.002\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.980, p = 0.254\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.918, p = 0.060\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 5.558, p = 0.020\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.425, p = 0.516\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.901, p = 0.345\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'UPDRS_Part1Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "febf5515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 8.436, p = 0.0037\n",
      "Difference is significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 968.000, p = 0.635\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  -1.5 DOF:  99.0\n",
      "Difference is not significant, p =  0.137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.4f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac994d5",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2bc4b27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  168\n",
      "White and Black PD patients count:  113\n",
      "Black and South Asian PD patients count:  101\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9d153cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome  White vs South Asian, exposure  UPDRS_Part1Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    90\n",
      "0    78\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680320\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  168\n",
      "Model:                          Logit   Df Residuals:                      166\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01488\n",
      "Time:                        13:47:27   Log-Likelihood:                -114.29\n",
      "converged:                       True   LL-Null:                       -116.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06318\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part1Total         -0.0233      0.013     -1.835      0.067      -0.048       0.002\n",
      "DaysSinceSymptomOnset     0.0001   6.85e-05      1.890      0.059   -4.77e-06       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.06656881813598853\n",
      "\n",
      "Outcome  White vs South Asian, exposure  UPDRS_Part1Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    90\n",
      "0    78\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648167\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  168\n",
      "Model:                          Logit   Df Residuals:                      164\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.06144\n",
      "Time:                        13:47:27   Log-Likelihood:                -108.89\n",
      "converged:                       True   LL-Null:                       -116.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.002577\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part1Total         -0.0658      0.019     -3.453      0.001      -0.103      -0.028\n",
      "DaysSinceSymptomOnset  3.741e-05   7.19e-05      0.520      0.603      -0.000       0.000\n",
      "Age                       0.0182      0.006      2.983      0.003       0.006       0.030\n",
      "Gender                   -0.1159      0.327     -0.354      0.723      -0.758       0.526\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0005552440180626795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3006853217.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('Outcome ','White vs South Asian,', 'exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Outcome ','White vs South Asian,', 'exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7a5a39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  UPDRS_Part1Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    90\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534139\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  113\n",
      "Model:                          Logit   Df Residuals:                      111\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.05713\n",
      "Time:                        13:47:33   Log-Likelihood:                -60.358\n",
      "converged:                       True   LL-Null:                       -57.096\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part1Total          0.0447      0.021      2.092      0.036       0.003       0.087\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.730      0.084   -2.55e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.03644634013471674\n",
      "\n",
      "Exposure  UPDRS_Part1Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    90\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500601\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  113\n",
      "Model:                          Logit   Df Residuals:                      109\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.009243\n",
      "Time:                        13:47:33   Log-Likelihood:                -56.568\n",
      "converged:                       True   LL-Null:                       -57.096\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7878\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part1Total         -0.0114      0.029     -0.395      0.693      -0.068       0.045\n",
      "DaysSinceSymptomOnset  7.282e-05      0.000      0.644      0.520      -0.000       0.000\n",
      "Age                       0.0140      0.008      1.717      0.086      -0.002       0.030\n",
      "Gender                    0.5811      0.468      1.242      0.214      -0.336       1.498\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.6926214604183496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2164510637.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c3747bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  UPDRS_Part1Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    78\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531284\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  101\n",
      "Model:                          Logit   Df Residuals:                       99\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.009741\n",
      "Time:                        13:47:34   Log-Likelihood:                -53.660\n",
      "converged:                       True   LL-Null:                       -54.188\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3042\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part1Total          0.0624      0.022      2.875      0.004       0.020       0.105\n",
      "DaysSinceSymptomOnset   2.54e-05      0.000      0.211      0.833      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.004045550814776264\n",
      "\n",
      "Exposure  UPDRS_Part1Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    78\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.517095\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  101\n",
      "Model:                          Logit   Df Residuals:                       97\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03619\n",
      "Time:                        13:47:34   Log-Likelihood:                -52.227\n",
      "converged:                       True   LL-Null:                       -54.188\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2700\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part1Total          0.0535      0.029      1.827      0.068      -0.004       0.111\n",
      "DaysSinceSymptomOnset -9.858e-06      0.000     -0.076      0.939      -0.000       0.000\n",
      "Age                      -0.0023      0.008     -0.283      0.777      -0.018       0.014\n",
      "Gender                    0.7562      0.459      1.646      0.100      -0.144       1.657\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.06777445460701464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fe2e4",
   "metadata": {},
   "source": [
    "## UPDRS II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5b2fd",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "37734799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part2Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  19.5\n",
      "SD:  11.0\n",
      "\n",
      "White\n",
      "Mean:  16.1\n",
      "SD:  9.2\n",
      "\n",
      "South Asian\n",
      "Mean:  23.5\n",
      "SD:  11.7\n",
      "\n",
      "Black\n",
      "Mean:  21.8\n",
      "SD:  9.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'UPDRS_Part2Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 52), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9c8b5",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b19dca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part2Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.956, p = 0.003\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.976, p = 0.126\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.970, p = 0.685\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 6.647, p = 0.011\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.437, p = 0.510\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.070, p = 0.303\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'UPDRS_Part2Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "edc2f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 18.165, p = 0.000\n",
      "Difference is significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 704.500, p = 0.012\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  -0.6 DOF:  103.0\n",
      "Difference is not significant, p =  0.519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848282e",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ada847d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  175\n",
      "White and Black PD patients count:  116\n",
      "Black and South Asian PD patients count:  105\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d9c2537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  UPDRS_Part2Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    93\n",
      "0    82\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651169\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  175\n",
      "Model:                          Logit   Df Residuals:                      173\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05788\n",
      "Time:                        13:47:57   Log-Likelihood:                -113.95\n",
      "converged:                       True   LL-Null:                       -120.95\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001828\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part2Total         -0.0436      0.013     -3.426      0.001      -0.068      -0.019\n",
      "DaysSinceSymptomOnset     0.0003   8.39e-05      3.184      0.001       0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0006119100830201364\n",
      "\n",
      "Exposure  UPDRS_Part2Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    93\n",
      "0    82\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600922\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  175\n",
      "Model:                          Logit   Df Residuals:                      171\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1306\n",
      "Time:                        13:47:57   Log-Likelihood:                -105.16\n",
      "converged:                       True   LL-Null:                       -120.95\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.395e-07\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part2Total         -0.0897      0.018     -4.911      0.000      -0.126      -0.054\n",
      "DaysSinceSymptomOnset     0.0002   8.38e-05      1.980      0.048    1.66e-06       0.000\n",
      "Age                       0.0210      0.006      3.500      0.000       0.009       0.033\n",
      "Gender                    0.0394      0.339      0.116      0.908      -0.625       0.704\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  9.077736387107153e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "10b54cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  UPDRS_Part2Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    93\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543494\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      114\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.09135\n",
      "Time:                        13:47:58   Log-Likelihood:                -63.045\n",
      "converged:                       True   LL-Null:                       -57.768\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part2Total         -0.0009      0.019     -0.048      0.962      -0.038       0.036\n",
      "DaysSinceSymptomOnset     0.0004      0.000      2.900      0.004       0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.9618439939148492\n",
      "\n",
      "Exposure  UPDRS_Part2Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    93\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.452658\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      112\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.09105\n",
      "Time:                        13:47:58   Log-Likelihood:                -52.508\n",
      "converged:                       True   LL-Null:                       -57.768\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01463\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part2Total         -0.0811      0.029     -2.818      0.005      -0.138      -0.025\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.581      0.114   -5.15e-05       0.000\n",
      "Age                       0.0253      0.009      2.921      0.003       0.008       0.042\n",
      "Gender                    0.8900      0.501      1.775      0.076      -0.093       1.873\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.004837251031650531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2164510637.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b5eaa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  UPDRS_Part2Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    82\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539436\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  105\n",
      "Model:                          Logit   Df Residuals:                      103\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.02613\n",
      "Time:                        13:47:59   Log-Likelihood:                -56.641\n",
      "converged:                       True   LL-Null:                       -55.198\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part2Total          0.0434      0.017      2.481      0.013       0.009       0.078\n",
      "DaysSinceSymptomOnset  5.749e-05      0.000      0.432      0.666      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.01311534046547703\n",
      "\n",
      "Exposure  UPDRS_Part2Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    82\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.520491\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  105\n",
      "Model:                          Logit   Df Residuals:                      101\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.009909\n",
      "Time:                        13:47:59   Log-Likelihood:                -54.652\n",
      "converged:                       True   LL-Null:                       -55.198\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7785\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part2Total          0.0220      0.024      0.923      0.356      -0.025       0.069\n",
      "DaysSinceSymptomOnset  1.046e-05      0.000      0.078      0.938      -0.000       0.000\n",
      "Age                       0.0036      0.008      0.433      0.665      -0.013       0.020\n",
      "Gender                    0.7650      0.451      1.695      0.090      -0.120       1.650\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.3557562938840928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b2deb",
   "metadata": {},
   "source": [
    "## UPDRS III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ceabc",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0b192bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "UPDRS_Part3Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  38.6\n",
      "SD:  18.1\n",
      "\n",
      "White\n",
      "Mean:  35.2\n",
      "SD:  16.4\n",
      "\n",
      "South Asian\n",
      "Mean:  42.2\n",
      "SD:  18.8\n",
      "\n",
      "Black\n",
      "Mean:  47.0\n",
      "SD:  16.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'UPDRS_Part3Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 132), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893e80a",
   "metadata": {},
   "source": [
    "### Signifcance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8af4d828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part3Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.937, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.976, p = 0.155\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.939, p = 0.153\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 1.205, p = 0.274\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.003, p = 0.958\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.523, p = 0.471\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'UPDRS_Part3Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6c41838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 2797.000, p = 0.013\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 650.500, p = 0.002\n",
      "Difference is significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  1.1 DOF:  100.0\n",
      "Difference is not significant, p =  0.266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a62b5",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0117431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  170\n",
      "White and Black PD patients count:  116\n",
      "Black and South Asian PD patients count:  102\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a1ad09d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    92\n",
      "0    78\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683263\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  170\n",
      "Model:                          Logit   Df Residuals:                      168\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.009409\n",
      "Time:                        13:48:21   Log-Likelihood:                -116.15\n",
      "converged:                       True   LL-Null:                       -117.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1374\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0083      0.006     -1.446      0.148      -0.020       0.003\n",
      "DaysSinceSymptomOnset     0.0001   6.85e-05      1.769      0.077   -1.31e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.14826240558763543\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    92\n",
      "0    78\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651230\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  170\n",
      "Model:                          Logit   Df Residuals:                      166\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05585\n",
      "Time:                        13:48:21   Log-Likelihood:                -110.71\n",
      "converged:                       True   LL-Null:                       -117.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.004430\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0325      0.010     -3.324      0.001      -0.052      -0.013\n",
      "DaysSinceSymptomOnset  5.489e-05   7.11e-05      0.772      0.440   -8.45e-05       0.000\n",
      "Age                       0.0191      0.007      2.928      0.003       0.006       0.032\n",
      "Gender                    0.0110      0.321      0.034      0.973      -0.618       0.640\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0008872921992233357\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    92\n",
      "0    78\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651214\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  170\n",
      "Model:                          Logit   Df Residuals:                      165\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05587\n",
      "Time:                        13:48:21   Log-Likelihood:                -110.71\n",
      "converged:                       True   LL-Null:                       -117.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01078\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0325      0.010     -3.319      0.001      -0.052      -0.013\n",
      "DaysSinceSymptomOnset  5.769e-05   8.07e-05      0.715      0.475      -0.000       0.000\n",
      "Age                       0.0192      0.007      2.907      0.004       0.006       0.032\n",
      "Gender                    0.0142      0.324      0.044      0.965      -0.620       0.649\n",
      "LEDD_ADJUSTED_2       -2.508e-05      0.000     -0.074      0.941      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0009030256589401362\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    92\n",
      "0    78\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624569\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  164\n",
      "Model:                          Logit   Df Residuals:                      159\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.09651\n",
      "Time:                        13:48:21   Log-Likelihood:                -102.43\n",
      "converged:                       True   LL-Null:                       -113.37\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002114\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total                 -0.0362      0.011     -3.433      0.001      -0.057      -0.016\n",
      "DaysSinceSymptomOnset             0.0001   7.66e-05      1.478      0.139   -3.69e-05       0.000\n",
      "Age                               0.0312      0.009      3.640      0.000       0.014       0.048\n",
      "Gender                            0.1372      0.338      0.406      0.685      -0.525       0.799\n",
      "UPDRS_3b_CurrentClinicalState    -1.2070      0.472     -2.558      0.011      -2.132      -0.282\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.0005979900489377537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2428004995.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "df1 = df1[df1[f].notna()]\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "769cd6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    92\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551549\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      114\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.08186\n",
      "Time:                        13:48:22   Log-Likelihood:                -63.980\n",
      "converged:                       True   LL-Null:                       -59.139\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total          0.0031      0.009      0.349      0.727      -0.014       0.020\n",
      "DaysSinceSymptomOnset     0.0003      0.000      2.628      0.009    8.76e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.7270954522286934\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    92\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.451060\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      112\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1152\n",
      "Time:                        13:48:22   Log-Likelihood:                -52.323\n",
      "converged:                       True   LL-Null:                       -59.139\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.003453\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0507      0.015     -3.279      0.001      -0.081      -0.020\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.620      0.105   -4.48e-05       0.000\n",
      "Age                       0.0310      0.010      3.221      0.001       0.012       0.050\n",
      "Gender                    1.0765      0.502      2.143      0.032       0.092       2.061\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0010412527574922275\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    92\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.450960\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      111\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1154\n",
      "Time:                        13:48:22   Log-Likelihood:                -52.311\n",
      "converged:                       True   LL-Null:                       -59.139\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.008483\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0505      0.015     -3.259      0.001      -0.081      -0.020\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.415      0.157   -7.86e-05       0.000\n",
      "Age                       0.0307      0.010      3.130      0.002       0.011       0.050\n",
      "Gender                    1.0680      0.506      2.112      0.035       0.077       2.059\n",
      "LEDD_ADJUSTED_2        7.274e-05      0.000      0.150      0.881      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.001117393620447408\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    92\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.450040\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1380\n",
      "Time:                        13:48:22   Log-Likelihood:                -49.954\n",
      "converged:                       True   LL-Null:                       -57.951\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.003030\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total                 -0.0570      0.017     -3.442      0.001      -0.089      -0.025\n",
      "DaysSinceSymptomOnset             0.0002      0.000      1.496      0.135   -6.32e-05       0.000\n",
      "Age                               0.0294      0.011      2.633      0.008       0.008       0.051\n",
      "Gender                            1.2206      0.526      2.321      0.020       0.190       2.251\n",
      "UPDRS_3b_CurrentClinicalState     0.3010      0.551      0.546      0.585      -0.780       1.382\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.0005776540198522105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1570576919.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "df1 = df1[df1[f].notna()]\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "71b3571d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    78\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.572575\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  102\n",
      "Model:                          Logit   Df Residuals:                      100\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.04945\n",
      "Time:                        13:48:22   Log-Likelihood:                -58.403\n",
      "converged:                       True   LL-Null:                       -55.651\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total          0.0114      0.008      1.415      0.157      -0.004       0.027\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.497      0.134   -5.75e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.15704922437306337\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    78\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542193\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  102\n",
      "Model:                          Logit   Df Residuals:                       98\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.006235\n",
      "Time:                        13:48:22   Log-Likelihood:                -55.304\n",
      "converged:                       True   LL-Null:                       -55.651\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8746\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0097      0.014     -0.718      0.473      -0.036       0.017\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.810      0.418      -0.000       0.000\n",
      "Age                       0.0118      0.010      1.217      0.224      -0.007       0.031\n",
      "Gender                    0.8178      0.446      1.833      0.067      -0.057       1.692\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.47268511425041726\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    78\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537646\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  102\n",
      "Model:                          Logit   Df Residuals:                       97\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01457\n",
      "Time:                        13:48:22   Log-Likelihood:                -54.840\n",
      "converged:                       True   LL-Null:                       -55.651\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8049\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total         -0.0124      0.014     -0.886      0.376      -0.040       0.015\n",
      "DaysSinceSymptomOnset  1.741e-05      0.000      0.120      0.905      -0.000       0.000\n",
      "Age                       0.0108      0.010      1.100      0.271      -0.008       0.030\n",
      "Gender                    0.7157      0.456      1.568      0.117      -0.179       1.610\n",
      "LEDD_ADJUSTED_2           0.0008      0.001      0.949      0.342      -0.001       0.003\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.3755923247116212\n",
      "\n",
      "Exposure  UPDRS_Part3Total  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    78\n",
      "0    24\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512953\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  101\n",
      "Model:                          Logit   Df Residuals:                       96\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.06451\n",
      "Time:                        13:48:22   Log-Likelihood:                -51.808\n",
      "converged:                       True   LL-Null:                       -55.381\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1284\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "UPDRS_Part3Total                 -0.0123      0.014     -0.889      0.374      -0.039       0.015\n",
      "DaysSinceSymptomOnset         -1.849e-05      0.000     -0.142      0.887      -0.000       0.000\n",
      "Age                               0.0007      0.011      0.064      0.949      -0.020       0.022\n",
      "Gender                            0.6520      0.466      1.398      0.162      -0.262       1.566\n",
      "UPDRS_3b_CurrentClinicalState     1.5960      0.626      2.549      0.011       0.369       2.823\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.3742118255379332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1883674105.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1883674105.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "df1 = df1[df1[f].notna()]\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4bfc3",
   "metadata": {},
   "source": [
    "### OFF vs ON state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1b0ca3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "\n",
      "DaysSinceSymptomOnset\n",
      "All:  201\n",
      "n:  36\n",
      "%:  17.9\n",
      "\n",
      "White:  87\n",
      "n:  20\n",
      "%:  23.0\n",
      "\n",
      "South Asian:  77\n",
      "n:  8\n",
      "%:  10.4\n",
      "\n",
      "Black:  24\n",
      "n:  7\n",
      "%:  29.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df\n",
    "a = 'UPDRS_3b_CurrentClinicalState'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "# Percentage:\n",
    "print('PwP')\n",
    "off = df[df[a]==0].count()\n",
    "print('')\n",
    "print(c)\n",
    "print('All: ', df[a].count())\n",
    "print('n: ', off[a])\n",
    "Percentage = off[a] / df[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "W = df[df[b]==1]\n",
    "print('White: ', W[a].count())\n",
    "W_off = W[W[a]==0].count()\n",
    "print('n: ', W_off[a])\n",
    "Percentage = W_off[a] / W[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "SA = df[df[b]==3]\n",
    "print('South Asian: ', SA[a].count())\n",
    "SA_off = SA[SA[a]==0].count()\n",
    "print('n: ', SA_off[a])\n",
    "Percentage = SA_off[a] / SA[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')\n",
    "\n",
    "\n",
    "B = df[df[b]==2]\n",
    "print('Black: ', B[a].count())\n",
    "B_off = B[B[a]==0].count()\n",
    "print('n: ', B_off[a])\n",
    "Percentage = B_off[a] / B[a].count() * 100\n",
    "print('%: ', \"%.1f\" % Percentage)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e48de9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               White  South Asian  Black\n",
      "UPDRS_3b_CurrentClinicalState                           \n",
      "On                                20            8      7\n",
      "Off                               67           69     17\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "W_off = W[W[a]==0]\n",
    "W_off = W_off[a].count()\n",
    "W_on = W[W[a]==1]\n",
    "W_on = W_on[a].count()\n",
    "\n",
    "SA_off = SA[SA[a]==0]\n",
    "SA_off =SA_off[a].count()\n",
    "SA_on = SA[SA[a]==1]\n",
    "SA_on = SA_on[a].count()\n",
    "\n",
    "\n",
    "B_off = B[B[a]==0]\n",
    "B_off =B_off[a].count()\n",
    "B_on = B[B[a]==1]\n",
    "B_on = B_on[a].count()\n",
    "\n",
    "\n",
    "# initialize data of lists\n",
    "data_cont = {a:['On', 'Off'],\n",
    "        'White': [W_off, W_on], \n",
    "        'South Asian': [SA_off, SA_on],\n",
    "            'Black': [B_off, B_on]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=[a,'White', 'South Asian', 'Black'])\n",
    "\n",
    "# set the index to the 'name' column\n",
    "data_cont.set_index(a, inplace=True)\n",
    "\n",
    "# reset the index\n",
    "data_cont.reset_index(inplace=False)\n",
    "\n",
    "# print dataframe\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "51bf1088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T statistic:  6.300\n",
      "Degrees of freedom:  2\n",
      "p value: 0.0428\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Chi-squared\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.004\n",
    "print(\"p value: \" + str(\"%.4f\" % p))\n",
    "if p < alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73b1b1",
   "metadata": {},
   "source": [
    "## UPDRS IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe919d",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "80ae4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part4Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  4.3\n",
      "SD:  4.3\n",
      "\n",
      "White\n",
      "Mean:  3.5\n",
      "SD:  3.7\n",
      "\n",
      "South Asian\n",
      "Mean:  4.8\n",
      "SD:  4.7\n",
      "\n",
      "Black\n",
      "Mean:  6.0\n",
      "SD:  3.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'UPDRS_Part4Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 44), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95622bba",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "374955b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part4Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.857, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.875, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.949, p = 0.276\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 6.286, p = 0.013\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.003, p = 0.958\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 2.081, p = 0.152\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'UPDRS_Part4Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8b4918bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 2.554, p = 0.110\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 643.000, p = 0.006\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1055.000, p = 0.160\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08454fd9",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d4d46fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  165\n",
      "White and Black PD patients count:  111\n",
      "Black and South Asian PD patients count:  100\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3c5c2e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    88\n",
      "0    77\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681946\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  165\n",
      "Model:                          Logit   Df Residuals:                      163\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01299\n",
      "Time:                        13:49:15   Log-Likelihood:                -112.52\n",
      "converged:                       True   LL-Null:                       -114.00\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.08521\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.0674      0.038     -1.761      0.078      -0.142       0.008\n",
      "DaysSinceSymptomOnset     0.0001   6.28e-05      1.677      0.093   -1.77e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.07829755907044532\n",
      "\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    88\n",
      "0    77\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.672669\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  165\n",
      "Model:                          Logit   Df Residuals:                      161\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02642\n",
      "Time:                        13:49:15   Log-Likelihood:                -110.99\n",
      "converged:                       True   LL-Null:                       -114.00\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1104\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.0851      0.040     -2.138      0.033      -0.163      -0.007\n",
      "DaysSinceSymptomOnset   3.05e-05   7.43e-05      0.410      0.682      -0.000       0.000\n",
      "Age                       0.0077      0.005      1.619      0.105      -0.002       0.017\n",
      "Gender                   -0.1415      0.320     -0.442      0.658      -0.768       0.485\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.03253545848179707\n",
      "\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    88\n",
      "0    77\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.671999\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  165\n",
      "Model:                          Logit   Df Residuals:                      160\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02739\n",
      "Time:                        13:49:15   Log-Likelihood:                -110.88\n",
      "converged:                       True   LL-Null:                       -114.00\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1816\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.0924      0.043     -2.157      0.031      -0.176      -0.008\n",
      "DaysSinceSymptomOnset  1.659e-05   7.99e-05      0.208      0.835      -0.000       0.000\n",
      "Age                       0.0073      0.005      1.509      0.131      -0.002       0.017\n",
      "Gender                   -0.1577      0.322     -0.489      0.625      -0.789       0.474\n",
      "LEDD_ADJUSTED_2           0.0002      0.000      0.464      0.643      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.031018817576914468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2464278909.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "df1 = df1[df1[f].notna()]\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "aae8cb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    88\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514782\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      109\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:               -0.008916\n",
      "Time:                        13:49:16   Log-Likelihood:                -57.141\n",
      "converged:                       True   LL-Null:                       -56.636\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.1888      0.073     -2.581      0.010      -0.332      -0.045\n",
      "DaysSinceSymptomOnset     0.0007      0.000      4.306      0.000       0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.009850460273532959\n",
      "\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    88\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.451415\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      107\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1153\n",
      "Time:                        13:49:16   Log-Likelihood:                -50.107\n",
      "converged:                       True   LL-Null:                       -56.636\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.004514\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.2352      0.076     -3.104      0.002      -0.384      -0.087\n",
      "DaysSinceSymptomOnset     0.0004      0.000      2.106      0.035    2.56e-05       0.001\n",
      "Age                       0.0137      0.007      1.874      0.061      -0.001       0.028\n",
      "Gender                    0.8214      0.492      1.668      0.095      -0.144       1.786\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0019098176229055928\n",
      "\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    88\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442376\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1330\n",
      "Time:                        13:49:16   Log-Likelihood:                -49.104\n",
      "converged:                       True   LL-Null:                       -56.636\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.004570\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.2675      0.081     -3.301      0.001      -0.426      -0.109\n",
      "DaysSinceSymptomOnset     0.0003      0.000      1.538      0.124   -7.87e-05       0.001\n",
      "Age                       0.0122      0.007      1.642      0.101      -0.002       0.027\n",
      "Gender                    0.7579      0.504      1.503      0.133      -0.231       1.746\n",
      "LEDD_ADJUSTED_2           0.0009      0.001      1.111      0.267      -0.001       0.002\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0009637258756271812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\108281127.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "df1 = df1[df1[f].notna()]\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7c701d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    77\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.559455\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       98\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.03742\n",
      "Time:                        13:49:17   Log-Likelihood:                -55.945\n",
      "converged:                       True   LL-Null:                       -53.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.0489      0.058     -0.837      0.403      -0.164       0.066\n",
      "DaysSinceSymptomOnset     0.0005      0.000      3.152      0.002       0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.4025805517870087\n",
      "\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    77\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.519905\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       96\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03592\n",
      "Time:                        13:49:17   Log-Likelihood:                -51.990\n",
      "converged:                       True   LL-Null:                       -53.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2754\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.0799      0.061     -1.314      0.189      -0.199       0.039\n",
      "DaysSinceSymptomOnset     0.0003      0.000      1.478      0.139   -8.41e-05       0.001\n",
      "Age                       0.0052      0.007      0.721      0.471      -0.009       0.019\n",
      "Gender                    0.9506      0.458      2.075      0.038       0.053       1.849\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.1888675776638502\n",
      "\n",
      "Exposure  UPDRS_Part4Total  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    77\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509922\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       95\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05443\n",
      "Time:                        13:49:17   Log-Likelihood:                -50.992\n",
      "converged:                       True   LL-Null:                       -53.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2090\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "UPDRS_Part4Total         -0.1068      0.064     -1.681      0.093      -0.231       0.018\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.675      0.500      -0.000       0.000\n",
      "Age                       0.0027      0.007      0.369      0.712      -0.012       0.017\n",
      "Gender                    0.7591      0.477      1.591      0.112      -0.176       1.694\n",
      "LEDD_ADJUSTED_2           0.0013      0.001      1.367      0.172      -0.001       0.003\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.09279026221694514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2269531791.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2269531791.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "df1 = df1[df1[f].notna()]\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd446b7",
   "metadata": {},
   "source": [
    "## UPDRS figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "498cafca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1419539268.py:32: UserWarning:\n",
      "\n",
      "Legend does not support handles for Annotation instances.\n",
      "See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#implementing-a-custom-legend-handler\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-v0_8-deep')\n",
    "\n",
    "#Define variables:\n",
    "X = ['UPDRS III','UPDRS IV'] \n",
    "\n",
    "Y_W = [35.2, 3.5]\n",
    "Y_W_std = [16.4, 3.7]\n",
    "\n",
    "Z_SA = [42.2, 4.8] \n",
    "Z_SA_std = [18.8, 4.8]\n",
    "\n",
    "W_B = [47, 6]\n",
    "W_B_std = [16.6, 3.8]\n",
    "\n",
    "#Define plot\n",
    "X_axis = np.arange(len(X)) \n",
    "  \n",
    "barplot1 = plt.bar(X_axis + 0, Y_W, 0.2, label = 'White',  color='lightseagreen') \n",
    "barplot2 = plt.bar(X_axis + 0.2, Z_SA, 0.2, label = 'South Asian', color='crimson') \n",
    "barplot3 = plt.bar(X_axis + 0.4, W_B, 0.2, label = 'Black', color='goldenrod') \n",
    "\n",
    "plt.errorbar(X_axis + 0, Y_W, Y_W_std, linestyle='None', c='#1A8E88', capsize=4)\n",
    "plt.errorbar(X_axis + 0.2, Z_SA, Z_SA_std, linestyle='None', c='#B01030', capsize=4)\n",
    "plt.errorbar(X_axis + 0.4, W_B, W_B_std, linestyle='None', c='#B38619', capsize=4)\n",
    "\n",
    "plt.bar_label(barplot1, label=Y_W, label_type='center', padding=-3, c='black')\n",
    "plt.bar_label(barplot2, label=Z_SA, label_type='center', padding=-3, c='black')\n",
    "plt.bar_label(barplot3, label=W_B, label_type='center', padding=-3, c='black')\n",
    "\n",
    "plt.xticks(X_axis + 0.2, X) \n",
    "plt.ylabel(\"Score\", ha = 'center')\n",
    "plt.legend() \n",
    "plt.ylim(0,75)\n",
    "\n",
    "# Draw a line with downticks at the ends\n",
    "plt.plot([(0, 0.2)], 64,'-', color = 'k', lw=1.2, marker = TICKDOWN, markeredgewidth=1.2, markersize = 8)\n",
    "# Plotting line within the given range \n",
    "plt.axhline(y = 64, xmin=0.105, xmax = 0.213, color='k', lw=1.2, markeredgewidth=1.2, markersize = 8)\n",
    "# Draw the text with a bounding box covering up the line\n",
    "plt.text(0.5*(0+0.2),66,'**',ha = 'center',va='center',size = 10)\n",
    "\n",
    "\n",
    "# Draw a line with downticks at the ends\n",
    "plt.plot([(0, 0.4)], 69,'-', color = 'k', lw=1.2, marker = TICKDOWN, markeredgewidth=1.2, markersize = 8)\n",
    "# Plotting line within the given range \n",
    "plt.axhline(y = 69, xmin=0.105, xmax = 0.328, color='k', lw=1.2, markeredgewidth=1.2, markersize = 8)            \n",
    "# Draw the text with a bounding box covering up the line\n",
    "plt.text(0.5*(0+0.4),71,'**',ha = 'center',va='center',size = 10)\n",
    "\n",
    "# Statistical annotation for UPDRS IV\n",
    "# Draw a line with downticks at the ends\n",
    "plt.plot([(1, 1.2)], 13,'-', color = 'k', lw=1.2, marker = TICKDOWN, markeredgewidth=1.2, markersize = 8)\n",
    "# Plotting line within the given range \n",
    "plt.axhline(y = 13, xmin=0.672, xmax = 0.783, color='k', lw=1.2, markeredgewidth=1.2, markersize = 8)            \n",
    "# Draw the text with a bounding box covering up the line\n",
    "plt.text(0.5*(1 + 1.2),15,'ns',ha = 'center',va='center',size = 10)\n",
    "\n",
    "# Draw a line with downticks at the ends\n",
    "plt.plot([(1, 1.4)], 18,'-', color = 'k', lw=1.2, marker = TICKDOWN, markeredgewidth=1.2, markersize = 8)\n",
    "# Plotting line within the given range \n",
    "plt.axhline(y = 18, xmin=0.672, xmax = 0.895, color='k', lw=1.2, markeredgewidth=1.2, markersize = 8)            \n",
    "# Draw the text with a bounding box covering up the line\n",
    "plt.text(0.5*(1 + 1.4),20,'*',ha = 'center',va='center',size = 10)\n",
    "\n",
    "plt.savefig('Figure 2.png', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da521c0",
   "metadata": {},
   "source": [
    "# NMSQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f6369",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "12a43907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSQ_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  12.0\n",
      "SD:  6.2\n",
      "Median:  12.0\n",
      "IQR:  10.0\n",
      "\n",
      "White\n",
      "Mean:  11.1\n",
      "SD:  5.4\n",
      "Median:  11.0\n",
      "IQR:  8.0\n",
      "\n",
      "South Asian\n",
      "Mean:  13.4\n",
      "SD:  6.8\n",
      "Median:  13.5\n",
      "IQR:  11.2\n",
      "\n",
      "Black\n",
      "Mean:  12.0\n",
      "SD:  5.8\n",
      "Median:  12.0\n",
      "IQR:  9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'NMSQ_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(score))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(score))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(score))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print(\"Median: \" , \"%.1f\" % np.median(score))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.1f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192bea9f",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5b000c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSQ_Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.972, p = 0.042\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.964, p = 0.023\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.943, p = 0.254\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 7.305, p = 0.008\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.308, p = 0.580\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.227, p = 0.271\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'NMSQ_Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "131b2ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 5.436, p = 0.020\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 881.000, p = 0.532\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 747.000, p = 0.438\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db639ca9",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5d2d1785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  172\n",
      "White and Black PD patients count:  113\n",
      "Black and South Asian PD patients count:  101\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4a526b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  NMSQ_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    92\n",
      "0    80\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681852\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  172\n",
      "Model:                          Logit   Df Residuals:                      170\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01283\n",
      "Time:                        14:00:06   Log-Likelihood:                -117.28\n",
      "converged:                       True   LL-Null:                       -118.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.08085\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "NMSQ_Total               -0.0286      0.018     -1.630      0.103      -0.063       0.006\n",
      "DaysSinceSymptomOnset     0.0001    6.8e-05      1.869      0.062    -6.2e-06       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.10314905123734637\n",
      "\n",
      "Exposure  NMSQ_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    92\n",
      "0    80\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657409\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  172\n",
      "Model:                          Logit   Df Residuals:                      168\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.04822\n",
      "Time:                        14:00:06   Log-Likelihood:                -113.07\n",
      "converged:                       True   LL-Null:                       -118.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.009499\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "NMSQ_Total               -0.0840      0.027     -3.147      0.002      -0.136      -0.032\n",
      "DaysSinceSymptomOnset  5.067e-05   7.17e-05      0.707      0.480   -8.99e-05       0.000\n",
      "Age                       0.0142      0.006      2.410      0.016       0.003       0.026\n",
      "Gender                    0.1531      0.323      0.474      0.635      -0.480       0.786\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0016474826998684412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "98624753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  NMSQ_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    92\n",
      "0    21\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511415\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  113\n",
      "Model:                          Logit   Df Residuals:                      111\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.06515\n",
      "Time:                        14:00:07   Log-Likelihood:                -57.790\n",
      "converged:                       True   LL-Null:                       -54.255\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "NMSQ_Total                0.0593      0.030      2.004      0.045       0.001       0.117\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.877      0.061   -9.82e-06       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.04507212626484957\n",
      "\n",
      "Exposure  NMSQ_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    92\n",
      "0    21\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.468712\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  113\n",
      "Model:                          Logit   Df Residuals:                      109\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02379\n",
      "Time:                        14:00:07   Log-Likelihood:                -52.964\n",
      "converged:                       True   LL-Null:                       -54.255\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4607\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "NMSQ_Total               -0.0366      0.043     -0.844      0.399      -0.122       0.048\n",
      "DaysSinceSymptomOnset  9.772e-05      0.000      0.798      0.425      -0.000       0.000\n",
      "Age                       0.0166      0.009      1.863      0.063      -0.001       0.034\n",
      "Gender                    0.7527      0.490      1.537      0.124      -0.207       1.712\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.3988694455336941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2164510637.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a1abdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  NMSQ_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    80\n",
      "0    21\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.523145\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  101\n",
      "Model:                          Logit   Df Residuals:                       99\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.02339\n",
      "Time:                        14:00:10   Log-Likelihood:                -52.838\n",
      "converged:                       True   LL-Null:                       -51.630\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "NMSQ_Total                0.0794      0.030      2.603      0.009       0.020       0.139\n",
      "DaysSinceSymptomOnset  7.004e-05      0.000      0.546      0.585      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.009233893755204323\n",
      "\n",
      "Exposure  NMSQ_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    80\n",
      "0    21\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.507934\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  101\n",
      "Model:                          Logit   Df Residuals:                       97\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.006367\n",
      "Time:                        14:00:10   Log-Likelihood:                -51.301\n",
      "converged:                       True   LL-Null:                       -51.630\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8832\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "NMSQ_Total                0.0430      0.040      1.083      0.279      -0.035       0.121\n",
      "DaysSinceSymptomOnset  1.379e-05      0.000      0.104      0.917      -0.000       0.000\n",
      "Age                       0.0048      0.008      0.595      0.552      -0.011       0.021\n",
      "Gender                    0.6481      0.470      1.380      0.168      -0.272       1.568\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.27870260728652396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72302e8d",
   "metadata": {},
   "source": [
    "# MoCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119b429",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d7df5823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  211\n",
      "n:  211\n",
      "Number of unreliable scores:  44\n",
      "     ELPD_ID  Ethnicity\n",
      "12     11404          3\n",
      "15     32776          3\n",
      "16     24716          4\n",
      "22     24092          3\n",
      "40     13640          2\n",
      "53     19152          3\n",
      "56     41564          2\n",
      "69     38704          3\n",
      "72     27056          3\n",
      "74     37768          3\n",
      "75     46244          3\n",
      "76     10988          3\n",
      "83     12652          1\n",
      "86     20244          3\n",
      "89     51288          2\n",
      "93     40784          3\n",
      "94     31008          3\n",
      "97     14680          2\n",
      "118    40680          2\n",
      "129    33140          3\n",
      "131    47076          3\n",
      "133    43124          2\n",
      "140    38340          3\n",
      "142    17280          3\n",
      "149    42552          2\n",
      "151    28304          1\n",
      "153    20088          1\n",
      "157    37560          3\n",
      "164    26016          2\n",
      "166    27472          3\n",
      "167    16604          1\n",
      "169    49936          3\n",
      "175    29552          3\n",
      "177    30020          3\n",
      "179    45568          8\n",
      "182    52328          3\n",
      "189    20816          7\n",
      "192    45516          3\n",
      "195    26432          3\n",
      "199    34128          3\n",
      "207    18164          8\n",
      "211    30176          3\n",
      "215    16812          1\n",
      "216    15200          3\n",
      "\n",
      "n:  167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2940153571.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "print('n: ', df[a].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "print('n: ', df[a].count())\n",
    "\n",
    "# Further exclusion due to score unreliable:\n",
    "unreliable_MOCA=df[df.MOCA_Reliability == 0]\n",
    "print('Number of unreliable scores: ', unreliable_MOCA['ELPD_ID'].count())\n",
    "df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n",
    "\n",
    "nan_rows = df[df['MOCA_Reliability'].isna()]\n",
    "columns_to_select = ['ELPD_ID', 'Ethnicity']\n",
    "nan_rows = nan_rows[columns_to_select]\n",
    "print(nan_rows)\n",
    "\n",
    "df = df[df['MOCA_Reliability'].notna()]\n",
    "print('')\n",
    "print('n: ', df[a].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a066553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MOCA_TotalEducationLevelConsidered\n",
      "PwP\n",
      "\n",
      "All\n",
      "n:  167\n",
      "Mean:  23.8\n",
      "SD:  4.6\n",
      "\n",
      "White\n",
      "Mean:  24.9\n",
      "SD:  4.2\n",
      "\n",
      "South Asian\n",
      "Mean:  22.2\n",
      "SD:  4.6\n",
      "\n",
      "Black\n",
      "Mean:  22.4\n",
      "SD:  4.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean for all PD patients\n",
    "print('')\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e76093",
   "metadata": {},
   "source": [
    "## HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a18ee982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  45\n",
      "Number of unreliable scores:  6\n",
      "\n",
      "n:  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\323674018.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "\n",
    "df = df[df[a].notna()]\n",
    "print('n: ', df[a].count())\n",
    "\n",
    "# Further exclusion due to score unreliable:\n",
    "unreliable_MOCA=df[df.MOCA_Reliability == 0]\n",
    "print('Number of unreliable scores: ', unreliable_MOCA['ELPD_ID'].count())\n",
    "df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n",
    "\n",
    "df = df[df['MOCA_Reliability'].notna()]\n",
    "print('')\n",
    "print('n: ', df[a].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c385a0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MOCA_TotalEducationLevelConsidered\n",
      "PwP\n",
      "\n",
      "All\n",
      "n:  39\n",
      "Mean:  25.6\n",
      "SD:  3.4\n",
      "\n",
      "White\n",
      "Mean:  26.1\n",
      "SD:  2.7\n",
      "\n",
      "South Asian\n",
      "Mean:  25.4\n",
      "SD:  3.8\n",
      "\n",
      "Black\n",
      "Mean:  nan\n",
      "SD:  nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3972042984.py:30: RuntimeWarning: Mean of empty slice.\n",
      "  print(\"Mean: \" , \"%.1f\" % score.mean())\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean for all PD patients\n",
    "print('')\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295c9b4",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09d98e",
   "metadata": {},
   "source": [
    "PwP vs HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "67ea1ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\792873137.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "# Further exclusion due to score unreliable:\n",
    "df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n",
    "df1 = df[df['MOCA_Reliability'].notna()]\n",
    "print('n: ', df1[a].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8f2cb0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n:  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\4108962291.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "# Further exclusion due to score unreliable:\n",
    "df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n",
    "df2 = df[df['MOCA_Reliability'].notna()]\n",
    "print('')\n",
    "print('n: ', df2[a].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "18b3df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOCA_TotalEducationLevelConsidered\n",
      "Distribution\n",
      "\n",
      "PwP\n",
      "Statistics = 0.922, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "HCs\n",
      "Statistics = 0.924, p = 0.012\n",
      "Distribution is not normal\n",
      "\n",
      "PwP vs HC\n",
      "Statistics = 3.415, p = 0.066\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "a1 = 'MOCA_TotalEducationLevelConsidered'\n",
    "print(a1)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('PwP')\n",
    "stat, p = st.shapiro(df1[a1])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "a2 = 'MOCA_TotalEducationLevelConsidered'\n",
    "print('HCs')\n",
    "stat, p = st.shapiro(df2[a2])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('PwP vs HC')\n",
    "stat, p = st.levene(df1[a1], df2[a2], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f8504354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP vs HCs\n",
      "Statistics = 5.096, p = 0.024\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('PwP vs HCs')\n",
    "stat, p = st.kruskal(df1[a1], df2[a2])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7008a0",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "84f0e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOCA_TotalEducationLevelConsidered\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.876, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.961, p = 0.090\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.900, p = 0.082\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 1.316, p = 0.253\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.481, p = 0.489\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.001, p = 0.980\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ddce0a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 3235.000, p = 0.000\n",
      "Difference is significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 965.000, p = 0.038\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  0.2 DOF:  66.0\n",
      "Difference is not significant, p =  0.857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances -  Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22519766",
   "metadata": {},
   "source": [
    "HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8b12873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  45\n",
      "\n",
      "MOCA_TotalEducationLevelConsidered\n",
      "PwP\n",
      "White\n",
      "South Asian\n"
     ]
    }
   ],
   "source": [
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "\n",
    "df = df[df[a].notna()]\n",
    "print('n: ', df[a].count())\n",
    "\n",
    "# Descriptive statistics\n",
    "print('')\n",
    "print(a)\n",
    "print('PwP')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "#W_score = W[a].to_numpy(dtype=np.float32)\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "#score = SA[a].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "17bdbe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOCA_TotalEducationLevelConsidered\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.961, p = 0.740\n",
      "Distribution is normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.939, p = 0.087\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 1.402, p = 0.243\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a4691090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PwP\n",
      "White vs South Asian\n",
      "T:  1.0 DOF:  42.0\n",
      "Difference is not significant, p =  0.322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution normal, variances equal, therefore use t-test:\n",
    "print('PwP')\n",
    "print('White vs South Asian')\n",
    "summary, results = rp.ttest(group1= W[a], group1_name= \"White\",\n",
    "                            group2= SA[a], group2_name= \"South Asian\")\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aca81f",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "63fc49cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  143\n",
      "White and Black PD patients count:  107\n",
      "Black and South Asian PD patients count:  68\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c4f05d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  MOCA_TotalEducationLevelConsidered  adjusted by  DaysSinceSymptomOnset\n",
      "1    91\n",
      "0    52\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.641052\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  143\n",
      "Model:                          Logit   Df Residuals:                      141\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02201\n",
      "Time:                        14:07:26   Log-Likelihood:                -91.670\n",
      "converged:                       True   LL-Null:                       -93.734\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04220\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "MOCA_TotalEducationLevelConsidered     0.0247      0.011      2.213      0.027       0.003       0.047\n",
      "DaysSinceSymptomOnset               2.421e-05   7.95e-05      0.305      0.761      -0.000       0.000\n",
      "======================================================================================================\n",
      "Full p-value for exposure:  0.02687538095675232\n",
      "\n",
      "Exposure  MOCA_TotalEducationLevelConsidered  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    91\n",
      "0    52\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613324\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  143\n",
      "Model:                          Logit   Df Residuals:                      139\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.06432\n",
      "Time:                        14:07:26   Log-Likelihood:                -87.705\n",
      "converged:                       True   LL-Null:                       -93.734\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.007190\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "MOCA_TotalEducationLevelConsidered     0.0198      0.028      0.705      0.481      -0.035       0.075\n",
      "DaysSinceSymptomOnset               5.521e-06   8.24e-05      0.067      0.947      -0.000       0.000\n",
      "Age                                    0.0148      0.011      1.383      0.167      -0.006       0.036\n",
      "Gender                                -1.0999      0.429     -2.565      0.010      -1.940      -0.259\n",
      "======================================================================================================\n",
      "Full p-value for exposure:  0.481051968467183\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aa961c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  MOCA_TotalEducationLevelConsidered  adjusted by  DaysSinceSymptomOnset\n",
      "1.0    91\n",
      "0.0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.406036\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  107\n",
      "Model:                          Logit   Df Residuals:                      105\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 22 Oct 2024   Pseudo R-squ.:                 0.03760\n",
      "Time:                        10:47:19   Log-Likelihood:                -43.446\n",
      "converged:                       True   LL-Null:                       -45.143\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06542\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "MOCA_TotalEducationLevelConsidered     0.0695      0.018      3.772      0.000       0.033       0.106\n",
      "DaysSinceSymptomOnset               4.103e-05      0.000      0.305      0.761      -0.000       0.000\n",
      "======================================================================================================\n",
      "Full p-value for exposure:  0.0001619515422919596\n",
      "\n",
      "Exposure  MOCA_TotalEducationLevelConsidered  adjusted by  DaysSinceSymptomOnset Self_Reported_Age Gender\n",
      "1.0    91\n",
      "0.0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.397508\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  107\n",
      "Model:                          Logit   Df Residuals:                      103\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 22 Oct 2024   Pseudo R-squ.:                 0.05781\n",
      "Time:                        10:47:19   Log-Likelihood:                -42.533\n",
      "converged:                       True   LL-Null:                       -45.143\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1564\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "MOCA_TotalEducationLevelConsidered     0.0480      0.044      1.087      0.277      -0.039       0.135\n",
      "DaysSinceSymptomOnset               3.458e-05      0.000      0.244      0.807      -0.000       0.000\n",
      "Self_Reported_Age                      0.0020      0.016      0.126      0.900      -0.029       0.033\n",
      "Gender                                 0.7331      0.560      1.309      0.191      -0.365       1.831\n",
      "======================================================================================================\n",
      "Full p-value for exposure:  0.27691631221172275\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9b51a4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  MOCA_TotalEducationLevelConsidered  adjusted by  DaysSinceSymptomOnset\n",
      "1    52\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553323\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   68\n",
      "Model:                          Logit   Df Residuals:                       66\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.01417\n",
      "Time:                        14:07:30   Log-Likelihood:                -37.626\n",
      "converged:                       True   LL-Null:                       -37.100\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "MOCA_TotalEducationLevelConsidered     0.0498      0.019      2.567      0.010       0.012       0.088\n",
      "DaysSinceSymptomOnset               8.657e-06      0.000      0.064      0.949      -0.000       0.000\n",
      "======================================================================================================\n",
      "Full p-value for exposure:  0.01025943644417129\n",
      "\n",
      "Exposure  MOCA_TotalEducationLevelConsidered  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    52\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493172\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   68\n",
      "Model:                          Logit   Df Residuals:                       64\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.09608\n",
      "Time:                        14:07:30   Log-Likelihood:                -33.536\n",
      "converged:                       True   LL-Null:                       -37.100\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06788\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "MOCA_TotalEducationLevelConsidered     0.0284      0.045      0.629      0.530      -0.060       0.117\n",
      "DaysSinceSymptomOnset              -6.138e-05      0.000     -0.420      0.674      -0.000       0.000\n",
      "Age                                   -0.0057      0.016     -0.365      0.715      -0.037       0.025\n",
      "Gender                                 1.6685      0.598      2.792      0.005       0.497       2.840\n",
      "======================================================================================================\n",
      "Full p-value for exposure:  0.5296017848803438\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a8e396",
   "metadata": {},
   "source": [
    "## MoCA Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0e27ef74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  211\n",
      "Number of unreliable scores:  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\690411023.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print('n: ', df[a].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 30), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "unreliable_MOCA=df[df.MOCA_Reliability == 0]\n",
    "print('Number of unreliable scores: ', unreliable_MOCA['ELPD_ID'].count())\n",
    "df['MOCA_Reliability'].mask((df['MOCA_Reliability'] == 0), inplace=True)\n",
    "df = df[df['MOCA_Reliability'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "06096cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal cognition\n",
      "PwP\n",
      "White:  50\n",
      "South Asian:  14\n",
      "Black:  4\n",
      "\n",
      "MCI\n",
      "White:  33\n",
      "South Asian:  27\n",
      "Black:  10\n",
      "\n",
      "Dementia\n",
      "White:  8\n",
      "South Asian:  11\n",
      "Black :  2\n"
     ]
    }
   ],
   "source": [
    "# Define\n",
    "W = df[df[b]==1]\n",
    "B = df[df[b]==2]\n",
    "SA = df[df[b]==3]\n",
    "\n",
    "# Normal cognition\n",
    "a = 'MOCA_TotalEducationLevelConsidered'\n",
    "print('Normal cognition')\n",
    "print('PwP')\n",
    "W_PDnoCI = W.loc[(W[a]>25)]\n",
    "W_PDnoCI_total = W_PDnoCI['Diagnosis'].count()\n",
    "print('White: ', W_PDnoCI_total)\n",
    "\n",
    "SA_PDnoCI = SA.loc[(SA[a]>25)]\n",
    "SA_PDnoCI_total = SA_PDnoCI['Diagnosis'].count()\n",
    "print('South Asian: ', SA_PDnoCI_total)\n",
    "\n",
    "B_PDnoCI = B.loc[(B[a]>25)]\n",
    "B_PDnoCI_total = B_PDnoCI['Diagnosis'].count()\n",
    "print('Black: ', B_PDnoCI_total)\n",
    "\n",
    "\n",
    "# MCI\n",
    "print('')\n",
    "print('MCI')\n",
    "W_PDMCI = W[(W[a]>18) & (W[a]<26)]\n",
    "W_PDMCI_total = W_PDMCI['Diagnosis'].count()\n",
    "print('White: ', W_PDMCI_total)\n",
    "\n",
    "SA_PDMCI = SA[(SA[a]>18) & (SA[a]<26)]\n",
    "SA_PDMCI_total = SA_PDMCI['Diagnosis'].count()\n",
    "print('South Asian: ', SA_PDMCI_total)\n",
    "\n",
    "B_PDMCI = B[(B[a]>18) & (B[a]<26)]\n",
    "B_PDMCI_total = B_PDMCI['Diagnosis'].count()\n",
    "print('Black: ', B_PDMCI_total)\n",
    "\n",
    "\n",
    "# PDD\n",
    "print('')\n",
    "print('Dementia')\n",
    "W_PDD = W.loc[(W[a]<19)]\n",
    "W_PDD_total = W_PDD['Diagnosis'].count()\n",
    "print('White: ', W_PDD_total)\n",
    "\n",
    "SA_PDD = SA.loc[(SA[a]<19)]\n",
    "SA_PDD_total = SA_PDD['Diagnosis'].count()\n",
    "print('South Asian: ', SA_PDD_total) \n",
    "\n",
    "B_PDD = B.loc[(B[a]<19)]\n",
    "B_PDD_total = B_PDD['Diagnosis'].count()\n",
    "print('Black : ', B_PDD_total)  \n",
    "\n",
    "# Create categorical data arrays\n",
    "x = [\"White\",\"South Asian\", \"Black\"]\n",
    "PD_noCI = np.array([W_PDnoCI_total, SA_PDnoCI_total, B_PDnoCI_total])\n",
    "PD_MCI = np.array([W_PDMCI_total,SA_PDMCI_total, B_PDMCI_total])\n",
    "PD_D = np.array([W_PDD_total, SA_PDD_total, B_PDD_total])\n",
    "\n",
    "# Memo of sample number\n",
    "snum = PD_noCI + PD_MCI + PD_D\n",
    "\n",
    "# Normalization\n",
    "y1 = PD_noCI/snum*100.\n",
    "y2 = PD_MCI/snum*100.\n",
    "y3 = PD_D/snum*100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "661fdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sunburst plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6ab94d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "branchvalues": "total",
         "customdata": [
          [
           "South Asian"
          ],
          [
           "White"
          ],
          [
           "White"
          ],
          [
           "Black"
          ],
          [
           "Black"
          ],
          [
           "South Asian"
          ],
          [
           "Black"
          ],
          [
           "South Asian"
          ],
          [
           "White"
          ],
          [
           "(?)"
          ]
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hoverinfo": "label+percent entry+value",
         "hovertemplate": "labels=%{label}<br>value=%{value}<br>parent=%{parent}<br>id=%{id}<br>sub_categories=%{customdata[0]}<extra></extra>",
         "ids": [
          "Cognition/South Asian/Normal",
          "Cognition/White/Normal",
          "Cognition/White/Impairment",
          "Cognition/Black/Normal",
          "Cognition/Black/Impairment",
          "Cognition/South Asian/Impairment",
          "Cognition/Black",
          "Cognition/South Asian",
          "Cognition/White",
          "Cognition"
         ],
         "labels": [
          "Normal",
          "Normal",
          "Impairment",
          "Normal",
          "Impairment",
          "Impairment",
          "Black",
          "South Asian",
          "White",
          "Cognition"
         ],
         "marker": {
          "colors": [
           "crimson",
           "lightseagreen",
           "lightseagreen",
           "goldenrod",
           "goldenrod",
           "crimson",
           "goldenrod",
           "crimson",
           "lightseagreen",
           "#FFA15A"
          ],
          "line": {
           "color": "white",
           "width": 8
          }
         },
         "name": "",
         "parents": [
          "Cognition/South Asian",
          "Cognition/White",
          "Cognition/White",
          "Cognition/Black",
          "Cognition/Black",
          "Cognition/South Asian",
          "Cognition",
          "Cognition",
          "Cognition",
          ""
         ],
         "textinfo": "label+percent parent",
         "type": "sunburst",
         "values": [
          14,
          50,
          41,
          4,
          12,
          38,
          16,
          52,
          91,
          159
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "showscale": false
        },
        "font": {
         "family": "Arial",
         "size": 14
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 30
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "x": 0.5
        },
        "uniformtext": {
         "minsize": 10,
         "mode": "show"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"dfc4ada9-8b65-499a-a981-6cb7b7ab3146\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dfc4ada9-8b65-499a-a981-6cb7b7ab3146\")) {                    Plotly.newPlot(                        \"dfc4ada9-8b65-499a-a981-6cb7b7ab3146\",                        [{\"branchvalues\":\"total\",\"customdata\":[[\"South Asian\"],[\"White\"],[\"White\"],[\"Black\"],[\"Black\"],[\"South Asian\"],[\"Black\"],[\"South Asian\"],[\"White\"],[\"(?)\"]],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"labels=%{label}\\u003cbr\\u003evalue=%{value}\\u003cbr\\u003eparent=%{parent}\\u003cbr\\u003eid=%{id}\\u003cbr\\u003esub_categories=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"ids\":[\"Cognition\\u002fSouth Asian\\u002fNormal\",\"Cognition\\u002fWhite\\u002fNormal\",\"Cognition\\u002fWhite\\u002fImpairment\",\"Cognition\\u002fBlack\\u002fNormal\",\"Cognition\\u002fBlack\\u002fImpairment\",\"Cognition\\u002fSouth Asian\\u002fImpairment\",\"Cognition\\u002fBlack\",\"Cognition\\u002fSouth Asian\",\"Cognition\\u002fWhite\",\"Cognition\"],\"labels\":[\"Normal\",\"Normal\",\"Impairment\",\"Normal\",\"Impairment\",\"Impairment\",\"Black\",\"South Asian\",\"White\",\"Cognition\"],\"marker\":{\"colors\":[\"crimson\",\"lightseagreen\",\"lightseagreen\",\"goldenrod\",\"goldenrod\",\"crimson\",\"goldenrod\",\"crimson\",\"lightseagreen\",\"#FFA15A\"],\"line\":{\"color\":\"white\",\"width\":8}},\"name\":\"\",\"parents\":[\"Cognition\\u002fSouth Asian\",\"Cognition\\u002fWhite\",\"Cognition\\u002fWhite\",\"Cognition\\u002fBlack\",\"Cognition\\u002fBlack\",\"Cognition\\u002fSouth Asian\",\"Cognition\",\"Cognition\",\"Cognition\",\"\"],\"values\":[14,50,41,4,12,38,16,52,91,159],\"type\":\"sunburst\",\"hoverinfo\":\"label+percent entry+value\",\"textinfo\":\"label+percent parent\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":30,\"l\":0,\"r\":0,\"b\":0},\"uniformtext\":{\"minsize\":10,\"mode\":\"show\"},\"coloraxis\":{\"showscale\":false},\"title\":{\"x\":0.5},\"font\":{\"family\":\"Arial\",\"size\":14}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('dfc4ada9-8b65-499a-a981-6cb7b7ab3146');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "W_PDCI_total = W_PDMCI_total + W_PDD_total\n",
    "SA_PDCI_total = SA_PDMCI_total + SA_PDD_total\n",
    "B_PDCI_total = B_PDMCI_total + B_PDD_total\n",
    "\n",
    "\n",
    "# Sample data (you can replace this with your own hierarchical data)\n",
    "data = {\n",
    "    'categories': ['Cognition', 'Cognition', 'Cognition','Cognition','Cognition','Cognition'],\n",
    "    'sub_categories': ['White', 'White', 'South Asian', 'South Asian','Black', 'Black'],\n",
    "    'sub_sub_categories': ['Normal', 'Impairment', 'Normal', 'Impairment', \n",
    "                           'Normal', 'Impairment',],\n",
    "    'values': [W_PDnoCI_total, W_PDCI_total, SA_PDnoCI_total, SA_PDCI_total, \n",
    "               B_PDnoCI_total, B_PDCI_total]\n",
    "}\n",
    "\n",
    "# Define a consistent color mapping for sub_sub_category\n",
    "color_map = {\n",
    "    'Cognition': 'red',\n",
    "    'White': 'lightseagreen',\n",
    "    'South Asian': 'crimson',\n",
    "    'Black': 'goldenrod'\n",
    "}\n",
    "\n",
    "# Create the sunburst plot\n",
    "fig = px.sunburst(\n",
    "    data,\n",
    "    path=['categories', 'sub_categories', 'sub_sub_categories'],  # Hierarchy levels\n",
    "    values='values',  # Value for each leaf node\n",
    "    color = 'sub_categories',\n",
    "    color_discrete_map=color_map,  # Red-yellow-blue color scale\n",
    "    title=''\n",
    ")\n",
    "\n",
    "\n",
    "# Enhance the appearance\n",
    "fig.update_traces(\n",
    "    hoverinfo=\"label+percent entry+value\",\n",
    "    textinfo='label+percent parent',\n",
    "    marker=dict(line=dict(width=8, color='white'))\n",
    ")\n",
    "\n",
    "# Update layout for visual appeal\n",
    "fig.update_layout(\n",
    "    margin=dict(t=30, l=0, r=0, b=0),\n",
    "    uniformtext=dict(minsize=10, mode='show'),\n",
    "    coloraxis_showscale=False,  # Hide the color scale bar\n",
    "    title_x=0.5,\n",
    "    font=dict(family=\"Arial\", size=14)\n",
    ")\n",
    "\n",
    "plt.savefig('Figure 3.png', bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd7625",
   "metadata": {},
   "source": [
    "## Significance - categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1d187",
   "metadata": {},
   "source": [
    "### NC, MCI, PDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39dee4b",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fbf3e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PDnoCI  PDMCI  PDD\n",
      "White            50     33    8\n",
      "South Asian      14     27   11\n",
      "Black             4     10    2\n"
     ]
    }
   ],
   "source": [
    "# Initialize data of lists.\n",
    "data = {'PDnoCI': [W_PDnoCI_total, SA_PDnoCI_total, B_PDnoCI_total], 'PDMCI': [W_PDMCI_total,SA_PDMCI_total, B_PDMCI_total],\n",
    "       'PDD': [W_PDD_total, SA_PDD_total, B_PDD_total]}\n",
    "row_titles = ['White', 'South Asian', 'Black']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "be661304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 14.45\n",
      "\n",
      "Difference is significant, p:  0.0060 0.006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca0a99",
   "metadata": {},
   "source": [
    "White vs South Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1ce56ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PDnoCI  PDMCI  PDD\n",
      "White            50     33    8\n",
      "South Asian      14     27   11\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists.\n",
    "data = {'PDnoCI': [W_PDnoCI_total, SA_PDnoCI_total], 'PDMCI': [W_PDMCI_total,SA_PDMCI_total],\n",
    "       'PDD': [W_PDD_total, SA_PDD_total]}\n",
    "row_titles = ['White', 'South Asian']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5d593e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T statistic:  11.546\n",
      "Degrees of freedom:  2\n",
      "p value: 0.0031\n",
      "Difference is significant\n"
     ]
    }
   ],
   "source": [
    "# Chi-squared\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.4f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aecd509",
   "metadata": {},
   "source": [
    "White vs Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6f38b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PDnoCI  PDMCI  PDD\n",
      "White      50     33    8\n",
      "Black       4     10    2\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists.\n",
    "data = {'PDnoCI': [W_PDnoCI_total, B_PDnoCI_total], 'PDMCI': [W_PDMCI_total, B_PDMCI_total],\n",
    "       'PDD': [W_PDD_total, B_PDD_total]}\n",
    "row_titles = ['White', 'Black']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0daa13ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 4.95\n",
      "\n",
      "Difference is not significant, p:  0.0842 0.084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e23bb",
   "metadata": {},
   "source": [
    "Black vs South Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0a16dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PDnoCI  PDMCI  PDD\n",
      "Black             4     10    2\n",
      "South Asian      14     27   11\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists.\n",
    "data = {'PDnoCI': [B_PDnoCI_total, SA_PDnoCI_total], 'PDMCI': [B_PDMCI_total, SA_PDMCI_total],\n",
    "       'PDD': [B_PDD_total, SA_PDD_total]}\n",
    "row_titles = ['Black', 'South Asian']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c9876c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 0.75\n",
      "\n",
      "Difference is not significant, p:  0.6880 0.688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d7a64",
   "metadata": {},
   "source": [
    "### NC vs CI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9147c0",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "720fa0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PDnoCI  PDCI\n",
      "White            50    41\n",
      "South Asian      14    38\n",
      "Black             4    12\n"
     ]
    }
   ],
   "source": [
    "# Define \n",
    "# Normal cognition\n",
    "W_PDnoCI = W.loc[(W[a]>25)]\n",
    "W_PDnoCI_total = W_PDnoCI['Diagnosis'].count()\n",
    "\n",
    "SA_PDnoCI = SA.loc[(SA[a]>25)]\n",
    "SA_PDnoCI_total = SA_PDnoCI['Diagnosis'].count()\n",
    "\n",
    "B_PDnoCI = B.loc[(B[a]>25)]\n",
    "B_PDnoCI_total = B_PDnoCI['Diagnosis'].count()\n",
    "\n",
    "\n",
    "# CI\n",
    "W_CI = W.loc[(W[a]<=25)]\n",
    "W_CI_total = W_CI['Diagnosis'].count()\n",
    "\n",
    "SA_CI = SA.loc[(SA[a]<=25)]\n",
    "SA_CI_total = SA_CI['Diagnosis'].count() \n",
    "\n",
    "B_CI = B.loc[(B[a]<=25)]\n",
    "B_CI_total = B_CI['Diagnosis'].count()\n",
    "\n",
    "\n",
    "# Initialize data of lists.\n",
    "data = {'PDnoCI': [W_PDnoCI_total, SA_PDnoCI_total, B_PDnoCI_total],\n",
    "       'PDCI': [W_CI_total, SA_CI_total, B_CI_total]}\n",
    "row_titles = ['White', 'South Asian', 'Black']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "426c7811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T statistic:  12.910\n",
      "Degrees of freedom:  2\n",
      "p value: 0.0016\n",
      "Difference is significant\n"
     ]
    }
   ],
   "source": [
    "# Chi-squared\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.4f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6250a",
   "metadata": {},
   "source": [
    "White vs South Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "12af9f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PDnoCI  PDCI\n",
      "White            50    41\n",
      "South Asian      14    38\n"
     ]
    }
   ],
   "source": [
    "# Initialize data of lists.\n",
    "data = {'PDnoCI': [W_PDnoCI_total, SA_PDnoCI_total],\n",
    "       'PDCI': [W_CI_total, SA_CI_total]}\n",
    "row_titles = ['White', 'South Asian']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ec98c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T statistic:  9.406\n",
      "Degrees of freedom:  1\n",
      "p value: 0.0022\n",
      "Difference is significant\n"
     ]
    }
   ],
   "source": [
    "# Chi-squared\n",
    "st, p, dof, expected = chi2_contingency(data_cont)\n",
    "print('T statistic: ', \"%.3f\" % st)\n",
    "print('Degrees of freedom: ', dof)\n",
    "\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value: \" + str(\"%.4f\" % p))\n",
    "if p <= alpha:   \n",
    "    print('Difference is significant')  \n",
    "else:\n",
    "    print('Difference is not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321b289",
   "metadata": {},
   "source": [
    "White vs Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "efbfef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PDnoCI  PDCI\n",
      "White      50    41\n",
      "Black       4    12\n"
     ]
    }
   ],
   "source": [
    "# Initialize data of lists.\n",
    "data = {'PDnoCI': [W_PDnoCI_total, B_PDnoCI_total],\n",
    "       'PDCI': [W_CI_total, B_CI_total]}\n",
    "row_titles = ['White', 'Black']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "883a5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 4.88\n",
      "\n",
      "Difference is significant, p:  0.0272 0.027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test:\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8038f7",
   "metadata": {},
   "source": [
    "Black vs South Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "73a32f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PDnoCI  PDCI\n",
      "South Asian      14    38\n",
      "Black             4    12\n"
     ]
    }
   ],
   "source": [
    "# Initialize data of lists.\n",
    "data = {'PDnoCI': [SA_PDnoCI_total, B_PDnoCI_total],\n",
    "       'PDCI': [SA_CI_total, B_CI_total]}\n",
    "row_titles = ['South Asian', 'Black']\n",
    "\n",
    "# Create DataFrame\n",
    "data_cont = pd.DataFrame(data, index=row_titles)\n",
    " \n",
    "# Print the output.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "87d81d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 0.02\n",
      "\n",
      "Difference is not significant, p:  0.8788 0.879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test:\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602cd2b5",
   "metadata": {},
   "source": [
    "# Smell test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7100a1",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e5d09887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smell_Test_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "n:  98\n",
      "Mean:  2\n",
      "SD:  1\n",
      "Median:  2\n",
      "IQR:  2\n",
      "\n",
      "White\n",
      "Mean:  3\n",
      "SD:  1\n",
      "Median:  2\n",
      "IQR:  1\n",
      "\n",
      "South Asian\n",
      "Mean:  2\n",
      "SD:  1\n",
      "Median:  2\n",
      "IQR:  3\n",
      "\n",
      "Black\n",
      "Mean:  1\n",
      "SD:  1\n",
      "Median:  1\n",
      "IQR:  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'Smell_Test_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df[a].mask((df[a] > 6), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "# Descriptive statistics\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "duration = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "duration = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "duration = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "duration = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a785522",
   "metadata": {},
   "source": [
    "## HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "aae7f021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smell_Test_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "n:  29\n",
      "Mean:  3\n",
      "SD:  1\n",
      "Median:  3\n",
      "IQR:  2\n",
      "\n",
      "White\n",
      "Mean:  2\n",
      "SD:  1\n",
      "Median:  2\n",
      "IQR:  0\n",
      "\n",
      "South Asian\n",
      "Mean:  3\n",
      "SD:  1\n",
      "Median:  3\n",
      "IQR:  2\n",
      "\n",
      "Black - no smell test results\n"
     ]
    }
   ],
   "source": [
    "a = 'Smell_Test_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDH\n",
    "df[a].mask((df[a] > 6), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "# Descriptive statistics\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % score.mean())\n",
    "print(\"SD: \", \"%.0f\"  % score.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(score))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % score.mean())\n",
    "print(\"SD: \", \"%.0f\"  % score.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(score))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % score.mean())\n",
    "print(\"SD: \", \"%.0f\"  % score.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(score))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "print('Black - no smell test results')\n",
    "#B = df[df.Ethnicity==2]\n",
    "#score = B[a].to_numpy(dtype=np.float32)\n",
    "#print(\"Mean: \" , \"%.0f\" % score.mean())\n",
    "#print(\"SD: \", \"%.0f\"  % score.std())\n",
    "#print(\"Median: \" , \"%.0f\" % np.median(score))\n",
    "#q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "#iqr = q75 - q25\n",
    "#print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "#print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54179bea",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2edbe",
   "metadata": {},
   "source": [
    "PwP vs HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "711f6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smell_Test_Total\n",
      "Distribution\n",
      "All PwP\n",
      "Statistics = 0.934, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "All HCs\n",
      "Statistics = 0.890, p = 0.006\n",
      "Distribution is not normal\n",
      "\n",
      "Total PwP vs total HCs\n",
      "Statistics = 0.235, p = 0.629\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = ELPDP\n",
    "a = 'Smell_Test_Total'\n",
    "df1[a].mask((df1[a] > 6), inplace=True)\n",
    "df1 = df1[df1[a].notna()]\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('All PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Check that distribution is normal with Shapiro test\n",
    "df2 = ELPDH\n",
    "df2[a].mask((df2[a] > 6), inplace=True)\n",
    "df2 = df2[df2[a].notna()]\n",
    "stat, p = st.shapiro(df2[a])\n",
    "print('All HCs')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "# Check that distribution is normal with Shapiro test\n",
    "stat, p = st.levene(df1[a], df2[a], center= 'mean')\n",
    "print('Total PwP vs total HCs')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "81f281ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All PwP vs all HCs\n",
      "Statistics = 964.000, p = 0.00710\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution non-normal, variances equal, therefore use Mann-Whitney U test:\n",
    "print('All PwP vs all HCs')\n",
    "stat, p = st.mannwhitneyu(x=df1[a], y=df2[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.5f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')\n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5a4c8",
   "metadata": {},
   "source": [
    "PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f0a9e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smell_Test_Total\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = 0.934, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.901, p = 0.001\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.918, p = 0.007\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.894, p = 0.294\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.030, p = 0.862\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1.078, p = 0.304\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.907, p = 0.174\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "a = 'Smell_Test_Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f3d032bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 872.500, p = 0.911\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 233.500, p = 0.018\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 71.000, p = 0.037\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances -  Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecd354",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d787fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  83\n",
      "White and Black PD patients count:  50\n",
      "Black and South Asian PD patients count:  47\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "59e40b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  Smell_Test_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    43\n",
      "0    40\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685566\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   83\n",
      "Model:                          Logit   Df Residuals:                       81\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01000\n",
      "Time:                        14:25:38   Log-Likelihood:                -56.902\n",
      "converged:                       True   LL-Null:                       -57.477\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2835\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Smell_Test_Total         -0.0098      0.095     -0.104      0.917      -0.196       0.176\n",
      "DaysSinceSymptomOnset  7.513e-05   7.86e-05      0.956      0.339   -7.89e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.9174100109518143\n",
      "\n",
      "Exposure  Smell_Test_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    43\n",
      "0    40\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681275\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   83\n",
      "Model:                          Logit   Df Residuals:                       79\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01620\n",
      "Time:                        14:25:38   Log-Likelihood:                -56.546\n",
      "converged:                       True   LL-Null:                       -57.477\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6015\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Smell_Test_Total          0.0025      0.144      0.018      0.986      -0.279       0.284\n",
      "DaysSinceSymptomOnset  7.069e-05   9.76e-05      0.725      0.469      -0.000       0.000\n",
      "Age                       0.0034      0.008      0.440      0.660      -0.012       0.019\n",
      "Gender                   -0.3729      0.450     -0.829      0.407      -1.254       0.508\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.9859787652303883\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8711c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  Smell_Test_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    43\n",
      "0     7\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.323532\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   50\n",
      "Model:                          Logit   Df Residuals:                       48\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.2011\n",
      "Time:                        14:25:40   Log-Likelihood:                -16.177\n",
      "converged:                       True   LL-Null:                       -20.248\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.004322\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Smell_Test_Total          0.8378      0.305      2.748      0.006       0.240       1.435\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.040      0.298      -0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.005987308804113678\n",
      "\n",
      "Exposure  Smell_Test_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    43\n",
      "0     7\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.265962\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   50\n",
      "Model:                          Logit   Df Residuals:                       46\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.3432\n",
      "Time:                        14:25:40   Log-Likelihood:                -13.298\n",
      "converged:                       True   LL-Null:                       -20.248\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.003044\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Smell_Test_Total          1.0083      0.549      1.838      0.066      -0.067       2.083\n",
      "DaysSinceSymptomOnset     0.0004      0.000      1.415      0.157      -0.000       0.001\n",
      "Age                      -0.0249      0.018     -1.387      0.166      -0.060       0.010\n",
      "Gender                    2.2623      1.196      1.891      0.059      -0.082       4.607\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.06605626538915405\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c41b4237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  Smell_Test_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    40\n",
      "0     7\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.369546\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   47\n",
      "Model:                          Logit   Df Residuals:                       45\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1219\n",
      "Time:                        14:25:40   Log-Likelihood:                -17.369\n",
      "converged:                       True   LL-Null:                       -19.780\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02807\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Smell_Test_Total          0.8002      0.292      2.737      0.006       0.227       1.373\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.775      0.438      -0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.006203132570380204\n",
      "\n",
      "Exposure  Smell_Test_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    40\n",
      "0     7\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.314911\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   47\n",
      "Model:                          Logit   Df Residuals:                       43\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.2517\n",
      "Time:                        14:25:40   Log-Likelihood:                -14.801\n",
      "converged:                       True   LL-Null:                       -19.780\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01892\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Smell_Test_Total          0.5420      0.348      1.558      0.119      -0.140       1.224\n",
      "DaysSinceSymptomOnset -4.087e-05      0.000     -0.154      0.878      -0.001       0.000\n",
      "Age                    4.949e-05      0.012      0.004      0.997      -0.024       0.024\n",
      "Gender                    2.3222      1.218      1.907      0.056      -0.064       4.709\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.11929732986896709\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0e5ad",
   "metadata": {},
   "source": [
    "# HADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613749d",
   "metadata": {},
   "source": [
    "## HADS-D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091d019",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "00f3bd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HADQ_DepressionTotal\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  7.1\n",
      "SD:  4.5\n",
      "\n",
      "White\n",
      "Mean:  6.3\n",
      "SD:  3.8\n",
      "\n",
      "South Asian\n",
      "Mean:  8.5\n",
      "SD:  5.2\n",
      "\n",
      "Black\n",
      "Mean:  6.8\n",
      "SD:  4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'HADQ_DepressionTotal'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 21), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16a277",
   "metadata": {},
   "source": [
    "### SIgnificance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2b5c5814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HADQ_DepressionTotal\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.951, p = 0.005\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.966, p = 0.139\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.925, p = 0.205\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 4.593, p = 0.034\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.859, p = 0.357\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.285, p = 0.595\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'HADQ_DepressionTotal'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8fc0a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 5.539, p = 0.019\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 560.500, p = 0.627\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  -1.2 DOF:  67.0\n",
      "Difference is not significant, p =  0.245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "    \n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ',\"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4516f5d",
   "metadata": {},
   "source": [
    "### SIgnificance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cf1f709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  129\n",
      "White and Black PD patients count:  92\n",
      "Black and South Asian PD patients count:  69\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d63e3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  HADQ_DepressionTotal  adjusted by  DaysSinceSymptomOnset\n",
      "1    76\n",
      "0    53\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652749\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  129\n",
      "Model:                          Logit   Df Residuals:                      127\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03606\n",
      "Time:                        14:25:47   Log-Likelihood:                -84.205\n",
      "converged:                       True   LL-Null:                       -87.355\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01207\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADQ_DepressionTotal     -0.0587      0.030     -1.946      0.052      -0.118       0.000\n",
      "DaysSinceSymptomOnset     0.0002   8.47e-05      2.872      0.004    7.72e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.05169065930338626\n",
      "\n",
      "Exposure  HADQ_DepressionTotal  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    76\n",
      "0    53\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623852\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  129\n",
      "Model:                          Logit   Df Residuals:                      125\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.07873\n",
      "Time:                        14:25:47   Log-Likelihood:                -80.477\n",
      "converged:                       True   LL-Null:                       -87.355\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.003258\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADQ_DepressionTotal     -0.1387      0.044     -3.173      0.002      -0.224      -0.053\n",
      "DaysSinceSymptomOnset     0.0001    9.2e-05      1.221      0.222    -6.8e-05       0.000\n",
      "Age                       0.0157      0.007      2.241      0.025       0.002       0.029\n",
      "Gender                    0.0810      0.385      0.210      0.833      -0.674       0.836\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0015088509845504901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e5996911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  HADQ_DepressionTotal  adjusted by  DaysSinceSymptomOnset\n",
      "1    76\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498240\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   92\n",
      "Model:                          Logit   Df Residuals:                       90\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.07836\n",
      "Time:                        14:25:47   Log-Likelihood:                -45.838\n",
      "converged:                       True   LL-Null:                       -42.507\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADQ_DepressionTotal      0.0956      0.050      1.920      0.055      -0.002       0.193\n",
      "DaysSinceSymptomOnset     0.0003      0.000      2.175      0.030    2.61e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.05483602060307576\n",
      "\n",
      "Exposure  HADQ_DepressionTotal  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    76\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447370\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   92\n",
      "Model:                          Logit   Df Residuals:                       88\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03174\n",
      "Time:                        14:25:47   Log-Likelihood:                -41.158\n",
      "converged:                       True   LL-Null:                       -42.507\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4404\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADQ_DepressionTotal     -0.0565      0.072     -0.780      0.435      -0.198       0.085\n",
      "DaysSinceSymptomOnset  4.004e-05      0.000      0.324      0.746      -0.000       0.000\n",
      "Age                       0.0233      0.011      2.192      0.028       0.002       0.044\n",
      "Gender                    0.3575      0.564      0.634      0.526      -0.747       1.462\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.4353295143070276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2164510637.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e2bf201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  HADQ_DepressionTotal  adjusted by  DaysSinceSymptomOnset\n",
      "1    53\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543532\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   69\n",
      "Model:                          Logit   Df Residuals:                       67\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:               -0.003673\n",
      "Time:                        14:25:48   Log-Likelihood:                -37.504\n",
      "converged:                       True   LL-Null:                       -37.366\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADQ_DepressionTotal      0.1380      0.051      2.679      0.007       0.037       0.239\n",
      "DaysSinceSymptomOnset -8.516e-06      0.000     -0.059      0.953      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.007385814707558443\n",
      "\n",
      "Exposure  HADQ_DepressionTotal  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    53\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.526174\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   69\n",
      "Model:                          Logit   Df Residuals:                       65\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02838\n",
      "Time:                        14:25:48   Log-Likelihood:                -36.306\n",
      "converged:                       True   LL-Null:                       -37.366\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.5477\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADQ_DepressionTotal      0.0844      0.064      1.311      0.190      -0.042       0.211\n",
      "DaysSinceSymptomOnset    -0.0001      0.000     -0.770      0.441      -0.000       0.000\n",
      "Age                       0.0087      0.010      0.872      0.383      -0.011       0.028\n",
      "Gender                    0.4375      0.552      0.792      0.428      -0.645       1.520\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.18986488080356034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1790320347.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265621c8",
   "metadata": {},
   "source": [
    "## HADS-A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981759e",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "402e289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HADSQ_AnxietyTotal\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  6.9\n",
      "SD:  4.6\n",
      "\n",
      "White\n",
      "Mean:  6.2\n",
      "SD:  4.3\n",
      "\n",
      "South Asian\n",
      "Mean:  7.9\n",
      "SD:  5.0\n",
      "\n",
      "Black\n",
      "Mean:  6.9\n",
      "SD:  4.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'HADSQ_AnxietyTotal'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 21), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8981f",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "47c756dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HADSQ_AnxietyTotal\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.946, p = 0.003\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.941, p = 0.010\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.956, p = 0.593\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 4.250, p = 0.041\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.033, p = 0.857\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 1.208, p = 0.276\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'HADSQ_AnxietyTotal'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5b5b1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 3.128, p = 0.077\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 539.500, p = 0.482\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 385.000, p = 0.514\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796ebf4",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c66c39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  130\n",
      "White and Black PD patients count:  92\n",
      "Black and South Asian PD patients count:  70\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d7710f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  HADSQ_AnxietyTotal  adjusted by  DaysSinceSymptomOnset\n",
      "1    76\n",
      "0    53\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660661\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  129\n",
      "Model:                          Logit   Df Residuals:                      127\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02438\n",
      "Time:                        14:25:59   Log-Likelihood:                -85.225\n",
      "converged:                       True   LL-Null:                       -87.355\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.03905\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADSQ_AnxietyTotal       -0.0402      0.029     -1.372      0.170      -0.098       0.017\n",
      "DaysSinceSymptomOnset     0.0002   7.98e-05      2.553      0.011    4.73e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.17000099760499254\n",
      "\n",
      "Exposure  HADSQ_AnxietyTotal  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    76\n",
      "0    53\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646857\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  129\n",
      "Model:                          Logit   Df Residuals:                      125\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.04476\n",
      "Time:                        14:25:59   Log-Likelihood:                -83.444\n",
      "converged:                       True   LL-Null:                       -87.355\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04988\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADSQ_AnxietyTotal       -0.0852      0.038     -2.234      0.026      -0.160      -0.010\n",
      "DaysSinceSymptomOnset     0.0001   9.19e-05      1.156      0.248   -7.39e-05       0.000\n",
      "Age                       0.0097      0.006      1.512      0.131      -0.003       0.022\n",
      "Gender                    0.0736      0.377      0.195      0.845      -0.665       0.813\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.02551009821655217\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "85fd9440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  HADSQ_AnxietyTotal  adjusted by  DaysSinceSymptomOnset\n",
      "1    76\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499327\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   92\n",
      "Model:                          Logit   Df Residuals:                       90\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.08071\n",
      "Time:                        14:25:59   Log-Likelihood:                -45.938\n",
      "converged:                       True   LL-Null:                       -42.507\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADSQ_AnxietyTotal        0.0879      0.047      1.873      0.061      -0.004       0.180\n",
      "DaysSinceSymptomOnset     0.0003      0.000      2.392      0.017    5.05e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.06106936777002053\n",
      "\n",
      "Exposure  HADSQ_AnxietyTotal  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    76\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.448439\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   92\n",
      "Model:                          Logit   Df Residuals:                       88\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02943\n",
      "Time:                        14:25:59   Log-Likelihood:                -41.256\n",
      "converged:                       True   LL-Null:                       -42.507\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4749\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADSQ_AnxietyTotal       -0.0394      0.061     -0.649      0.517      -0.159       0.080\n",
      "DaysSinceSymptomOnset  3.385e-05      0.000      0.268      0.788      -0.000       0.000\n",
      "Age                       0.0219      0.010      2.163      0.031       0.002       0.042\n",
      "Gender                    0.3590      0.560      0.641      0.522      -0.739       1.458\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.5166330042159244\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "598e3cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  HADSQ_AnxietyTotal  adjusted by  DaysSinceSymptomOnset\n",
      "1    53\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563385\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   69\n",
      "Model:                          Logit   Df Residuals:                       67\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.04033\n",
      "Time:                        14:26:00   Log-Likelihood:                -38.874\n",
      "converged:                       True   LL-Null:                       -37.366\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADSQ_AnxietyTotal        0.1181      0.052      2.261      0.024       0.016       0.220\n",
      "DaysSinceSymptomOnset  3.967e-05      0.000      0.268      0.788      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.02372861933464231\n",
      "\n",
      "Exposure  HADSQ_AnxietyTotal  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    53\n",
      "0    16\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530584\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   69\n",
      "Model:                          Logit   Df Residuals:                       65\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02024\n",
      "Time:                        14:26:00   Log-Likelihood:                -36.610\n",
      "converged:                       True   LL-Null:                       -37.366\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6794\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "HADSQ_AnxietyTotal        0.0649      0.061      1.071      0.284      -0.054       0.184\n",
      "DaysSinceSymptomOnset    -0.0001      0.000     -0.848      0.396      -0.000       0.000\n",
      "Age                       0.0115      0.009      1.229      0.219      -0.007       0.030\n",
      "Gender                    0.5022      0.551      0.911      0.363      -0.579       1.583\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.28437426944548616\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dcc1b",
   "metadata": {},
   "source": [
    "# RBDSQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563d757",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5f67889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBDSQ_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  4.6\n",
      "SD:  3.1\n",
      "\n",
      "White\n",
      "Mean:  3.9\n",
      "SD:  3.1\n",
      "\n",
      "South Asian\n",
      "Mean:  4.8\n",
      "SD:  3.1\n",
      "\n",
      "Black\n",
      "Mean:  5.9\n",
      "SD:  2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'RBDSQ_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 13), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c023313",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "51e3e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBDSQ_Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.879, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.939, p = 0.027\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.916, p = 0.290\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.460, p = 0.500\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1.213, p = 0.275\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 2.921, p = 0.094\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "df1 = df\n",
    "a = 'RBDSQ_Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a314c09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 897.000, p = 0.177\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "White vs Black\n",
      "Statistics = 166.500, p = 0.035\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 279.500, p = 0.290\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ce941",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6507261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  93\n",
      "White and Black PD patients count:  62\n",
      "Black and South Asian PD patients count:  53\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b9aa0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  RBDSQ_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    51\n",
      "0    42\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680288\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   93\n",
      "Model:                          Logit   Df Residuals:                       91\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01187\n",
      "Time:                        14:26:05   Log-Likelihood:                -63.267\n",
      "converged:                       True   LL-Null:                       -64.027\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2177\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "RBDSQ_Total              -0.0566      0.054     -1.042      0.297      -0.163       0.050\n",
      "DaysSinceSymptomOnset     0.0001   8.23e-05      1.446      0.148   -4.23e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.2973470466886935\n",
      "\n",
      "Exposure  RBDSQ_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    51\n",
      "0    42\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.662162\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   93\n",
      "Model:                          Logit   Df Residuals:                       89\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03819\n",
      "Time:                        14:26:05   Log-Likelihood:                -61.581\n",
      "converged:                       True   LL-Null:                       -64.027\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1800\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "RBDSQ_Total              -0.1440      0.073     -1.961      0.050      -0.288   -9.43e-05\n",
      "DaysSinceSymptomOnset  4.606e-05   9.02e-05      0.511      0.610      -0.000       0.000\n",
      "Age                       0.0089      0.007      1.340      0.180      -0.004       0.022\n",
      "Gender                    0.2449      0.436      0.562      0.574      -0.610       1.099\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.049850077301942713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4b21b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  RBDSQ_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    51\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490010\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   62\n",
      "Model:                          Logit   Df Residuals:                       60\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.04825\n",
      "Time:                        14:26:06   Log-Likelihood:                -30.381\n",
      "converged:                       True   LL-Null:                       -28.982\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "RBDSQ_Total              -0.0202      0.086     -0.236      0.813      -0.188       0.147\n",
      "DaysSinceSymptomOnset     0.0006      0.000      2.737      0.006       0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.8130915444981865\n",
      "\n",
      "Exposure  RBDSQ_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    51\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.336962\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   62\n",
      "Model:                          Logit   Df Residuals:                       58\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.2792\n",
      "Time:                        14:26:06   Log-Likelihood:                -20.892\n",
      "converged:                       True   LL-Null:                       -28.982\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001041\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "RBDSQ_Total              -0.3937      0.158     -2.491      0.013      -0.704      -0.084\n",
      "DaysSinceSymptomOnset     0.0005      0.000      1.700      0.089   -7.24e-05       0.001\n",
      "Age                       0.0156      0.013      1.243      0.214      -0.009       0.040\n",
      "Gender                    2.8001      0.997      2.809      0.005       0.846       4.754\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.012743786383369234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3125225527.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2acf18aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  RBDSQ_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    42\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538526\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   53\n",
      "Model:                          Logit   Df Residuals:                       51\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.05451\n",
      "Time:                        14:26:06   Log-Likelihood:                -28.542\n",
      "converged:                       True   LL-Null:                       -27.066\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "RBDSQ_Total              -0.0094      0.097     -0.097      0.923      -0.200       0.181\n",
      "DaysSinceSymptomOnset     0.0005      0.000      1.989      0.047    7.31e-06       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.9227439637227957\n",
      "\n",
      "Exposure  RBDSQ_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    42\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.425596\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   53\n",
      "Model:                          Logit   Df Residuals:                       49\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1666\n",
      "Time:                        14:26:06   Log-Likelihood:                -22.557\n",
      "converged:                       True   LL-Null:                       -27.066\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02903\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "RBDSQ_Total              -0.3251      0.161     -2.024      0.043      -0.640      -0.010\n",
      "DaysSinceSymptomOnset     0.0003      0.000      1.303      0.193      -0.000       0.001\n",
      "Age                       0.0184      0.012      1.519      0.129      -0.005       0.042\n",
      "Gender                    2.3432      0.913      2.568      0.010       0.555       4.132\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.04298401278335627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c258883",
   "metadata": {},
   "source": [
    "# PSS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3584d7",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c3984c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSS2_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  19.5\n",
      "SD:  11.3\n",
      "\n",
      "White\n",
      "Mean:  17.1\n",
      "SD:  10.2\n",
      "\n",
      "South Asian\n",
      "Mean:  23.1\n",
      "SD:  11.7\n",
      "\n",
      "Black\n",
      "Mean:  19.0\n",
      "SD:  9.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'PSS2_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 60), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f686f",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "758cf554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSS2_Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.925, p = 0.002\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.986, p = 0.892\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.945, p = 0.581\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 1.001, p = 0.320\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.013, p = 0.910\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.267, p = 0.608\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "a = 'PSS2_Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "60005eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 748.000, p = 0.008\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "White vs Black\n",
      "Statistics = 259.500, p = 0.464\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  -1.1 DOF:  49.0\n",
      "Difference is not significant, p =  0.291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "    \n",
    "# Normal distribution, equal variances - t-test\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ',\"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a112f5",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b7ad59a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  95\n",
      "White and Black PD patients count:  66\n",
      "Black and South Asian PD patients count:  51\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4710dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  PSS2_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    55\n",
      "0    40\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646376\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   95\n",
      "Model:                          Logit   Df Residuals:                       93\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05033\n",
      "Time:                        14:26:12   Log-Likelihood:                -61.406\n",
      "converged:                       True   LL-Null:                       -64.660\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01074\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "PSS2_Total               -0.0281      0.014     -1.973      0.049      -0.056      -0.000\n",
      "DaysSinceSymptomOnset     0.0003      0.000      2.580      0.010    6.59e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.048518889283341006\n",
      "\n",
      "Exposure  PSS2_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    55\n",
      "0    40\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617896\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   95\n",
      "Model:                          Logit   Df Residuals:                       91\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.09217\n",
      "Time:                        14:26:12   Log-Likelihood:                -58.700\n",
      "converged:                       True   LL-Null:                       -64.660\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.007665\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "PSS2_Total               -0.0583      0.020     -2.935      0.003      -0.097      -0.019\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.358      0.174   -6.91e-05       0.000\n",
      "Age                       0.0147      0.008      1.833      0.067      -0.001       0.030\n",
      "Gender                    0.1444      0.439      0.329      0.742      -0.715       1.004\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0033341251110631767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f787fd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  PSS2_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    55\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482545\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   66\n",
      "Model:                          Logit   Df Residuals:                       64\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.07099\n",
      "Time:                        14:26:12   Log-Likelihood:                -31.848\n",
      "converged:                       True   LL-Null:                       -29.737\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "PSS2_Total                0.0333      0.025      1.350      0.177      -0.015       0.082\n",
      "DaysSinceSymptomOnset     0.0003      0.000      1.812      0.070   -2.47e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.17699672288416346\n",
      "\n",
      "Exposure  PSS2_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    55\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412979\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   66\n",
      "Model:                          Logit   Df Residuals:                       62\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.08341\n",
      "Time:                        14:26:12   Log-Likelihood:                -27.257\n",
      "converged:                       True   LL-Null:                       -29.737\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1747\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "PSS2_Total               -0.0220      0.032     -0.682      0.495      -0.085       0.041\n",
      "DaysSinceSymptomOnset     0.0002      0.000      0.924      0.356      -0.000       0.001\n",
      "Age                       0.0128      0.012      1.099      0.272      -0.010       0.036\n",
      "Gender                    1.2977      0.701      1.852      0.064      -0.076       2.671\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.4949243769693207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3125225527.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "1d63a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  PSS2_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    40\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516028\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   51\n",
      "Model:                          Logit   Df Residuals:                       49\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01029\n",
      "Time:                        14:26:13   Log-Likelihood:                -26.317\n",
      "converged:                       True   LL-Null:                       -26.591\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4594\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "PSS2_Total                0.0606      0.026      2.365      0.018       0.010       0.111\n",
      "DaysSinceSymptomOnset -3.761e-05      0.000     -0.193      0.847      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.018025119707768662\n",
      "\n",
      "Exposure  PSS2_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    40\n",
      "0    11\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.481101\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   51\n",
      "Model:                          Logit   Df Residuals:                       47\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.07728\n",
      "Time:                        14:26:13   Log-Likelihood:                -24.536\n",
      "converged:                       True   LL-Null:                       -26.591\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2498\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "PSS2_Total                0.0433      0.033      1.321      0.187      -0.021       0.108\n",
      "DaysSinceSymptomOnset    -0.0002      0.000     -0.747      0.455      -0.001       0.000\n",
      "Age                       0.0029      0.012      0.249      0.803      -0.020       0.026\n",
      "Gender                    1.1904      0.700      1.701      0.089      -0.181       2.562\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.18653048246998927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582e9c9",
   "metadata": {},
   "source": [
    "# ESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658a178",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5c430138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EpworthSleepScale_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  9.4\n",
      "SD:  6.4\n",
      "\n",
      "White\n",
      "Mean:  8.7\n",
      "SD:  5.5\n",
      "\n",
      "South Asian\n",
      "Mean:  10.7\n",
      "SD:  7.1\n",
      "\n",
      "Black\n",
      "Mean:  9.3\n",
      "SD:  6.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'EpworthSleepScale_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 24), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae72d2",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6e56186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EpworthSleepScale_Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.967, p = 0.016\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.951, p = 0.003\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.942, p = 0.222\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 9.008, p = 0.003\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1.620, p = 0.206\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.452, p = 0.503\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "a = 'EpworthSleepScale_Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "96da5f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 3.225, p = 0.073\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 987.000, p = 0.743\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 832.000, p = 0.475\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f744cbe",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8915617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  178\n",
      "White and Black PD patients count:  116\n",
      "Black and South Asian PD patients count:  106\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "66808a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  EpworthSleepScale_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    94\n",
      "0    84\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683907\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  178\n",
      "Model:                          Logit   Df Residuals:                      176\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01108\n",
      "Time:                        14:26:17   Log-Likelihood:                -121.74\n",
      "converged:                       True   LL-Null:                       -123.10\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.09863\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "EpworthSleepScale_Total    -0.0304      0.019     -1.606      0.108      -0.068       0.007\n",
      "DaysSinceSymptomOnset       0.0001   6.03e-05      1.681      0.093   -1.68e-05       0.000\n",
      "===========================================================================================\n",
      "Full p-value for exposure:  0.10826078194038433\n",
      "\n",
      "Exposure  EpworthSleepScale_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    94\n",
      "0    84\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668996\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  178\n",
      "Model:                          Logit   Df Residuals:                      174\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03264\n",
      "Time:                        14:26:17   Log-Likelihood:                -119.08\n",
      "converged:                       True   LL-Null:                       -123.10\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04528\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "EpworthSleepScale_Total    -0.0649      0.025     -2.606      0.009      -0.114      -0.016\n",
      "DaysSinceSymptomOnset    2.599e-05   6.75e-05      0.385      0.700      -0.000       0.000\n",
      "Age                         0.0104      0.005      1.995      0.046       0.000       0.021\n",
      "Gender                      0.0021      0.315      0.007      0.995      -0.616       0.620\n",
      "===========================================================================================\n",
      "Full p-value for exposure:  0.00916801000324631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "79f28335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  EpworthSleepScale_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    94\n",
      "0    22\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.522828\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      114\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.07639\n",
      "Time:                        14:26:17   Log-Likelihood:                -60.648\n",
      "converged:                       True   LL-Null:                       -56.344\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "EpworthSleepScale_Total     0.0528      0.035      1.489      0.137      -0.017       0.122\n",
      "DaysSinceSymptomOnset       0.0003      0.000      2.292      0.022    3.98e-05       0.001\n",
      "===========================================================================================\n",
      "Full p-value for exposure:  0.13657601447950887\n",
      "\n",
      "Exposure  EpworthSleepScale_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    94\n",
      "0    22\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.473064\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  116\n",
      "Model:                          Logit   Df Residuals:                      112\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02606\n",
      "Time:                        14:26:17   Log-Likelihood:                -54.875\n",
      "converged:                       True   LL-Null:                       -56.344\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4015\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "EpworthSleepScale_Total    -0.0221      0.042     -0.531      0.595      -0.103       0.059\n",
      "DaysSinceSymptomOnset    9.431e-05      0.000      0.763      0.445      -0.000       0.000\n",
      "Age                         0.0135      0.008      1.770      0.077      -0.001       0.028\n",
      "Gender                      0.7473      0.473      1.578      0.114      -0.181       1.675\n",
      "===========================================================================================\n",
      "Full p-value for exposure:  0.5953937713997572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3125225527.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7635aae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  EpworthSleepScale_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    84\n",
      "0    22\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.527713\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  106\n",
      "Model:                          Logit   Df Residuals:                      104\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.03334\n",
      "Time:                        14:26:17   Log-Likelihood:                -55.938\n",
      "converged:                       True   LL-Null:                       -54.133\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "EpworthSleepScale_Total     0.0719      0.031      2.288      0.022       0.010       0.134\n",
      "DaysSinceSymptomOnset       0.0002      0.000      1.427      0.154   -6.11e-05       0.000\n",
      "===========================================================================================\n",
      "Full p-value for exposure:  0.02210975013895939\n",
      "\n",
      "Exposure  EpworthSleepScale_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    84\n",
      "0    22\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501926\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  106\n",
      "Model:                          Logit   Df Residuals:                      102\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01716\n",
      "Time:                        14:26:17   Log-Likelihood:                -53.204\n",
      "converged:                       True   LL-Null:                       -54.133\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6025\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "EpworthSleepScale_Total     0.0332      0.036      0.911      0.362      -0.038       0.105\n",
      "DaysSinceSymptomOnset    3.934e-05      0.000      0.305      0.760      -0.000       0.000\n",
      "Age                         0.0060      0.007      0.811      0.417      -0.008       0.020\n",
      "Gender                      0.7943      0.460      1.727      0.084      -0.107       1.696\n",
      "===========================================================================================\n",
      "Full p-value for exposure:  0.36221817572922355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1feaeb",
   "metadata": {},
   "source": [
    "# SCOPA- AUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa655280",
   "metadata": {},
   "source": [
    "## PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "98b96ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOPA_Total\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  17.5\n",
      "SD:  10.3\n",
      "\n",
      "White\n",
      "Mean:  18.1\n",
      "SD:  9.6\n",
      "\n",
      "South Asian\n",
      "Mean:  17.5\n",
      "SD:  10.7\n",
      "\n",
      "Black\n",
      "Mean:  16.9\n",
      "SD:  12.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'SCOPA_Total'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 75), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4a741",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ad069f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOPA_Total\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.958, p = 0.080\n",
      "Distribution is normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.953, p = 0.124\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.810, p = 0.026\n",
      "Distribution is not normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.396, p = 0.531\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.066, p = 0.798\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.006, p = 0.939\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "a = 'SCOPA_Total'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a0f6abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "T:  0.3 DOF:  83.0\n",
      "Difference is not significant, p =  0.776\n",
      "\n",
      "\n",
      "White vs Black\n",
      "Statistics = 250.500, p = 0.456\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 143.500, p = 0.533\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normal distribution, equal variances - t-test\n",
    "print('White vs South Asian')\n",
    "summary, results = rp.ttest(group1= W[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ',\"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35340d09",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "28d600d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  85\n",
      "White and Black PD patients count:  57\n",
      "Black and South Asian PD patients count:  46\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1391ebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  SCOPA_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    48\n",
      "0    37\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.664263\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   85\n",
      "Model:                          Logit   Df Residuals:                       83\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02992\n",
      "Time:                        14:26:22   Log-Likelihood:                -56.462\n",
      "converged:                       True   LL-Null:                       -58.204\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06201\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "SCOPA_Total              -0.0101      0.017     -0.611      0.541      -0.043       0.022\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.726      0.084   -2.45e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.5410362870494134\n",
      "\n",
      "Exposure  SCOPA_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    48\n",
      "0    37\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.663467\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   85\n",
      "Model:                          Logit   Df Residuals:                       81\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03108\n",
      "Time:                        14:26:22   Log-Likelihood:                -56.395\n",
      "converged:                       True   LL-Null:                       -58.204\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3058\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "SCOPA_Total              -0.0159      0.023     -0.689      0.491      -0.061       0.029\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.452      0.147   -5.75e-05       0.000\n",
      "Age                       0.0024      0.008      0.317      0.751      -0.013       0.017\n",
      "Gender                    0.0194      0.449      0.043      0.966      -0.861       0.900\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.4905451385798437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "665ad3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  SCOPA_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    48\n",
      "0     9\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.436874\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   57\n",
      "Model:                          Logit   Df Residuals:                       55\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:               -0.001632\n",
      "Time:                        14:26:23   Log-Likelihood:                -24.902\n",
      "converged:                       True   LL-Null:                       -24.861\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "SCOPA_Total               0.0348      0.031      1.118      0.263      -0.026       0.096\n",
      "DaysSinceSymptomOnset     0.0004      0.000      1.645      0.100   -7.32e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.263451543684074\n",
      "\n",
      "Exposure  SCOPA_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    48\n",
      "0     9\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.352042\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   57\n",
      "Model:                          Logit   Df Residuals:                       53\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1929\n",
      "Time:                        14:26:23   Log-Likelihood:                -20.066\n",
      "converged:                       True   LL-Null:                       -24.861\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02240\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "SCOPA_Total              -0.0175      0.039     -0.448      0.654      -0.094       0.059\n",
      "DaysSinceSymptomOnset     0.0005      0.000      1.634      0.102   -9.24e-05       0.001\n",
      "Age                      -0.0022      0.013     -0.175      0.861      -0.027       0.023\n",
      "Gender                    2.3280      0.928      2.509      0.012       0.510       4.146\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.6544423379932013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3125225527.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "dab59b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  SCOPA_Total  adjusted by  DaysSinceSymptomOnset\n",
      "1    37\n",
      "0     9\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.525122\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   46\n",
      "Model:                          Logit   Df Residuals:                       44\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.06232\n",
      "Time:                        14:26:23   Log-Likelihood:                -24.156\n",
      "converged:                       True   LL-Null:                       -22.739\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "SCOPA_Total               0.0343      0.033      1.055      0.291      -0.029       0.098\n",
      "DaysSinceSymptomOnset     0.0003      0.000      1.103      0.270      -0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.2914324180189577\n",
      "\n",
      "Exposure  SCOPA_Total  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    37\n",
      "0     9\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.443458\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   46\n",
      "Model:                          Logit   Df Residuals:                       42\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1029\n",
      "Time:                        14:26:23   Log-Likelihood:                -20.399\n",
      "converged:                       True   LL-Null:                       -22.739\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1969\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "SCOPA_Total               0.0013      0.038      0.033      0.973      -0.073       0.076\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.362      0.717      -0.000       0.001\n",
      "Age                       0.0054      0.011      0.493      0.622      -0.016       0.027\n",
      "Gender                    1.8576      0.844      2.202      0.028       0.204       3.511\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.9733677526407297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6df9f7",
   "metadata": {},
   "source": [
    "# EQ5D5L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049c0e0",
   "metadata": {},
   "source": [
    "## VAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d6726",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f14aa31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQ5D_VAS\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  59.4\n",
      "SD:  20.8\n",
      "\n",
      "White\n",
      "Mean:  63.7\n",
      "SD:  16.7\n",
      "\n",
      "South Asian\n",
      "Mean:  53.3\n",
      "SD:  21.8\n",
      "\n",
      "Black\n",
      "Mean:  60.4\n",
      "SD:  22.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'EQ5D_VAS'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 100), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1cb0f",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f1eb77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQ5D_VAS\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.963, p = 0.009\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.977, p = 0.137\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.927, p = 0.094\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 3.698, p = 0.056\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1.416, p = 0.236\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.016, p = 0.899\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "a = 'EQ5D_VAS'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6cf9ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 5116.000, p = 0.0011\n",
      "Difference is significant\n",
      "\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1129.500, p = 0.740\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  1.38 DOF:  106.0\n",
      "Difference is significant, p =  0.171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.4f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "    \n",
    "# Normal distribution, equal variances - t-test\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1 = B[a], group2 = SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('T: ', \"%.2f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ',\"%.2f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c8e04",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "39fe6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  179\n",
      "White and Black PD patients count:  117\n",
      "Black and South Asian PD patients count:  108\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "02dea79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  EQ5D_VAS  adjusted by  DaysSinceSymptomOnset\n",
      "1    94\n",
      "0    85\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682648\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  179\n",
      "Model:                          Logit   Df Residuals:                      177\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01335\n",
      "Time:                        14:26:30   Log-Likelihood:                -122.19\n",
      "converged:                       True   LL-Null:                       -123.85\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06903\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5D_VAS                  0.0062      0.003      1.795      0.073      -0.001       0.013\n",
      "DaysSinceSymptomOnset -4.659e-05   5.82e-05     -0.801      0.423      -0.000    6.74e-05\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.07259100677180563\n",
      "\n",
      "Exposure  EQ5D_VAS  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    94\n",
      "0    85\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674925\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  179\n",
      "Model:                          Logit   Df Residuals:                      175\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02451\n",
      "Time:                        14:26:30   Log-Likelihood:                -120.81\n",
      "converged:                       True   LL-Null:                       -123.85\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1082\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5D_VAS                  0.0156      0.007      2.254      0.024       0.002       0.029\n",
      "DaysSinceSymptomOnset -5.278e-07    6.6e-05     -0.008      0.994      -0.000       0.000\n",
      "Age                      -0.0087      0.007     -1.223      0.221      -0.023       0.005\n",
      "Gender                   -0.2219      0.309     -0.717      0.473      -0.828       0.385\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.024185287116399223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "aa1ea158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  EQ5D_VAS  adjusted by  DaysSinceSymptomOnset\n",
      "1    94\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492956\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      115\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.005387\n",
      "Time:                        14:26:30   Log-Likelihood:                -57.676\n",
      "converged:                       True   LL-Null:                       -57.988\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4293\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5D_VAS                  0.0178      0.006      3.206      0.001       0.007       0.029\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.951      0.342      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0013461319306167022\n",
      "\n",
      "Exposure  EQ5D_VAS  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    94\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.485059\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      113\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02132\n",
      "Time:                        14:26:30   Log-Likelihood:                -56.752\n",
      "converged:                       True   LL-Null:                       -57.988\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4802\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5D_VAS                  0.0105      0.011      0.964      0.335      -0.011       0.032\n",
      "DaysSinceSymptomOnset  7.594e-05      0.000      0.661      0.509      -0.000       0.000\n",
      "Age                       0.0030      0.011      0.273      0.785      -0.018       0.024\n",
      "Gender                    0.5721      0.468      1.222      0.222      -0.345       1.490\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.33520722737903297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3125225527.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d3cf6d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  EQ5D_VAS  adjusted by  DaysSinceSymptomOnset\n",
      "1    85\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540100\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  108\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.04295\n",
      "Time:                        14:26:31   Log-Likelihood:                -58.331\n",
      "converged:                       True   LL-Null:                       -55.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5D_VAS                  0.0103      0.005      1.920      0.055      -0.000       0.021\n",
      "DaysSinceSymptomOnset     0.0002      0.000      2.073      0.038    1.22e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.05484960823344552\n",
      "\n",
      "Exposure  EQ5D_VAS  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    85\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516285\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  108\n",
      "Model:                          Logit   Df Residuals:                      104\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.003035\n",
      "Time:                        14:26:31   Log-Likelihood:                -55.759\n",
      "converged:                       True   LL-Null:                       -55.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9524\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5D_VAS                 -0.0041      0.010     -0.409      0.682      -0.024       0.015\n",
      "DaysSinceSymptomOnset  7.915e-05      0.000      0.613      0.540      -0.000       0.000\n",
      "Age                       0.0120      0.011      1.126      0.260      -0.009       0.033\n",
      "Gender                    0.7805      0.452      1.726      0.084      -0.106       1.667\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.6823714054420928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06ecd2",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625e5c9",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "731e62e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "EQ5Dindex\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  0.47\n",
      "SD:  0.30\n",
      "\n",
      "White\n",
      "Mean:  0.53\n",
      "SD:  0.26\n",
      "\n",
      "South Asian\n",
      "Mean:  0.38\n",
      "SD:  0.31\n",
      "\n",
      "Black\n",
      "Mean:  0.45\n",
      "SD:  0.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'EQ5Dindex'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "print(df[a].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.2f\" % score.mean())\n",
    "print(\"SD: \", \"%.2f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.2f\" % score.mean())\n",
    "print(\"SD: \", \"%.2f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.2f\" % score.mean())\n",
    "print(\"SD: \", \"%.2f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.2f\" % score.mean())\n",
    "print(\"SD: \", \"%.2f\"  % score.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefffd0a",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "8c493ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQ5Dindex\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.924, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.979, p = 0.177\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.967, p = 0.614\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 6.611, p = 0.011\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 2.924, p = 0.090\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.005, p = 0.944\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "a = 'EQ5Dindex'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "9cf797e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 12.205, p = 0.000\n",
      "Difference is significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1228.000, p = 0.359\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "T:  1.06 DOF:  106.0\n",
      "Difference is significant, p =  0.293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Normal distribution, equal variances - t-test\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1 = B[a], group2 = SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] > alpha:\n",
    "    print('T: ', \"%.2f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ',\"%.2f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e7a55",
   "metadata": {},
   "source": [
    "### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "bd23733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  180\n",
      "White and Black PD patients count:  118\n",
      "Black and South Asian PD patients count:  108\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "49d9095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Exposure  EQ5Dindex  adjusted by  DaysSinceSymptomOnset\n",
      "1    95\n",
      "0    85\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673475\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  180\n",
      "Model:                          Logit   Df Residuals:                      178\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02621\n",
      "Time:                        14:47:48   Log-Likelihood:                -121.23\n",
      "converged:                       True   LL-Null:                       -124.49\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01063\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5Dindex                 0.8884      0.355      2.505      0.012       0.193       1.584\n",
      "DaysSinceSymptomOnset  -4.64e-05    5.1e-05     -0.909      0.363      -0.000    5.36e-05\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.012257241013621734\n",
      "\n",
      "Exposure  EQ5Dindex  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    95\n",
      "0    85\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.666650\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  180\n",
      "Model:                          Logit   Df Residuals:                      176\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03608\n",
      "Time:                        14:47:48   Log-Likelihood:                -120.00\n",
      "converged:                       True   LL-Null:                       -124.49\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02951\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5Dindex                 1.4119      0.508      2.781      0.005       0.417       2.407\n",
      "DaysSinceSymptomOnset  1.115e-05   6.65e-05      0.168      0.867      -0.000       0.000\n",
      "Age                      -0.0046      0.005     -0.850      0.396      -0.015       0.006\n",
      "Gender                   -0.2582      0.314     -0.823      0.410      -0.873       0.357\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0054239189383451306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2117076295.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "12f67277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  EQ5Dindex  adjusted by  DaysSinceSymptomOnset\n",
      "1    95\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492467\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  118\n",
      "Model:                          Logit   Df Residuals:                      116\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.001632\n",
      "Time:                        14:47:48   Log-Likelihood:                -58.111\n",
      "converged:                       True   LL-Null:                       -58.206\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6629\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5Dindex                 1.7366      0.552      3.145      0.002       0.654       2.819\n",
      "DaysSinceSymptomOnset     0.0002   9.67e-05      1.827      0.068   -1.29e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.00165941155392324\n",
      "\n",
      "Exposure  EQ5Dindex  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    95\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.477100\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  118\n",
      "Model:                          Logit   Df Residuals:                      114\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03279\n",
      "Time:                        14:47:48   Log-Likelihood:                -56.298\n",
      "converged:                       True   LL-Null:                       -58.206\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2819\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5Dindex                 1.1193      0.766      1.461      0.144      -0.382       2.621\n",
      "DaysSinceSymptomOnset  8.361e-05      0.000      0.721      0.471      -0.000       0.000\n",
      "Age                       0.0035      0.008      0.418      0.676      -0.013       0.020\n",
      "Gender                    0.6630      0.471      1.407      0.159      -0.260       1.586\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.14402015337527477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3125225527.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "22971c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  EQ5Dindex  adjusted by  DaysSinceSymptomOnset\n",
      "1    85\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.547971\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  108\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.05815\n",
      "Time:                        14:47:49   Log-Likelihood:                -59.181\n",
      "converged:                       True   LL-Null:                       -55.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5Dindex                 0.7574      0.527      1.438      0.150      -0.275       1.789\n",
      "DaysSinceSymptomOnset     0.0003   9.43e-05      3.201      0.001       0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.15033843317942958\n",
      "\n",
      "Exposure  EQ5Dindex  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    85\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.515569\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  108\n",
      "Model:                          Logit   Df Residuals:                      104\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.004417\n",
      "Time:                        14:47:49   Log-Likelihood:                -55.681\n",
      "converged:                       True   LL-Null:                       -55.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9202\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "EQ5Dindex                -0.4131      0.730     -0.566      0.571      -1.843       1.017\n",
      "DaysSinceSymptomOnset  7.535e-05      0.000      0.587      0.557      -0.000       0.000\n",
      "Age                       0.0109      0.008      1.411      0.158      -0.004       0.026\n",
      "Gender                    0.8171      0.462      1.768      0.077      -0.089       1.723\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.5713738439353151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3272010089.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d89d83",
   "metadata": {},
   "source": [
    "# MERQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b24df",
   "metadata": {},
   "source": [
    "## Pesticides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee2033",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4f83d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  113\n",
      "n : 2\n",
      "%  1.8\n",
      "\n",
      "White\n",
      "n:  52\n",
      "n : 2\n",
      "%  3.8\n",
      "\n",
      "South Asian\n",
      "n:  45\n",
      "n : 0\n",
      "%  0.0\n",
      "\n",
      "Black\n",
      "n:  8\n",
      "n:  0\n",
      "%  0.0\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B1'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b1b95",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "2e50ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present      2            0      0\n",
      "Absent      50           45      8\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a : ['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "49904d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 0.98\n",
      "\n",
      "Difference is not significant, p:  0.6129 0.613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6ce7a",
   "metadata": {},
   "source": [
    "## Head innjury"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9e00e",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "745524fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  114\n",
      "n : 15\n",
      "%  13.2\n",
      "\n",
      "White\n",
      "n:  52\n",
      "n : 9\n",
      "%  17.3\n",
      "\n",
      "South Asian\n",
      "n:  45\n",
      "n : 5\n",
      "%  11.1\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  1\n",
      "%  11.1\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B11'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e35a7",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c71911af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present      9            5      1\n",
      "Absent      43           40      8\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "22944056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 0.84\n",
      "\n",
      "Difference is not significant, p:  0.6579 0.658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1047465",
   "metadata": {},
   "source": [
    "## Caffeine - previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d294a86",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "4b075fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  115\n",
      "n : 108\n",
      "%  93.9\n",
      "\n",
      "White\n",
      "n:  53\n",
      "n : 51\n",
      "%  96.2\n",
      "\n",
      "South Asian\n",
      "n:  45\n",
      "n : 41\n",
      "%  91.1\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  9\n",
      "%  100.0\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B6'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19f0d5",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "17d3f007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present     51           41      9\n",
      "Absent       2            4      0\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1952d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1.13\n",
      "\n",
      "Difference is not significant, p:  0.5677 0.568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57da77e",
   "metadata": {},
   "source": [
    "## Caffeine - current "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259603c3",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9cd1fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  115\n",
      "n : 97\n",
      "%  84.3\n",
      "\n",
      "White\n",
      "n:  53\n",
      "n : 47\n",
      "%  88.7\n",
      "\n",
      "South Asian\n",
      "n:  45\n",
      "n : 37\n",
      "%  82.2\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  7\n",
      "%  77.8\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B7'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a42582",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3435efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present     47           37      7\n",
      "Absent       6            8      2\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9593ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1.21\n",
      "\n",
      "Difference is not significant, p:  0.5471 0.547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72d65c",
   "metadata": {},
   "source": [
    "## Caffeine amount - previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068f58c",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "5b944a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERQ_PD_B6a\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  3.5\n",
      "SD:  2.1\n",
      "\n",
      "White\n",
      "Mean:  4.1\n",
      "SD:  2.3\n",
      "\n",
      "South Asian\n",
      "Mean:  3.1\n",
      "SD:  1.9\n",
      "\n",
      "Black\n",
      "Mean:  2.4\n",
      "SD:  0.8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2127976725.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2127976725.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B6a'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "df.replace('unknown', np.NaN, inplace=True)\n",
    "df.replace('2 to 3', np.NaN, inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "df[a] = pd.to_numeric(df[a])\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 20), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "df[a] = pd.to_numeric(df[a])\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630ea80",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a14d1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERQ_PD_B7a\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.135, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.912, p = 0.002\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.889, p = 0.195\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 3.432, p = 0.067\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.685, p = 0.411\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.253, p = 0.617\n",
      "Variances are equal\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2861333316.py:55: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2861333316.py:56: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\2861333316.py:57: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "df1[a] = pd.to_numeric(df1[a])\n",
    "a = 'MERQ_PD_B7a'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "W[a] = W[a].astype(float)\n",
    "SA[a] = SA[a].astype(float)\n",
    "B[a] = B[a].astype(float)\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center = 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "f2a65484",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "Statistics = 1298.000, p = 0.262\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "White vs Black\n",
      "Statistics = 311.000, p = 0.088\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 144.500, p = 0.166\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b087b75",
   "metadata": {},
   "source": [
    "## Caffeine amount - current "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fda95",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ac63a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERQ_PD_B7a\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  2.3\n",
      "SD:  1.9\n",
      "\n",
      "White\n",
      "Mean:  2.8\n",
      "SD:  2.3\n",
      "\n",
      "South Asian\n",
      "Mean:  2.1\n",
      "SD:  1.5\n",
      "\n",
      "Black\n",
      "Mean:  1.4\n",
      "SD:  1.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\4192529652.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\4192529652.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B7a'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "df.replace('unknown', np.NaN, inplace=True)\n",
    "df.replace('2 to 3', np.NaN, inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "df[a] = pd.to_numeric(df[a])\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 20), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "df[a] = pd.to_numeric(df[a])\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6fc72",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c8915cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERQ_PD_B7a\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.896, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.912, p = 0.002\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.889, p = 0.195\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 8.922, p = 0.004\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 3.893, p = 0.053\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.253, p = 0.617\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = df\n",
    "a = 'MERQ_PD_B7a'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4ac4d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 0.946, p = 0.331\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 302.000, p = 0.101\n",
      "Difference is not significant\n",
      "\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 144.500, p = 0.166\n",
      "Difference is not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9c7b79",
   "metadata": {},
   "source": [
    "## Alcohol - previous "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce129336",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "7311e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  104\n",
      "n : 52\n",
      "%  50.0\n",
      "\n",
      "White\n",
      "n:  48\n",
      "n : 36\n",
      "%  75.0\n",
      "\n",
      "South Asian\n",
      "n:  40\n",
      "n : 7\n",
      "%  17.5\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  6\n",
      "%  66.7\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B15'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773904e",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ade05610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present     36            7      6\n",
      "Absent      12           33      3\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c05e4b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 29.89\n",
      "\n",
      "Difference is significant, p:  0.0000 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468f88f",
   "metadata": {},
   "source": [
    "## Acohol - current "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dea12",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "a70e06d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  105\n",
      "n : 35\n",
      "%  33.3\n",
      "\n",
      "White\n",
      "n:  48\n",
      "n : 27\n",
      "%  56.2\n",
      "\n",
      "South Asian\n",
      "n:  41\n",
      "n : 1\n",
      "%  2.4\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  5\n",
      "%  55.6\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B16'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be208c35",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "1a4f4b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present     27            1      5\n",
      "Absent      21           40      4\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d0f7eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 30.79\n",
      "\n",
      "Difference is significant, p:  0.0000 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273ec03",
   "metadata": {},
   "source": [
    "## Smoking - previous "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af64527",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "eb9aa7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  115\n",
      "n : 34\n",
      "%  29.6\n",
      "\n",
      "White\n",
      "n:  53\n",
      "n : 24\n",
      "%  45.3\n",
      "\n",
      "South Asian\n",
      "n:  45\n",
      "n : 8\n",
      "%  17.8\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  0\n",
      "%  0.0\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B8'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1216a31",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "28337c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present     24            8      0\n",
      "Absent      29           37      9\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0f8d8efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 11.81\n",
      "\n",
      "Difference is significant, p:  0.0027 0.003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23303bae",
   "metadata": {},
   "source": [
    "## Smoking - current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5777572",
   "metadata": {},
   "source": [
    "### PwP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d59d7403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "All\n",
      "n:  114\n",
      "n : 6\n",
      "%  5.3\n",
      "\n",
      "White\n",
      "n:  52\n",
      "n : 4\n",
      "%  7.7\n",
      "\n",
      "South Asian\n",
      "n:  45\n",
      "n : 1\n",
      "%  2.2\n",
      "\n",
      "Black\n",
      "n:  9\n",
      "n:  0\n",
      "%  0.0\n"
     ]
    }
   ],
   "source": [
    "a = 'MERQ_PD_B9'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "print(df[b].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 1), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W = df[df[b]==1]\n",
    "SA = df[df[b]==3]\n",
    "B = df[df[b]==2]\n",
    "\n",
    "# Present exposure\n",
    "a1 = df[df[a]==1]\n",
    "a1 = a1[a].count()\n",
    "\n",
    "b = W[W[a]==1]\n",
    "b = b[a].count()\n",
    "\n",
    "c = SA[SA[a]==1]\n",
    "c = c[a].count()\n",
    "\n",
    "d = B[B[a]==1]\n",
    "d = d[a].count()\n",
    "\n",
    "\n",
    "# Absent exposure\n",
    "a2 = df[df[a]==0]\n",
    "a2 = a2[a].count()\n",
    "\n",
    "e = W[W[a]==0]\n",
    "e = e[a].count()\n",
    "\n",
    "f = SA[SA[a]==0]\n",
    "f = f[a].count()\n",
    "\n",
    "g = B[B[a]==0]\n",
    "g = g[a].count()\n",
    "\n",
    "# Print data results\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "print('n :', a1)\n",
    "a3 = (a1/(a1+a2))*100\n",
    "print('% ', \"%.1f\" % a3)\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "print('n: ', W[a].count())\n",
    "print('n :', b)\n",
    "h = (b/(b+e))*100\n",
    "print('% ', \"%.1f\" % h)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "print('n: ', SA[a].count())\n",
    "print('n :', c)\n",
    "i = (c/(c+f))*100\n",
    "print('% ', \"%.1f\" % i)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "print('n: ', B[a].count())\n",
    "print('n: ', d)\n",
    "j = (d/(d+g))*100\n",
    "print('% ', \"%.1f\" % j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db3d68",
   "metadata": {},
   "source": [
    "### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d2b01ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         White  South Asian  Black\n",
      "Present      4            1      0\n",
      "Absent      48           44      9\n"
     ]
    }
   ],
   "source": [
    "# initialize data of lists\n",
    "data_cont = {a :['Present', 'Absent'],\n",
    "        'White': [b, e], \n",
    "        'South Asian': [c, f],\n",
    "        'Black': [d, g]}\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "data_cont = pd.DataFrame(data_cont, columns=['White', 'South Asian', 'Black'], index=['Present', 'Absent'])\n",
    "\n",
    "\n",
    "# print dataframe.\n",
    "print(data_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ded8467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1.47\n",
      "\n",
      "Difference is not significant, p:  0.4785 0.479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's exact test for a 2x3 table using statsmodels\n",
    "result = Table(data_cont).test_nominal_association()\n",
    "print(\"Test Statistic:\",  \"%.2f\" % result.statistic)\n",
    "\n",
    "\n",
    "# Decide on outcome\n",
    "print('')\n",
    "alpha = 0.004\n",
    "if result.pvalue > alpha:\n",
    "    print('Difference is not significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue) \n",
    "else:\n",
    "    print('Difference is significant, p: ', \"%.4f\" % result.pvalue, \"%.3f\" % result.pvalue)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea05cd1",
   "metadata": {},
   "source": [
    "# BRAINtest data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2cfb0",
   "metadata": {},
   "source": [
    "## UPDRSIII L vs R scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8c52a4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS_Part3_Right\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  12.5\n",
      "SD:  6.4\n",
      "\n",
      "White\n",
      "Mean:  11.0\n",
      "SD:  5.7\n",
      "\n",
      "South Asian\n",
      "Mean:  14.2\n",
      "SD:  6.5\n",
      "\n",
      "Black\n",
      "Mean:  15.2\n",
      "SD:  5.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'UPDRS_Part3_Right'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 44), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "ff3eb740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  218\n",
      "n:  208\n",
      "UPDRS_Part3_Left\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  13.8\n",
      "SD:  7.2\n",
      "\n",
      "White\n",
      "Mean:  12.8\n",
      "SD:  6.3\n",
      "\n",
      "South Asian\n",
      "Mean:  14.7\n",
      "SD:  8.3\n",
      "\n",
      "Black\n",
      "Mean:  16.8\n",
      "SD:  5.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'UPDRS_Part3_Left'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "print('n: ', df['ELPD_ID'].count())\n",
    "\n",
    "# Replace with NA any value in a > max of scale \n",
    "df[a].mask((df[a] > 44), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "print('n: ', df['ELPD_ID'].count())\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df492c45",
   "metadata": {},
   "source": [
    "## KS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cfeb30",
   "metadata": {},
   "source": [
    "### PwP - Group by UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "7922fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDP\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "2638e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n",
      "     ELPD_ID         DOA  Age  Gender  Ethnicity  Diagnosis  AgeSymptomOnset  \\\n",
      "240    10416  28/06/2023   78       0          1          1               62   \n",
      "185    10832  29/10/2021   65       0          8          1               61   \n",
      "125    10988  21/11/2019   83       0          3          1               73   \n",
      "66     11092  01/07/2019   50       1          3          1               34   \n",
      "216    11248  10/05/2022   81       1          1          1               60   \n",
      "\n",
      "     AgeDiagnosis  DaysSinceSymptomOnset  DaysSinceDiagnosis  ...  \\\n",
      "240            63                   6022                5871  ...   \n",
      "185            62                   1731                1489  ...   \n",
      "125            77                   3884                2625  ...   \n",
      "66             36                   6209                5386  ...   \n",
      "216            61                   8013                7397  ...   \n",
      "\n",
      "     HADQ_DepressionTotal  HADSQ_AnxietyTotal  \\\n",
      "240                   4.0                 4.0   \n",
      "185                  13.0                12.0   \n",
      "125                   NaN                 NaN   \n",
      "66                    8.0                 9.0   \n",
      "216                   1.0                 5.0   \n",
      "\n",
      "     MOCA_TotalEducationLevelConsidered  MOCA_Reliability  Smell_Test_Total  \\\n",
      "240                                16.0               1.0               2.0   \n",
      "185                                25.0               1.0               2.0   \n",
      "125                                10.0               0.0               NaN   \n",
      "66                                 28.0               1.0               NaN   \n",
      "216                                25.0               1.0               2.0   \n",
      "\n",
      "     IMD_decile       Type  KS   AT.Adj.    IS.Adj.  \n",
      "240         5.0  left real  13  484.1833        888  \n",
      "185         1.0  left real  34  192.2061  38,404.23  \n",
      "125         3.0  left real  21  192.5887   22710.13  \n",
      "66          6.0  left real  38  111.5243   19128.79  \n",
      "216         4.0  left real  34  166.6788  32,770.71  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "# Add a column that contains the maximum score of score1 and score2\n",
    "\n",
    "print(df_merged['UPDRS_Part3_Right'].isna().sum())\n",
    "df_merged = df_merged[df_merged['UPDRS_Part3_Right'].notna()]\n",
    "\n",
    "df_merged['max_score'] = df_merged[['UPDRS_Part3_Right', 'UPDRS_Part3_Left']].max(axis=1)\n",
    "print(df_merged['max_score'].isna().sum())\n",
    "\n",
    "# Find the index of the row with the highest max_score for each id\n",
    "idx = df_merged.groupby('ELPD_ID')['max_score'].idxmax()\n",
    "\n",
    "# Select the rows with the highest score\n",
    "most_affected = df_merged.loc[idx].drop(columns=['max_score'])\n",
    "\n",
    "print(most_affected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3cd2db54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS\n",
      "PwP\n",
      "\n",
      "All 141\n",
      "Mean:  34.7\n",
      "SD:  14.6\n",
      "\n",
      "White\n",
      "Mean:  36.5\n",
      "SD:  14.4\n",
      "\n",
      "South Asian\n",
      "Mean:  31.4\n",
      "SD:  12.5\n",
      "\n",
      "Black\n",
      "Mean:  32.2\n",
      "SD:  17.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'KS'\n",
    "b = 'Ethnicity'\n",
    "df = most_affected\n",
    "\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All', df[a].count())\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a3518",
   "metadata": {},
   "source": [
    "#### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "a6e71fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.980, p = 0.329\n",
      "Distribution is normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.977, p = 0.461\n",
      "Distribution is normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.956, p = 0.689\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 0.453, p = 0.502\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 1.353, p = 0.248\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 2.934, p = 0.092\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "a = 'KS'\n",
    "b = 'Ethnicity'\n",
    "df1 = most_affected\n",
    "df1 = df1[df1[a].notna()]\n",
    "\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "db28384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs South Asian\n",
      "T:  2.0 DOF:  115.0\n",
      "Difference is not significant, p =  0.052\n",
      "\n",
      "\n",
      "White vs Black\n",
      "T:  0.9 DOF:  80.0\n",
      "Difference is not significant, p =  0.358\n",
      "\n",
      "\n",
      "Black vs South Asian\n",
      "T:  0.2 DOF:  59.0\n",
      "Difference is not significant, p =  0.846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('White vs South Asian')\n",
    "summary, results = rp.ttest(group1= W[a], group2= SA[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n",
    "\n",
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('White vs Black')\n",
    "summary, results = rp.ttest(group1= W[a], group2= B[a])\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')\n",
    "\n",
    "# Normal distribution, equal variances - t-test\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "summary, results = rp.ttest(group1= B[a], group2= SA[a])\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if results.results[3] < alpha:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is significant, p = ', \"%.3f\" % results.results[3]) \n",
    "else:\n",
    "    print('T: ', \"%.1f\" % results.results[2],'DOF: ', results.results[1])\n",
    "    print('Difference is not significant, p = ', \"%.3f\" % results.results[3])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8094209",
   "metadata": {},
   "source": [
    "#### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "5a4f687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  117\n",
      "White and Black PD patients count:  82\n",
      "Black and South Asian PD patients count:  61\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "df = most_affected\n",
    "\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f40daf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665657\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      115\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01668\n",
      "Time:                        14:38:12   Log-Likelihood:                -77.882\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1040\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0126      0.007      1.724      0.085      -0.002       0.027\n",
      "DaysSinceSymptomOnset  3.819e-06   7.31e-05      0.052      0.958      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.08466835170880838\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.659111\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      113\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02635\n",
      "Time:                        14:38:12   Log-Likelihood:                -77.116\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2432\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0083      0.012      0.688      0.491      -0.015       0.032\n",
      "DaysSinceSymptomOnset -2.269e-05   8.18e-05     -0.277      0.781      -0.000       0.000\n",
      "Age                       0.0081      0.008      0.982      0.326      -0.008       0.024\n",
      "Gender                   -0.4416      0.397     -1.111      0.267      -1.221       0.337\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.49114159849248806\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658854\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      112\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02673\n",
      "Time:                        14:38:12   Log-Likelihood:                -77.086\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3751\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0081      0.012      0.666      0.505      -0.016       0.032\n",
      "DaysSinceSymptomOnset -3.262e-05   9.15e-05     -0.357      0.721      -0.000       0.000\n",
      "Age                       0.0079      0.008      0.953      0.341      -0.008       0.024\n",
      "Gender                   -0.4540      0.401     -1.131      0.258      -1.241       0.333\n",
      "LEDD_ADJUSTED_2        9.217e-05      0.000      0.242      0.809      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.5051246241737156\n",
      "\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    64\n",
      "0    47\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.659417\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03222\n",
      "Time:                        14:38:12   Log-Likelihood:                -73.195\n",
      "converged:                       True   LL-Null:                       -75.632\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3005\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "KS                                0.0125      0.013      0.965      0.335      -0.013       0.038\n",
      "DaysSinceSymptomOnset          1.619e-05   8.61e-05      0.188      0.851      -0.000       0.000\n",
      "Age                               0.0112      0.010      1.111      0.267      -0.009       0.031\n",
      "Gender                           -0.3293      0.408     -0.807      0.420      -1.129       0.471\n",
      "UPDRS_3b_CurrentClinicalState    -0.7055      0.574     -1.229      0.219      -1.831       0.420\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.3345270391174988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3735404075.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "print('')\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "fb57a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.437323\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       80\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:              -0.0002012\n",
      "Time:                        14:38:13   Log-Likelihood:                -35.861\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0338      0.013      2.687      0.007       0.009       0.058\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.110      0.267      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.0072012054173640596\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413905\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       78\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05336\n",
      "Time:                        14:38:13   Log-Likelihood:                -33.940\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2809\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0165      0.018      0.938      0.348      -0.018       0.051\n",
      "DaysSinceSymptomOnset  8.489e-05      0.000      0.518      0.604      -0.000       0.000\n",
      "Age                       0.0062      0.012      0.516      0.606      -0.017       0.030\n",
      "Gender                    0.8413      0.622      1.353      0.176      -0.377       2.060\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.34847567711395744\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413092\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       77\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05522\n",
      "Time:                        14:38:13   Log-Likelihood:                -33.874\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4115\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0154      0.018      0.868      0.385      -0.019       0.050\n",
      "DaysSinceSymptomOnset  5.798e-05      0.000      0.323      0.747      -0.000       0.000\n",
      "Age                       0.0060      0.012      0.506      0.613      -0.017       0.029\n",
      "Gender                    0.8178      0.628      1.302      0.193      -0.413       2.049\n",
      "LEDD_ADJUSTED_2           0.0002      0.001      0.340      0.734      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.3853808677293237\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    64\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.427958\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   77\n",
      "Model:                          Logit   Df Residuals:                       72\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05742\n",
      "Time:                        14:38:13   Log-Likelihood:                -32.953\n",
      "converged:                       True   LL-Null:                       -34.960\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4040\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "KS                                0.0193      0.019      1.001      0.317      -0.018       0.057\n",
      "DaysSinceSymptomOnset          6.576e-05      0.000      0.407      0.684      -0.000       0.000\n",
      "Age                               0.0016      0.013      0.120      0.904      -0.024       0.027\n",
      "Gender                            0.8822      0.626      1.409      0.159      -0.345       2.109\n",
      "UPDRS_3b_CurrentClinicalState     0.2027      0.818      0.248      0.804      -1.400       1.806\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.31673355495335676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\896035783.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ca8c5eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset\n",
      "1    48\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534188\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   61\n",
      "Model:                          Logit   Df Residuals:                       59\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.03114\n",
      "Time:                        14:38:13   Log-Likelihood:                -32.585\n",
      "converged:                       True   LL-Null:                       -31.601\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0232      0.013      1.773      0.076      -0.002       0.049\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.211      0.226      -0.000       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.07626363816941933\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    48\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502289\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   61\n",
      "Model:                          Logit   Df Residuals:                       57\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03043\n",
      "Time:                        14:38:13   Log-Likelihood:                -30.640\n",
      "converged:                       True   LL-Null:                       -31.601\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.5885\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0070      0.020      0.356      0.722      -0.032       0.046\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.636      0.524      -0.000       0.000\n",
      "Age                       0.0015      0.013      0.109      0.913      -0.025       0.028\n",
      "Gender                    1.1103      0.608      1.827      0.068      -0.081       2.302\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.7222075164193626\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    48\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501271\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   61\n",
      "Model:                          Logit   Df Residuals:                       56\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03240\n",
      "Time:                        14:38:13   Log-Likelihood:                -30.578\n",
      "converged:                       True   LL-Null:                       -31.601\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7270\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "KS                        0.0064      0.020      0.323      0.747      -0.033       0.046\n",
      "DaysSinceSymptomOnset  7.205e-05      0.000      0.335      0.737      -0.000       0.000\n",
      "Age                       0.0008      0.013      0.060      0.952      -0.025       0.027\n",
      "Gender                    1.0538      0.626      1.684      0.092      -0.173       2.280\n",
      "LEDD_ADJUSTED_2           0.0004      0.001      0.354      0.723      -0.002       0.002\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.7469677501839466\n",
      "\n",
      "Exposure  KS  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    47\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502354\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   60\n",
      "Model:                          Logit   Df Residuals:                       55\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03884\n",
      "Time:                        14:38:13   Log-Likelihood:                -30.141\n",
      "converged:                       True   LL-Null:                       -31.359\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6561\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "KS                                0.0071      0.020      0.348      0.728      -0.033       0.047\n",
      "DaysSinceSymptomOnset           4.38e-05      0.000      0.232      0.816      -0.000       0.000\n",
      "Age                              -0.0034      0.014     -0.236      0.814      -0.031       0.025\n",
      "Gender                            0.9986      0.619      1.614      0.107      -0.214       2.211\n",
      "UPDRS_3b_CurrentClinicalState     0.6811      0.818      0.833      0.405      -0.921       2.284\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.7275307472159157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1788337535.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1788337535.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1bad1",
   "metadata": {},
   "source": [
    "### HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "2153b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDH\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a16bd73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELPD_ID</th>\n",
       "      <th>DOA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>HTN</th>\n",
       "      <th>T2DM</th>\n",
       "      <th>MOCA_TotalEducationLevelConsidered</th>\n",
       "      <th>MOCA_Reliability</th>\n",
       "      <th>MOCA_ReasonforUnreliability</th>\n",
       "      <th>RBDSQ_Total</th>\n",
       "      <th>Smell_Test_Total</th>\n",
       "      <th>Type</th>\n",
       "      <th>KS</th>\n",
       "      <th>AT.Adj.</th>\n",
       "      <th>IS.Adj.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11196</td>\n",
       "      <td>12/04/2023</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>56</td>\n",
       "      <td>127.8745</td>\n",
       "      <td>5,922.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16084</td>\n",
       "      <td>17/07/2023</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>right real</td>\n",
       "      <td>49</td>\n",
       "      <td>122.8188</td>\n",
       "      <td>21,087.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23884</td>\n",
       "      <td>20/02/2023</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>54</td>\n",
       "      <td>201.0811</td>\n",
       "      <td>2,734.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26640</td>\n",
       "      <td>17/07/2023</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>18</td>\n",
       "      <td>468.7353</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30280</td>\n",
       "      <td>02/08/2023</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>57</td>\n",
       "      <td>117.3196</td>\n",
       "      <td>3,622.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ELPD_ID         DOA  Age  Gender  Ethnicity  Smoking  HTN  T2DM  \\\n",
       "18    11196  12/04/2023   51       1          3      0.0  1.0   0.0   \n",
       "3     16084  17/07/2023   60       1          3      2.0  0.0   0.0   \n",
       "14    23884  20/02/2023   52       0          3      0.0  1.0   1.0   \n",
       "0     26640  17/07/2023   66       1          3      2.0  1.0   1.0   \n",
       "4     30280  02/08/2023   45       0          3      0.0  0.0   0.0   \n",
       "\n",
       "    MOCA_TotalEducationLevelConsidered  MOCA_Reliability  \\\n",
       "18                                29.0               1.0   \n",
       "3                                 30.0               1.0   \n",
       "14                                29.0               1.0   \n",
       "0                                 15.0               1.0   \n",
       "4                                 29.0               1.0   \n",
       "\n",
       "    MOCA_ReasonforUnreliability  RBDSQ_Total  Smell_Test_Total        Type  \\\n",
       "18                          0.0          1.0               2.0   left real   \n",
       "3                           0.0          1.0               2.0  right real   \n",
       "14                          0.0          1.0               4.0   left real   \n",
       "0                           0.0          5.0               3.0   left real   \n",
       "4                           0.0          3.0               5.0   left real   \n",
       "\n",
       "    KS   AT.Adj.    IS.Adj.  \n",
       "18  56  127.8745   5,922.66  \n",
       "3   49  122.8188  21,087.17  \n",
       "14  54  201.0811   2,734.92  \n",
       "0   18  468.7353        888  \n",
       "4   57  117.3196   3,622.11  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "idx = df_merged.groupby('ELPD_ID')['KS'].idxmin()\n",
    "\n",
    "most_affected_HC = df_merged.loc[idx]\n",
    "\n",
    "most_affected_HC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "06512103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS\n",
      "HCs\n",
      "\n",
      "All 14\n",
      "Mean:  44.3\n",
      "SD:  11.2\n",
      "\n",
      "Lower threshold:  21.9\n",
      "Higher threshold:  66.7\n",
      "\n",
      "All 13\n",
      "Mean:  46.3\n",
      "SD:  8.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'KS'\n",
    "b = 'Ethnicity'\n",
    "\n",
    "#Calculate mean for all HCs \n",
    "df = most_affected_HC\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "print(a)\n",
    "print('HCs')\n",
    "print('')\n",
    "print('All', df[a].count())\n",
    "score_HC = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')\n",
    "\n",
    "low = score_HC.mean() - 2*(score_HC.std())\n",
    "high = score_HC.mean() + 2*(score_HC.std())\n",
    "print(\"Lower threshold: \", \"%.1f\"  % low)\n",
    "print(\"Higher threshold: \", \"%.1f\"  % high)\n",
    "\n",
    "# Exclude outliers\n",
    "df[a].mask((df[a] < low), inplace=True)\n",
    "df[a].mask((df[a] > high), inplace=True)\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "score_HC = df[a].to_numpy(dtype=np.float32)\n",
    "print('')\n",
    "print('All', df[a].count())\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3435012",
   "metadata": {},
   "source": [
    "#### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "ce0804c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS\n",
      "Distribution\n",
      "\n",
      "PwP\n",
      "Mean:  34.7\n",
      "SD:  14.6\n",
      "\n",
      "Statistics = 0.987, p = 0.209\n",
      "Distribution is normal\n",
      "\n",
      "HCs\n",
      "Mean:  46.3\n",
      "SD:  8.8\n",
      "\n",
      "Statistics = 0.987, p = 0.209\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "PwP vs HCs\n",
      "Statistics = 4.187, p = 0.042\n",
      "Variances are not equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "# PwP\n",
    "a = 'KS'\n",
    "b = 'Ethnicity'\n",
    "df1 = most_affected\n",
    "df1 = df1[df1[a].notna()]\n",
    "\n",
    "print('PwP')\n",
    "score = df1[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# HCs\n",
    "a = 'KS'\n",
    "b = 'Ethnicity'\n",
    "df2 = df\n",
    "df2 = df2[df2[a].notna()]\n",
    "\n",
    "print('HCs')\n",
    "score_HC = df2[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('PwP vs HCs')\n",
    "stat, p = st.levene(df1[a], df2[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "c7e023d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ELPDP    141\n",
       "ELPDH     13\n",
       "Name: Group, dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal distribution, non-equal variances - Welch's ANNOVA should be used\n",
    "\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "# Add a 'Group' column based on the content of the 'Label' column\n",
    "df_combined['Group']=df_combined.groupby('ELPD_ID').ngroup()\n",
    "df_combined['Group'] = np.where(df_combined['Group']>12, 'ELPDP', 'ELPDH')\n",
    "df_combined['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9cefd65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELPD_ID</th>\n",
       "      <th>DOA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>AgeSymptomOnset</th>\n",
       "      <th>AgeDiagnosis</th>\n",
       "      <th>DaysSinceSymptomOnset</th>\n",
       "      <th>DaysSinceDiagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>MOCA_TotalEducationLevelConsidered</th>\n",
       "      <th>MOCA_Reliability</th>\n",
       "      <th>Smell_Test_Total</th>\n",
       "      <th>IMD_decile</th>\n",
       "      <th>Type</th>\n",
       "      <th>KS</th>\n",
       "      <th>AT.Adj.</th>\n",
       "      <th>IS.Adj.</th>\n",
       "      <th>MOCA_ReasonforUnreliability</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10416</td>\n",
       "      <td>28/06/2023</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6022.0</td>\n",
       "      <td>5871.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>13.0</td>\n",
       "      <td>484.1833</td>\n",
       "      <td>888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELPDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10832</td>\n",
       "      <td>29/10/2021</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>34.0</td>\n",
       "      <td>192.2061</td>\n",
       "      <td>38,404.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELPDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10988</td>\n",
       "      <td>21/11/2019</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3884.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>21.0</td>\n",
       "      <td>192.5887</td>\n",
       "      <td>22710.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELPDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11092</td>\n",
       "      <td>01/07/2019</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6209.0</td>\n",
       "      <td>5386.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>38.0</td>\n",
       "      <td>111.5243</td>\n",
       "      <td>19128.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELPDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11248</td>\n",
       "      <td>10/05/2022</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>8013.0</td>\n",
       "      <td>7397.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>left real</td>\n",
       "      <td>34.0</td>\n",
       "      <td>166.6788</td>\n",
       "      <td>32,770.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELPDH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ELPD_ID         DOA  Age  Gender  Ethnicity  Diagnosis  AgeSymptomOnset  \\\n",
       "0    10416  28/06/2023   78       0          1        1.0             62.0   \n",
       "1    10832  29/10/2021   65       0          8        1.0             61.0   \n",
       "2    10988  21/11/2019   83       0          3        1.0             73.0   \n",
       "3    11092  01/07/2019   50       1          3        1.0             34.0   \n",
       "4    11248  10/05/2022   81       1          1        1.0             60.0   \n",
       "\n",
       "   AgeDiagnosis  DaysSinceSymptomOnset  DaysSinceDiagnosis  ...  \\\n",
       "0          63.0                 6022.0              5871.0  ...   \n",
       "1          62.0                 1731.0              1489.0  ...   \n",
       "2          77.0                 3884.0              2625.0  ...   \n",
       "3          36.0                 6209.0              5386.0  ...   \n",
       "4          61.0                 8013.0              7397.0  ...   \n",
       "\n",
       "   MOCA_TotalEducationLevelConsidered  MOCA_Reliability  Smell_Test_Total  \\\n",
       "0                                16.0               1.0               2.0   \n",
       "1                                25.0               1.0               2.0   \n",
       "2                                10.0               0.0               NaN   \n",
       "3                                28.0               1.0               NaN   \n",
       "4                                25.0               1.0               2.0   \n",
       "\n",
       "   IMD_decile       Type    KS   AT.Adj.    IS.Adj.  \\\n",
       "0         5.0  left real  13.0  484.1833        888   \n",
       "1         1.0  left real  34.0  192.2061  38,404.23   \n",
       "2         3.0  left real  21.0  192.5887   22710.13   \n",
       "3         6.0  left real  38.0  111.5243   19128.79   \n",
       "4         4.0  left real  34.0  166.6788  32,770.71   \n",
       "\n",
       "   MOCA_ReasonforUnreliability  Group  \n",
       "0                          NaN  ELPDH  \n",
       "1                          NaN  ELPDH  \n",
       "2                          NaN  ELPDH  \n",
       "3                          NaN  ELPDH  \n",
       "4                          NaN  ELPDH  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9b38e2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "                sum_sq     df         F    PR(>F)\n",
      "C(Group)      0.006212    1.0  0.000029  0.995724\n",
      "Residual  32775.630115  152.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Perform Welch's ANOVA\n",
    "print('White vs South Asian')\n",
    "model = ols('KS ~ C(Group)', data=df_combined).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2, robust='hc3')\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7df8b1",
   "metadata": {},
   "source": [
    "## AT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c71a3",
   "metadata": {},
   "source": [
    "### PwP - Group by UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "2f1a7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDP\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ec146886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n",
      "     ELPD_ID         DOA  Age  Gender  Ethnicity  Diagnosis  AgeSymptomOnset  \\\n",
      "240    10416  28/06/2023   78       0          1          1               62   \n",
      "185    10832  29/10/2021   65       0          8          1               61   \n",
      "125    10988  21/11/2019   83       0          3          1               73   \n",
      "66     11092  01/07/2019   50       1          3          1               34   \n",
      "216    11248  10/05/2022   81       1          1          1               60   \n",
      "..       ...         ...  ...     ...        ...        ...              ...   \n",
      "139    52380  02/03/2020   64       0          1          1               60   \n",
      "266    52952  31/10/2023   67       0          1          1               64   \n",
      "68     53680  01/07/2019   54       1          3          1               45   \n",
      "181    53732  26/10/2021   65       0          2          1               54   \n",
      "40     53836  02/04/2019   75       0          1          1               58   \n",
      "\n",
      "     AgeDiagnosis  DaysSinceSymptomOnset  DaysSinceDiagnosis  ...  \\\n",
      "240            63                   6022                5871  ...   \n",
      "185            62                   1731                1489  ...   \n",
      "125            77                   3884                2625  ...   \n",
      "66             36                   6209                5386  ...   \n",
      "216            61                   8013                7397  ...   \n",
      "..            ...                    ...                 ...  ...   \n",
      "139            60                   1417                1414  ...   \n",
      "266            65                   1064                 747  ...   \n",
      "68             46                   3833                3529  ...   \n",
      "181            57                   4226                3266  ...   \n",
      "40             59                   6300                6032  ...   \n",
      "\n",
      "     HADQ_DepressionTotal  HADSQ_AnxietyTotal  \\\n",
      "240                   4.0                 4.0   \n",
      "185                  13.0                12.0   \n",
      "125                   NaN                 NaN   \n",
      "66                    8.0                 9.0   \n",
      "216                   1.0                 5.0   \n",
      "..                    ...                 ...   \n",
      "139                   NaN                 NaN   \n",
      "266                   7.0                 4.0   \n",
      "68                    NaN                 NaN   \n",
      "181                  11.0                13.0   \n",
      "40                    6.0                 8.0   \n",
      "\n",
      "     MOCA_TotalEducationLevelConsidered  MOCA_Reliability  Smell_Test_Total  \\\n",
      "240                                16.0               1.0               2.0   \n",
      "185                                25.0               1.0               2.0   \n",
      "125                                10.0               0.0               NaN   \n",
      "66                                 28.0               1.0               NaN   \n",
      "216                                25.0               1.0               2.0   \n",
      "..                                  ...               ...               ...   \n",
      "139                                24.0               1.0               NaN   \n",
      "266                                29.0               1.0               3.0   \n",
      "68                                 22.0               1.0               NaN   \n",
      "181                                24.0               1.0               NaN   \n",
      "40                                 24.0               1.0               2.0   \n",
      "\n",
      "     IMD_decile        Type  KS   AT.Adj.    IS.Adj.  \n",
      "240         5.0   left real  13  484.1833        888  \n",
      "185         1.0   left real  34  192.2061  38,404.23  \n",
      "125         3.0   left real  21  192.5887   22710.13  \n",
      "66          6.0   left real  38  111.5243   19128.79  \n",
      "216         4.0   left real  34  166.6788  32,770.71  \n",
      "..          ...         ...  ..       ...        ...  \n",
      "139         2.0   left real  59  195.3125   8,662.26  \n",
      "266         4.0   left real  39  163.1816  11,579.68  \n",
      "68          4.0  right real  20  387.4947   12002.47  \n",
      "181         2.0  right real  51  157.2580    9775.26  \n",
      "40          4.0   left real  49   95.7500  19,973.34  \n",
      "\n",
      "[141 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "# Add a column that contains the maximum score of score1 and score2\n",
    "\n",
    "print(df_merged['UPDRS_Part3_Right'].isna().sum())\n",
    "df_merged = df_merged[df_merged['UPDRS_Part3_Right'].notna()]\n",
    "\n",
    "df_merged['max_score'] = df_merged[['UPDRS_Part3_Right', 'UPDRS_Part3_Left']].max(axis=1)\n",
    "print(df_merged['max_score'].isna().sum())\n",
    "\n",
    "# Find the index of the row with the highest max_score for each id\n",
    "idx = df_merged.groupby('ELPD_ID')['max_score'].idxmax()\n",
    "\n",
    "# Select the rows with the highest score\n",
    "most_affected = df_merged.loc[idx].drop(columns=['max_score'])\n",
    "\n",
    "print(most_affected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "377f283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT.Adj.\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  180.3\n",
      "SD:  88.9\n",
      "\n",
      "White\n",
      "Mean:  153.8\n",
      "SD:  70.2\n",
      "\n",
      "South Asian\n",
      "Mean:  204.9\n",
      "SD:  97.4\n",
      "\n",
      "Black\n",
      "Mean:  220.1\n",
      "SD:  93.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'AT.Adj.'\n",
    "b = 'Ethnicity'\n",
    "df = most_affected\n",
    "\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beaa864",
   "metadata": {},
   "source": [
    "#### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "aa7d91ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT.Adj.\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.901, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.935, p = 0.011\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.934, p = 0.381\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 4.518, p = 0.036\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 3.805, p = 0.055\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 0.116, p = 0.735\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "\n",
    "a = 'AT.Adj.'\n",
    "b = 'Ethnicity'\n",
    "df1 = most_affected\n",
    "df1 = df1[df1[a].notna()]\n",
    "\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "227d15d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 9.941, p = 0.0016\n",
      "Difference is significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 261.000, p = 0.018\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 343.000, p = 0.591\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.4f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "    \n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f640f5",
   "metadata": {},
   "source": [
    "#### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "6fb5e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  117\n",
      "White and Black PD patients count:  82\n",
      "Black and South Asian PD patients count:  61\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "df = most_affected\n",
    "a = 'AT.Adj.'\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0f0def04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670368\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      115\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.009726\n",
      "Time:                        14:42:50   Log-Likelihood:                -78.433\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2145\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                  -0.0020      0.001     -1.368      0.171      -0.005       0.001\n",
      "DaysSinceSymptomOnset     0.0002   8.36e-05      2.116      0.034    1.31e-05       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.17119875289984043\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574075\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      113\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1520\n",
      "Time:                        14:42:50   Log-Likelihood:                -67.167\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.412e-05\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                  -0.0117      0.003     -3.766      0.000      -0.018      -0.006\n",
      "DaysSinceSymptomOnset -1.039e-05   8.84e-05     -0.117      0.906      -0.000       0.000\n",
      "Age                       0.0437      0.011      4.022      0.000       0.022       0.065\n",
      "Gender                   -0.5997      0.443     -1.355      0.175      -1.467       0.268\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.000166142305113903\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.572979\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      112\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1536\n",
      "Time:                        14:42:50   Log-Likelihood:                -67.039\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.860e-05\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                  -0.0117      0.003     -3.781      0.000      -0.018      -0.006\n",
      "DaysSinceSymptomOnset -3.166e-05   9.83e-05     -0.322      0.747      -0.000       0.000\n",
      "Age                       0.0431      0.011      3.957      0.000       0.022       0.064\n",
      "Gender                   -0.6308      0.449     -1.405      0.160      -1.511       0.249\n",
      "LEDD_ADJUSTED_2           0.0002      0.000      0.486      0.627      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.00015619354632778282\n",
      "\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    64\n",
      "0    47\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575019\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1561\n",
      "Time:                        14:42:50   Log-Likelihood:                -63.827\n",
      "converged:                       True   LL-Null:                       -75.632\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.559e-05\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "AT.Adj.                          -0.0123      0.003     -3.645      0.000      -0.019      -0.006\n",
      "DaysSinceSymptomOnset          1.144e-05   9.42e-05      0.121      0.903      -0.000       0.000\n",
      "Age                               0.0458      0.012      3.718      0.000       0.022       0.070\n",
      "Gender                           -0.4064      0.457     -0.889      0.374      -1.302       0.489\n",
      "UPDRS_3b_CurrentClinicalState    -0.3017      0.581     -0.519      0.603      -1.440       0.836\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.00026694634472086324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3403251492.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "print('')\n",
    "\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "aa533719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.485698\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       80\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 -0.1108\n",
      "Time:                        14:42:50   Log-Likelihood:                -39.827\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                   0.0010      0.003      0.389      0.697      -0.004       0.006\n",
      "DaysSinceSymptomOnset     0.0005      0.000      2.487      0.013    9.81e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.6970825092654174\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.367983\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       78\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1584\n",
      "Time:                        14:42:50   Log-Likelihood:                -30.175\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.009942\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                  -0.0118      0.004     -2.646      0.008      -0.020      -0.003\n",
      "DaysSinceSymptomOnset     0.0002      0.000      0.943      0.346      -0.000       0.001\n",
      "Age                       0.0442      0.016      2.839      0.005       0.014       0.075\n",
      "Gender                    0.5055      0.664      0.762      0.446      -0.795       1.806\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.008156444823825076\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366187\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       77\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1625\n",
      "Time:                        14:42:50   Log-Likelihood:                -30.027\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02014\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                  -0.0118      0.004     -2.649      0.008      -0.021      -0.003\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.598      0.550      -0.000       0.001\n",
      "Age                       0.0435      0.016      2.773      0.006       0.013       0.074\n",
      "Gender                    0.4601      0.680      0.676      0.499      -0.873       1.793\n",
      "LEDD_ADJUSTED_2           0.0004      0.001      0.470      0.639      -0.001       0.002\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.00806373964044002\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    64\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.384748\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   77\n",
      "Model:                          Logit   Df Residuals:                       72\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                  0.1526\n",
      "Time:                        14:42:51   Log-Likelihood:                -29.626\n",
      "converged:                       True   LL-Null:                       -34.960\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.03055\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "AT.Adj.                          -0.0114      0.005     -2.516      0.012      -0.020      -0.003\n",
      "DaysSinceSymptomOnset             0.0002      0.000      0.776      0.438      -0.000       0.001\n",
      "Age                               0.0405      0.018      2.195      0.028       0.004       0.077\n",
      "Gender                            0.6019      0.668      0.901      0.368      -0.708       1.911\n",
      "UPDRS_3b_CurrentClinicalState     0.1812      0.811      0.223      0.823      -1.409       1.771\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.011862663432387462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\896035783.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "42523ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset\n",
      "1    48\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544333\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   61\n",
      "Model:                          Logit   Df Residuals:                       59\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                -0.05073\n",
      "Time:                        14:42:51   Log-Likelihood:                -33.204\n",
      "converged:                       True   LL-Null:                       -31.601\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                   0.0031      0.002      1.431      0.152      -0.001       0.007\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.151      0.250      -0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.15246551385527954\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    48\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503187\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   61\n",
      "Model:                          Logit   Df Residuals:                       57\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02870\n",
      "Time:                        14:42:51   Log-Likelihood:                -30.694\n",
      "converged:                       True   LL-Null:                       -31.601\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6119\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                   0.0004      0.003      0.131      0.896      -0.006       0.007\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.604      0.546      -0.000       0.000\n",
      "Age                       0.0035      0.014      0.256      0.798      -0.023       0.030\n",
      "Gender                    1.1403      0.604      1.888      0.059      -0.043       2.324\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.8956170256080034\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    48\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502023\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   61\n",
      "Model:                          Logit   Df Residuals:                       56\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03095\n",
      "Time:                        14:42:51   Log-Likelihood:                -30.623\n",
      "converged:                       True   LL-Null:                       -31.601\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7439\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "AT.Adj.                   0.0004      0.003      0.113      0.910      -0.006       0.007\n",
      "DaysSinceSymptomOnset  6.399e-05      0.000      0.304      0.761      -0.000       0.000\n",
      "Age                       0.0026      0.014      0.191      0.849      -0.024       0.030\n",
      "Gender                    1.0802      0.621      1.739      0.082      -0.137       2.297\n",
      "LEDD_ADJUSTED_2           0.0004      0.001      0.378      0.705      -0.002       0.002\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.9102655884033864\n",
      "\n",
      "Exposure  AT.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    47\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503162\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   60\n",
      "Model:                          Logit   Df Residuals:                       55\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03730\n",
      "Time:                        14:42:51   Log-Likelihood:                -30.190\n",
      "converged:                       True   LL-Null:                       -31.359\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6736\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "AT.Adj.                           0.0005      0.003      0.158      0.874      -0.006       0.007\n",
      "DaysSinceSymptomOnset          3.568e-05      0.000      0.191      0.849      -0.000       0.000\n",
      "Age                              -0.0019      0.015     -0.126      0.900      -0.031       0.027\n",
      "Gender                            1.0354      0.612      1.693      0.090      -0.163       2.234\n",
      "UPDRS_3b_CurrentClinicalState     0.7041      0.813      0.866      0.387      -0.890       2.298\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.8740773453038337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1147462592.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\1147462592.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5d1a0",
   "metadata": {},
   "source": [
    "### HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "87a037be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDH\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')\n",
    "\n",
    "# Group by 'key' and select the maximum 'value' in each group\n",
    " # Find the index of the maximum 'value' for each 'key'\n",
    "idx = df_merged.groupby('ELPD_ID')['KS'].idxmin()\n",
    "\n",
    "most_affected_HC = df_merged.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "551b6e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDP\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')\n",
    "\n",
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "# Add a column that contains the maximum score of score1 and score2\n",
    "\n",
    "print(df_merged['UPDRS_Part3_Right'].isna().sum())\n",
    "df_merged = df_merged[df_merged['UPDRS_Part3_Right'].notna()]\n",
    "\n",
    "df_merged['max_score'] = df_merged[['UPDRS_Part3_Right', 'UPDRS_Part3_Left']].max(axis=1)\n",
    "print(df_merged['max_score'].isna().sum())\n",
    "\n",
    "# Find the index of the row with the highest max_score for each id\n",
    "idx = df_merged.groupby('ELPD_ID')['max_score'].idxmax()\n",
    "\n",
    "# Select the rows with the highest score\n",
    "most_affected = df_merged.loc[idx].drop(columns=['max_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "6e17da97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT.Adj.\n",
      "\n",
      "PwP\n",
      "Mean:  180.3\n",
      "SD:  88.9\n",
      "\n",
      "Statistics = 0.926, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "HCs\n",
      "\n",
      "All 14\n",
      "Mean:  172.7\n",
      "SD:  90.2\n",
      "\n",
      "Lower threshold:  -7.6\n",
      "Higher threshold:  353.0\n",
      "\n",
      "13\n",
      "Mean:  150.0\n",
      "SD:  38.6\n",
      "\n",
      "Statistics = 0.929, p = 0.335\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "PwP vs HCs\n",
      "Statistics = 4.043, p = 0.046\n",
      "Variances are not equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select variables\n",
    "a = 'AT.Adj.'\n",
    "b = 'Ethnicity'\n",
    "print(a)\n",
    "print('')\n",
    "\n",
    "print('PwP')\n",
    "df1 = most_affected\n",
    "df1 = df1[df1[a].notna()]\n",
    "score = df1[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('HCs')\n",
    "print('')\n",
    "#Calculate mean for all HCs \n",
    "df2 = most_affected_HC\n",
    "df2 = df2[df2[a].notna()]\n",
    "print('All', df2[a].count())\n",
    "score_HC = df2[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')\n",
    "\n",
    "low = score_HC.mean() - 2*(score_HC.std())\n",
    "high = score_HC.mean() + 2*(score_HC.std())\n",
    "print(\"Lower threshold: \", \"%.1f\"  % low)\n",
    "print(\"Higher threshold: \", \"%.1f\"  % high)\n",
    "\n",
    "# Exclude outliers\n",
    "df2[a].mask((df2[a] < low), inplace=True)\n",
    "df2[a].mask((df2[a] > high), inplace=True)\n",
    "df2 = df2[df2[a].notna()]\n",
    "\n",
    "print('')\n",
    "score_HC = df2[a].to_numpy(dtype=np.float32)\n",
    "print(df2[a].count())\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "stat, p = st.shapiro(df2[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('Variances')\n",
    "print('PwP vs HCs')\n",
    "stat, p = st.levene(df1[a], df2[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "5f17a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PwP vs HC\n",
      "Statistics = 1081.000, p = 0.287\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('PwP vs HC')\n",
    "stat, p = st.mannwhitneyu(x=df1[a], y=df2[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8f657",
   "metadata": {},
   "source": [
    "## IS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d94f3c",
   "metadata": {},
   "source": [
    "### PwP - Group by UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "982ca25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDP\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Identify NAs\n",
    "df_brain.replace(999, np.NaN, inplace=True)\n",
    "df_brain = df_brain[df_brain['IS.Adj.'].notna()]\n",
    "\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')\n",
    "\n",
    "\n",
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "# Add a column that contains the maximum score of score1 and score2\n",
    "\n",
    "print(df_merged['UPDRS_Part3_Right'].isna().sum())\n",
    "df_merged = df_merged[df_merged['UPDRS_Part3_Right'].notna()]\n",
    "\n",
    "df_merged['max_score'] = df_merged[['UPDRS_Part3_Right', 'UPDRS_Part3_Left']].max(axis=1)\n",
    "print(df_merged['max_score'].isna().sum())\n",
    "\n",
    "# Find the index of the row with the highest max_score for each id\n",
    "idx = df_merged.groupby('ELPD_ID')['max_score'].idxmax()\n",
    "\n",
    "# Select the rows with the highest score\n",
    "most_affected = df_merged.loc[idx].drop(columns=['max_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "dce404d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS.Adj.\n",
      "PwP\n",
      "\n",
      "All\n",
      "Mean:  19356.5\n",
      "SD:  22019.2\n",
      "\n",
      "White\n",
      "Mean:  16681.5\n",
      "SD:  18822.9\n",
      "\n",
      "South Asian\n",
      "Mean:  22091.4\n",
      "SD:  25327.6\n",
      "\n",
      "Black\n",
      "Mean:  20583.5\n",
      "SD:  14211.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'IS.Adj.'\n",
    "b = 'Ethnicity'\n",
    "df = most_affected\n",
    "#df.replace('########', np.NaN, inplace=True)\n",
    "#df = df[df[a].notna()]\n",
    "df[a] = df[a].astype(str)\n",
    "df[a] = df[a].str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "#Calculate mean for all PD patients\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "score = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "score = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "score = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "score = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2397b8d",
   "metadata": {},
   "source": [
    "#### Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "82c33f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS.Adj.\n",
      "Distribution\n",
      "\n",
      "White\n",
      "Statistics = 0.807, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.798, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = 0.933, p = 0.375\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 3.869, p = 0.052\n",
      "Variances are equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = 0.851, p = 0.359\n",
      "Variances are equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 3.089, p = 0.084\n",
      "Variances are equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "a = 'IS.Adj.'\n",
    "b = 'Ethnicity'\n",
    "df1 = most_affected\n",
    "\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "9f8e2ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 1504.000, p = 0.401\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = 337.000, p = 0.158\n",
      "Difference is not significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = 357.000, p = 0.432\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, equal variances - Mann Whitney U   \n",
    "print('White vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U   \n",
    "print('White vs Black')\n",
    "stat, p = st.mannwhitneyu(x=W[a], y=B[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee9d75",
   "metadata": {},
   "source": [
    "#### Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ea265f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  117\n",
      "White and Black PD patients count:  82\n",
      "Black and South Asian PD patients count:  61\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes\n",
    "df = most_affected\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "W_SA = df[(df[b]==1) | (df[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df[(df[b]==1) | (df[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df[(df[b]==2) | (df[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "dc548448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674556\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      115\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                0.003540\n",
      "Time:                        14:46:00   Log-Likelihood:                -78.923\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4540\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.               -7.827e-06   8.11e-06     -0.966      0.334   -2.37e-05    8.06e-06\n",
      "DaysSinceSymptomOnset     0.0001   6.75e-05      1.980      0.048    1.33e-06       0.000\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.3342754526395806\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651383\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      113\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03777\n",
      "Time:                        14:46:00   Log-Likelihood:                -76.212\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1124\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.                -1.37e-05   9.21e-06     -1.487      0.137   -3.17e-05    4.35e-06\n",
      "DaysSinceSymptomOnset  4.386e-06   8.47e-05      0.052      0.959      -0.000       0.000\n",
      "Age                       0.0132      0.006      2.119      0.034       0.001       0.025\n",
      "Gender                   -0.2665      0.413     -0.645      0.519      -1.077       0.544\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.13695980933747995\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    69\n",
      "0    48\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650124\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  117\n",
      "Model:                          Logit   Df Residuals:                      112\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.03963\n",
      "Time:                        14:46:00   Log-Likelihood:                -76.065\n",
      "converged:                       True   LL-Null:                       -79.203\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1794\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.               -1.452e-05   9.39e-06     -1.547      0.122   -3.29e-05    3.87e-06\n",
      "DaysSinceSymptomOnset -1.734e-05   9.47e-05     -0.183      0.855      -0.000       0.000\n",
      "Age                       0.0126      0.006      1.977      0.048       0.000       0.025\n",
      "Gender                   -0.2872      0.416     -0.690      0.490      -1.103       0.529\n",
      "LEDD_ADJUSTED_2           0.0002      0.000      0.524      0.600      -0.001       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.12176691778951675\n",
      "\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    64\n",
      "0    47\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652162\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  111\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.04287\n",
      "Time:                        14:46:00   Log-Likelihood:                -72.390\n",
      "converged:                       True   LL-Null:                       -75.632\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1657\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "IS.Adj.                        -1.55e-05   9.99e-06     -1.552      0.121   -3.51e-05    4.07e-06\n",
      "DaysSinceSymptomOnset          4.325e-05   8.94e-05      0.484      0.629      -0.000       0.000\n",
      "Age                               0.0176      0.009      2.020      0.043       0.001       0.035\n",
      "Gender                           -0.1159      0.430     -0.270      0.787      -0.958       0.726\n",
      "UPDRS_3b_CurrentClinicalState    -0.6415      0.561     -1.144      0.252      -1.740       0.457\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.12055106364139209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\3735404075.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "print('')\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "dd296207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White vs Black\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.485274\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       80\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 -0.1099\n",
      "Time:                        14:46:07   Log-Likelihood:                -39.792\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.                7.226e-06   1.56e-05      0.464      0.643   -2.33e-05    3.78e-05\n",
      "DaysSinceSymptomOnset     0.0005      0.000      3.173      0.002       0.000       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.6429559894239936\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.411536\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       78\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.05878\n",
      "Time:                        14:46:07   Log-Likelihood:                -33.746\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2392\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.               -1.895e-05   1.64e-05     -1.153      0.249   -5.12e-05    1.33e-05\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.755      0.450      -0.000       0.000\n",
      "Age                       0.0162      0.010      1.645      0.100      -0.003       0.036\n",
      "Gender                    1.0009      0.648      1.544      0.122      -0.269       2.271\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.24889001066442162\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender LEDD_ADJUSTED_2\n",
      "1    69\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407982\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       77\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.06690\n",
      "Time:                        14:46:07   Log-Likelihood:                -33.455\n",
      "converged:                       True   LL-Null:                       -35.853\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3087\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.               -2.234e-05   1.75e-05     -1.280      0.201   -5.66e-05    1.19e-05\n",
      "DaysSinceSymptomOnset  6.589e-05      0.000      0.334      0.739      -0.000       0.000\n",
      "Age                       0.0156      0.010      1.564      0.118      -0.004       0.035\n",
      "Gender                    0.9540      0.656      1.453      0.146      -0.333       2.241\n",
      "LEDD_ADJUSTED_2           0.0005      0.001      0.642      0.521      -0.001       0.002\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.20071683229669424\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1    64\n",
      "0    13\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.423312\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   77\n",
      "Model:                          Logit   Df Residuals:                       72\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.06765\n",
      "Time:                        14:46:07   Log-Likelihood:                -32.595\n",
      "converged:                       True   LL-Null:                       -34.960\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3161\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "IS.Adj.                       -2.334e-05   1.75e-05     -1.335      0.182   -5.76e-05    1.09e-05\n",
      "DaysSinceSymptomOnset             0.0001      0.000      0.583      0.560      -0.000       0.000\n",
      "Age                               0.0112      0.012      0.910      0.363      -0.013       0.035\n",
      "Gender                            1.1692      0.686      1.704      0.088      -0.176       2.514\n",
      "UPDRS_3b_CurrentClinicalState     0.4156      0.747      0.557      0.578      -1.048       1.879\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.1817186570481536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_26880\\896035783.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('')\n",
    "print('White vs Black')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f23a0fae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset\n",
      "1.0    40\n",
      "0.0    12\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.561432\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   52\n",
      "Model:                          Logit   Df Residuals:                       50\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 02 Sep 2024   Pseudo R-squ.:                -0.03930\n",
      "Time:                        17:01:30   Log-Likelihood:                -29.194\n",
      "converged:                       True   LL-Null:                       -28.091\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.                1.823e-05   1.47e-05      1.243      0.214   -1.05e-05     4.7e-05\n",
      "DaysSinceSymptomOnset     0.0002      0.000      1.436      0.151   -7.89e-05       0.001\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.21392221624596586\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Self_Reported_Age Gender\n",
      "1.0    40\n",
      "0.0    12\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514877\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   52\n",
      "Model:                          Logit   Df Residuals:                       48\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 02 Sep 2024   Pseudo R-squ.:                 0.04688\n",
      "Time:                        17:01:30   Log-Likelihood:                -26.774\n",
      "converged:                       True   LL-Null:                       -28.091\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4516\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.                3.014e-06   1.64e-05      0.183      0.854   -2.92e-05    3.52e-05\n",
      "DaysSinceSymptomOnset     0.0001      0.000      0.625      0.532      -0.000       0.001\n",
      "Self_Reported_Age        -0.0006      0.011     -0.051      0.959      -0.023       0.022\n",
      "Gender                    1.2708      0.685      1.854      0.064      -0.073       2.614\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.8544595020061772\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Self_Reported_Age Gender LEDD_ADJUSTED_2\n",
      "1.0    40\n",
      "0.0    12\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514149\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   52\n",
      "Model:                          Logit   Df Residuals:                       47\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 02 Sep 2024   Pseudo R-squ.:                 0.04823\n",
      "Time:                        17:01:30   Log-Likelihood:                -26.736\n",
      "converged:                       True   LL-Null:                       -28.091\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6075\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "IS.Adj.                2.659e-06   1.63e-05      0.163      0.871   -2.94e-05    3.47e-05\n",
      "DaysSinceSymptomOnset  7.851e-05      0.000      0.331      0.741      -0.000       0.001\n",
      "Self_Reported_Age        -0.0013      0.012     -0.115      0.908      -0.024       0.021\n",
      "Gender                    1.2364      0.694      1.783      0.075      -0.123       2.596\n",
      "LEDD_ADJUSTED_2           0.0003      0.001      0.278      0.781      -0.002       0.003\n",
      "=========================================================================================\n",
      "Full p-value for exposure:  0.8706607102689441\n",
      "\n",
      "Exposure  IS.Adj.  adjusted by  DaysSinceSymptomOnset Self_Reported_Age Gender UPDRS_3b_CurrentClinicalState\n",
      "1.0    39\n",
      "0.0    12\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.520683\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                   51\n",
      "Model:                          Logit   Df Residuals:                       46\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 02 Sep 2024   Pseudo R-squ.:                 0.04566\n",
      "Time:                        17:01:30   Log-Likelihood:                -26.555\n",
      "converged:                       True   LL-Null:                       -27.825\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6373\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "IS.Adj.                        8.998e-07   1.68e-05      0.053      0.957   -3.21e-05    3.39e-05\n",
      "DaysSinceSymptomOnset          8.207e-05      0.000      0.407      0.684      -0.000       0.000\n",
      "Self_Reported_Age                -0.0036      0.014     -0.256      0.798      -0.031       0.024\n",
      "Gender                            1.2545      0.687      1.827      0.068      -0.091       2.600\n",
      "UPDRS_3b_CurrentClinicalState     0.4034      0.968      0.417      0.677      -1.494       2.301\n",
      "=================================================================================================\n",
      "Full p-value for exposure:  0.9573712659185349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_16904\\870125805.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(2, 0)\n",
      "C:\\Users\\hfx956\\AppData\\Local\\Temp\\ipykernel_16904\\870125805.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[b] = df1[b].replace(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'DaysSinceSymptomOnset'\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "e = 'Gender'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "f = 'LEDD_ADJUSTED_2'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1[b].value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "# This is to check if On-OFF affected scores\n",
    "f = 'UPDRS_3b_CurrentClinicalState'\n",
    "df1 = df1[df1[f].notna()]\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d, e, f)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d, e, f]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cc886",
   "metadata": {},
   "source": [
    "### HCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "8ceeb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDH\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')\n",
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "idx = df_merged.groupby('ELPD_ID')['KS'].idxmin()\n",
    "\n",
    "most_affected_HC = df_merged.loc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "cbf76af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Merge to BRAINtest data\n",
    "df = ELPDP\n",
    "\n",
    "# Read BRAINtest data\n",
    "df_brain = pd.read_csv('Raw_BRAINtest.csv', sep = ',', header = 0, engine='python')\n",
    "\n",
    "# Merge data sets\n",
    "df_merged = pd.merge(df, df_brain, how='inner', on='ELPD_ID')\n",
    "\n",
    "# Group by 'key' and select the maximum 'value' in each group\n",
    "# Find the index of the maximum 'value' for each 'key'\n",
    "# Add a column that contains the maximum score of score1 and score2\n",
    "\n",
    "print(df_merged['UPDRS_Part3_Right'].isna().sum())\n",
    "df_merged = df_merged[df_merged['UPDRS_Part3_Right'].notna()]\n",
    "\n",
    "df_merged['max_score'] = df_merged[['UPDRS_Part3_Right', 'UPDRS_Part3_Left']].max(axis=1)\n",
    "print(df_merged['max_score'].isna().sum())\n",
    "\n",
    "# Find the index of the row with the highest max_score for each id\n",
    "idx = df_merged.groupby('ELPD_ID')['max_score'].idxmax()\n",
    "\n",
    "# Select the rows with the highest score\n",
    "most_affected = df_merged.loc[idx].drop(columns=['max_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "c082d344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS.Adj.\n",
      "\n",
      "PwP\n",
      "Mean:  19356.5\n",
      "SD:  22019.2\n",
      "\n",
      "Statistics = 0.809, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "HCs\n",
      "\n",
      "All 14\n",
      "Mean:  15779.5\n",
      "SD:  17573.1\n",
      "\n",
      "Lower threshold:  -19366.7\n",
      "Higher threshold:  50925.7\n",
      "\n",
      "13\n",
      "Mean:  11279.7\n",
      "SD:  7006.9\n",
      "\n",
      "Statistics = 0.941, p = 0.470\n",
      "Distribution is normal\n",
      "\n",
      "Variances\n",
      "PwP vs HCs\n",
      "Statistics = 9.205, p = 0.003\n",
      "Variances are not equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select variables\n",
    "a = 'IS.Adj.'\n",
    "b = 'Ethnicity'\n",
    "print(a)\n",
    "print('')\n",
    "\n",
    "print('PwP')\n",
    "df1 = most_affected\n",
    "df1[a] = df1[a].astype(str)\n",
    "df1[a] = df1[a].str.replace(',', '').astype(float)\n",
    "score = df1[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score.std())\n",
    "print('')\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('HCs')\n",
    "print('')\n",
    "#Calculate mean for all HCs \n",
    "df2 = most_affected_HC\n",
    "df2.replace('########', np.NaN, inplace=True)\n",
    "df2 = df2[df2[a].notna()]\n",
    "df2[a] = df2[a].astype(str)\n",
    "df2[a] = df2[a].str.replace(',', '').astype(float)\n",
    "print('All', df2[a].count())\n",
    "score_HC = df2[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')\n",
    "\n",
    "low = score_HC.mean() - 2*(score_HC.std())\n",
    "high = score_HC.mean() + 2*(score_HC.std())\n",
    "print(\"Lower threshold: \", \"%.1f\"  % low)\n",
    "print(\"Higher threshold: \", \"%.1f\"  % high)\n",
    "\n",
    "# Exclude outliers\n",
    "df2[a].mask((df2[a] < low), inplace=True)\n",
    "df2[a].mask((df2[a] > high), inplace=True)\n",
    "df2 = df2[df2[a].notna()]\n",
    "\n",
    "print('')\n",
    "score_HC = df2[a].to_numpy(dtype=np.float32)\n",
    "print(df2[a].count())\n",
    "print(\"Mean: \" , \"%.1f\" % score_HC.mean())\n",
    "print(\"SD: \", \"%.1f\"  % score_HC.std())\n",
    "print('')\n",
    "\n",
    "\n",
    "stat, p = st.shapiro(df2[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('Variances')\n",
    "print('PwP vs HCs')\n",
    "stat, p = st.levene(df1[a], df2[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "89209361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PwP vs HC\n",
      "Statistics = 0.066, p = 0.797\n",
      "Difference is not significant\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskall\n",
    "print('')\n",
    "print('PwP vs HC')\n",
    "stat, p = st.kruskal(df1[a], df2[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90819c14",
   "metadata": {},
   "source": [
    "# Deprivation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ec861f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMD_decile\n",
      "PwP\n",
      "\n",
      "All\n",
      "n:  217\n",
      "Mean:  4\n",
      "SD:  2\n",
      "Median:  3\n",
      "IQR:  2\n",
      "\n",
      "White\n",
      "Mean:  4\n",
      "SD:  2\n",
      "Median:  4\n",
      "IQR:  3\n",
      "\n",
      "South Asian\n",
      "Mean:  4\n",
      "SD:  2\n",
      "Median:  3\n",
      "IQR:  1\n",
      "\n",
      "Black\n",
      "Mean:  3\n",
      "SD:  2\n",
      "Median:  3\n",
      "IQR:  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 'IMD_decile'\n",
    "b = 'Ethnicity'\n",
    "df = ELPDP\n",
    "df = df[df[a].notna()]\n",
    "\n",
    "# Descriptive statistics\n",
    "print(a)\n",
    "print('PwP')\n",
    "print('')\n",
    "print('All')\n",
    "print('n: ', df[a].count())\n",
    "duration = df[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(df[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White')\n",
    "W = df[df[b]==1]\n",
    "duration = W[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(W[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "print('South Asian')\n",
    "SA = df[df[b]==3]\n",
    "duration = SA[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(SA[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n",
    "\n",
    "print('Black')\n",
    "B = df[df.Ethnicity==2]\n",
    "duration = B[a].to_numpy(dtype=np.float32)\n",
    "print(\"Mean: \" , \"%.0f\" % duration.mean())\n",
    "print(\"SD: \", \"%.0f\"  % duration.std())\n",
    "print(\"Median: \" , \"%.0f\" % np.median(duration))\n",
    "q75, q25 = np.percentile(B[a], [75 ,25])\n",
    "iqr = q75 - q25\n",
    "print(\"IQR: \", \"%.0f\"  % iqr)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ccf71",
   "metadata": {},
   "source": [
    "## Significance - univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "04727cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMD_decile\n",
      "Distribution\n",
      "Total PwP\n",
      "Statistics = nan, p = nan\n",
      "Distribution is not normal\n",
      "\n",
      "White\n",
      "Statistics = 0.876, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "South Asian\n",
      "Statistics = 0.788, p = 0.000\n",
      "Distribution is not normal\n",
      "\n",
      "Black\n",
      "Statistics = nan, p = nan\n",
      "Distribution is not normal\n",
      "\n",
      "Variances\n",
      "White vs South Asian\n",
      "Statistics = 15.508, p = 0.000\n",
      "Variances are not equal\n",
      "\n",
      "White vs Black\n",
      "Statistics = nan, p = nan\n",
      "Variances are not equal\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = nan, p = nan\n",
      "Variances are not equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that distribution is normal with Shapiro test\n",
    "df1 = ELPDP\n",
    "b = 'Ethnicity'\n",
    "\n",
    "stat, p = st.shapiro(df1[a])\n",
    "print(a)\n",
    "print('Distribution')\n",
    "print('Total PwP')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal')    \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "print('White')\n",
    "W = df1[df1[b]==1]\n",
    "stat, p = st.shapiro(W[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('South Asian')\n",
    "SA = df1[df1[b]==3]\n",
    "stat, p = st.shapiro(SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black')\n",
    "B = df1[df1[b]==2]\n",
    "stat, p = st.shapiro(B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Distribution is normal') \n",
    "else:\n",
    "    print('Distribution is not normal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Variances')\n",
    "print('White vs South Asian')\n",
    "stat, p = st.levene(W[a], SA[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('White vs Black')\n",
    "stat, p = st.levene(W[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.levene(SA[a], B[a], center= 'mean')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "# Decide on outcome\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Variances are equal') \n",
    "else:\n",
    "    print('Variances are not equal')\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "975f9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Statistics = 7.779, p = 0.005\n",
      "Difference is not significant\n",
      "\n",
      "White vs Black\n",
      "Statistics = nan, p = nan\n",
      "Difference is significant\n",
      "\n",
      "Black vs South Asian\n",
      "Statistics = nan, p = nan\n",
      "Difference is significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('White vs South Asian')\n",
    "stat, p = st.kruskal(W[a], SA[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "# Non-normal distribution, non-equal variances - Kruskal Wallis\n",
    "print('')\n",
    "print('White vs Black')\n",
    "stat, p = st.kruskal(W[a], B[a])\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "\n",
    "# Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "\n",
    "\n",
    "# Non-normal distribution, equal variances - Mann Whitney U\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "stat, p = st.mannwhitneyu(x=B[a], y=SA[a], alternative = 'two-sided')\n",
    "print('Statistics = {0:.3f}, p = {1:.3f}'.format(stat, p))\n",
    "#Decide on outcome\n",
    "alpha = 0.004\n",
    "if p > alpha:\n",
    "    print('Difference is not significant')   \n",
    "else:\n",
    "    print('Difference is significant')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27f2d0",
   "metadata": {},
   "source": [
    "## Significance - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "cb22db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White and South Asian PD patients count:  181\n",
      "White and Black PD patients count:  119\n",
      "Black and South Asian PD patients count:  108\n"
     ]
    }
   ],
   "source": [
    "df1 = ELPDP\n",
    "df1 = df1[df1[a].notna()]\n",
    "\n",
    "# Create dataframes\n",
    "W_SA = df1[(df1[b]==1) | (df1[b]==3)]\n",
    "print('White and South Asian PD patients count: ',W_SA[b].count())\n",
    "\n",
    "W_B = df1[(df1[b]==1) | (df1[b]==2)]\n",
    "print('White and Black PD patients count: ',W_B[b].count())\n",
    "\n",
    "B_SA = df1[(df1[b]==2) | (df1[b]==3)]\n",
    "print('Black and South Asian PD patients count: ',B_SA.Ethnicity.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "bad2448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Exposure  IMD_decile  adjusted by  Gender\n",
      "1    96\n",
      "0    85\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674945\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  181\n",
      "Model:                          Logit   Df Residuals:                      179\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02366\n",
      "Time:                        15:10:31   Log-Likelihood:                -122.16\n",
      "converged:                       True   LL-Null:                       -125.13\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01497\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "IMD_decile     0.1269      0.052      2.423      0.015       0.024       0.230\n",
      "Gender        -0.4016      0.282     -1.427      0.154      -0.953       0.150\n",
      "==============================================================================\n",
      "Full p-value for exposure:  0.015403986541978162\n",
      "\n",
      "Exposure  IMD_decile  adjusted by  Gender Age\n",
      "1    96\n",
      "0    85\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.671375\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  181\n",
      "Model:                          Logit   Df Residuals:                      178\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.02882\n",
      "Time:                        15:10:31   Log-Likelihood:                -121.52\n",
      "converged:                       True   LL-Null:                       -125.13\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02715\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "IMD_decile     0.1936      0.080      2.418      0.016       0.037       0.350\n",
      "Gender        -0.2567      0.309     -0.832      0.405      -0.861       0.348\n",
      "Age           -0.0061      0.005     -1.131      0.258      -0.017       0.004\n",
      "==============================================================================\n",
      "Full p-value for exposure:  0.015591866233204453\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'Gender'\n",
    "df1 = W_SA\n",
    "df1[b] = df1[b].replace(3, 0)\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "b55aa8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White vs South Asian\n",
      "Exposure  IMD_decile  adjusted by  Gender\n",
      "1    96\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.456762\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  119\n",
      "Model:                          Logit   Df Residuals:                      117\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.06962\n",
      "Time:                        15:10:38   Log-Likelihood:                -54.355\n",
      "converged:                       True   LL-Null:                       -58.422\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.004343\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "IMD_decile     0.3227      0.087      3.699      0.000       0.152       0.494\n",
      "Gender         0.4023      0.439      0.916      0.360      -0.458       1.263\n",
      "==============================================================================\n",
      "Full p-value for exposure:  0.0002162050712488714\n",
      "\n",
      "Exposure  IMD_decile  adjusted by  Gender Age\n",
      "1    96\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.456117\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  119\n",
      "Model:                          Logit   Df Residuals:                      116\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.07093\n",
      "Time:                        15:10:38   Log-Likelihood:                -54.278\n",
      "converged:                       True   LL-Null:                       -58.422\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.01586\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "IMD_decile     0.3708      0.154      2.404      0.016       0.069       0.673\n",
      "Gender         0.4758      0.475      1.001      0.317      -0.455       1.407\n",
      "Age           -0.0033      0.009     -0.389      0.697      -0.020       0.013\n",
      "==============================================================================\n",
      "Full p-value for exposure:  0.016202713976637383\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "c = 'Gender'\n",
    "df1 = W_B\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "print('White vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "25ecfda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black vs South Asian\n",
      "Exposure  IMD_decile  adjusted by  Gender\n",
      "1    85\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.510996\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  108\n",
      "Model:                          Logit   Df Residuals:                      106\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01325\n",
      "Time:                        15:10:44   Log-Likelihood:                -55.188\n",
      "converged:                       True   LL-Null:                       -55.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2235\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "IMD_decile     0.2601      0.098      2.667      0.008       0.069       0.451\n",
      "Gender         0.6663      0.447      1.492      0.136      -0.209       1.542\n",
      "==============================================================================\n",
      "Full p-value for exposure:  0.0076480948476383625\n",
      "\n",
      "Exposure  IMD_decile  adjusted by  Gender Age\n",
      "1    85\n",
      "0    23\n",
      "Name: Ethnicity, dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.510980\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Ethnicity   No. Observations:                  108\n",
      "Model:                          Logit   Df Residuals:                      105\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 31 Oct 2024   Pseudo R-squ.:                 0.01328\n",
      "Time:                        15:10:44   Log-Likelihood:                -55.186\n",
      "converged:                       True   LL-Null:                       -55.928\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4759\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "IMD_decile     0.2507      0.187      1.344      0.179      -0.115       0.616\n",
      "Gender         0.6616      0.454      1.457      0.145      -0.228       1.551\n",
      "Age            0.0005      0.009      0.059      0.953      -0.017       0.018\n",
      "==============================================================================\n",
      "Full p-value for exposure:  0.17908485523322348\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "df1 = B_SA\n",
    "df1[b] = df1[b].replace(2, 0)\n",
    "df1[b] = df1[b].replace(3, 1)\n",
    "print('')\n",
    "print('Black vs South Asian')\n",
    "print('Exposure ', a, ' adjusted by ', c)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n",
    "\n",
    "\n",
    "d = 'Age'\n",
    "print('')\n",
    "print('Exposure ', a, ' adjusted by ', c, d)\n",
    "print(df1.Ethnicity.value_counts())\n",
    "\n",
    "# Defining the dependent and independent variables \n",
    "Xtrain = df1[[a, c, d]] \n",
    "ytrain = df1[b] \n",
    "\n",
    "# Building the model and fitting the data \n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() \n",
    "\n",
    "# Printing the summary table \n",
    "print(log_reg.summary())\n",
    "print('Full p-value for exposure: ', log_reg.pvalues[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "666px",
    "width": "285px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
